

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>The Neural Process Family &#8212; Neural Process Family</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Conditional NPF" href="CNPF.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="#">
   The Neural Process Family
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Sub-Families
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="CNPF.html">
   Conditional NPF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="LNPF.html">
   Latent NPF
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reproducibility
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/Datasets.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/CNP.html">
   CNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/AttnCNP.html">
   AttnCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/ConvCNP.html">
   ConvCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/LNP.html">
   LNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/AttnLNP.html">
   AttnLNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/ConvLNP.html">
   ConvLNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reproducibility/Losses.html">
   LNPF Losses
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../zbibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/YannDubs/Neural-Process-Family">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/text/Intro.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/YannDubs/Neural-Process-Family"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#meta-learning-stochastic-processes">
   Meta Learning Stochastic Processes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#meta-learning">
     Meta-learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-process-prediction">
     Stochastic Process Prediction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameterising-neural-processes">
   Parameterising Neural Processes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#meta-training-in-the-npf">
   Meta-Training in the NPF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-cases">
   Use Cases
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-of-npf-properties">
   Summary of NPF Properties
  </a>
  <ul class="nav section-nav flex-column">
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="the-neural-process-family">
<h1>The Neural Process Family<a class="headerlink" href="#the-neural-process-family" title="Permalink to this headline">¶</a></h1>
<p>Should doctors use predictions made by a neural network (e.g. predictions of your blood sugar level between appointments) to diagnose you, if the neural network was trained on millions of cases similar to yours?
Maybe, but what if it was trained on very different cases?
Probably not, as neural networks require large number of train examples that are similar to the test examples.
Recently there has been a big push in having networks that can quickly adapt to new situations.
These methods (known as meta-learning) are exciting as they enable the use of deep learning in settings with little training data.
Going back to our example, should doctors use a meta-learning network adapted on 10’000 cases ? 1’000 ? 100 ? 10 ? 1?
When the number of cases becomes scarce, it is hard to gauge whether predictions are trustworthy even if meta-learning works well.
Ideally, predictors should then also give an estimate of their confidence so that doctors can decide whether to trust the predictions.</p>
<p>The <strong>Neural Process Family</strong> (NPF) is a collection of models that incorporate uncertainty estimates in meta-learning in a very natural fashion, namely, by meta-learning a <em>distribution</em> over predictors.
More precisely, members of the NPF — Neural Processes (NPs) — use meta-learning of neural networks to directly model <em>stochastic processes</em>.</p>
<p>We will unpack both of the terms “meta-learning” and “stochastic processes” in the following section, focusing on how they are used in the NPF.
But before diving in, let us consider a few tasks that NPFs are particularly well-suited for.</p>
<ul class="simple">
<li><p><strong>Predicting times-series data with uncertainty.</strong>
Many tasks associated with time-series predictions require uncertainty estimate (e.g., clinical or economic forecasting).
Let us consider the task of restoring corrupted audio signals.
In this cases, we are given a dataset <span class="math notranslate nohighlight">\(\mathcal{D} = \{(x^{(n)}, y^{(n)})\}_{n=1}^N\)</span>, where <span class="math notranslate nohighlight">\(x\)</span> are the inputs (time) and <span class="math notranslate nohighlight">\(y\)</span> are the outputs (sound wave amplitude), and our goal is to reconstruct the signal conditioned on <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.
If <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is very sparse, there could be many reasonable reconstructions — hence we should be wary of simply providing a single prediction, and instead augment these with measures of uncertainty.
Ideally, we would be able to produce plausible <em>samples</em> of an entire audio signal.
<a class="reference internal" href="#convlnp"><span class="std std-numref">Fig. 1</span></a> shows a NP being used to sample plausible interpolations of simple time-series, both periodic and non-periodic.</p></li>
</ul>
<div class="figure align-default" id="convlnp">
<a class="reference internal image-reference" href="../_images/ConvLNP_norbf_gp_extrap.gif"><img alt="Samples from ConvLNP trained on GPs" src="../_images/ConvLNP_norbf_gp_extrap.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Sample functions from the predictive distribution of ConvLNPs (blue) and the oracle GP (green) with periodic and noisy Matern kernels.</span><a class="headerlink" href="#convlnp" title="Permalink to this image">¶</a></p>
</div>
<ul class="simple">
<li><p><strong>Interpolating image data with uncertainty.</strong> Imagine that we are given a satellite image of a region obscured by cloud-cover.
For downstream tasks, we may need to make predictions regarding what is “behind” the occlusions. For example, the <a class="reference external" href="https://en.wikipedia.org/wiki/United_Nations_High_Commissioner_for_Refugees">UNHCR</a> might need to count the number of tents in a refugee camp to know how much food and healthcare to send there.
If clouds are obscuring a large part of the image, we might be interested not just in a single interpolation, but in the entire probability distribution over plausible interpolations, to make our downstream predictions more robust to errors.
<a class="reference internal" href="#convcnp-superes-intro"><span class="std std-numref">Fig. 2</span></a> shows a NP upscaling the resolution of an image by treating pixel locations that are “in between” the pixels of the input images as occluded pixels, i.e., by interpolating between pixels.</p></li>
</ul>
<div class="figure align-default" id="convcnp-superes-intro">
<a class="reference internal image-reference" href="../_images/ConvCNP_superes.png"><img alt="Increasing image resolution with ConvCNP" src="../_images/ConvCNP_superes.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Increasing the resolution of <span class="math notranslate nohighlight">\(16 \times 16\)</span> CelebA to <span class="math notranslate nohighlight">\(128 \times 128\)</span> with a ConvCNP.</span><a class="headerlink" href="#convcnp-superes-intro" title="Permalink to this image">¶</a></p>
</div>
<div class="note dropdown admonition">
<p class="admonition-title">Note<span class="math notranslate nohighlight">\(\qquad\)</span>Outline</p>
<p>The goal of this tutorial is to provide a gentle introduction to the NPF.
Our approach is to walk through several prominent members of the NPF, highlighting their key advantages and drawbacks.
By accompanying the exposition with code and examples, we hope to (i) make the design choices and tradeoffs associated with each model clear and intuitive, and (ii) demonstrate both the simplicity of the framework and its broad applicability.</p>
<p>This tutorial is split into three sections.
This first page will give a broad, bird’s eye view of the entire Neural Process Family.
We’ll see that the family splits naturally into two sub-families: the <a class="reference internal" href="CNPF.html"><span class="doc">Conditional NPF</span></a>, and the <a class="reference internal" href="LNPF.html"><span class="doc">Latent NPF</span></a>.
These are covered in the following two pages, and there we’ll get into more detail about the different architectures in each family.
In the Reproducibility section we provide the code to run all the models and generate all the plots, while the main <a class="reference external" href="https://github.com/YannDubs/Neural-Process-Family">github repository</a> contains the main framework for implementing NPs.</p>
<p>Throughout the tutorial, we make liberal use of dropdown boxes to avoid breaking up the exposition.
Feel free to skip or skim those on a first reading.</p>
</div>
<div class="section" id="meta-learning-stochastic-processes">
<h2>Meta Learning Stochastic Processes<a class="headerlink" href="#meta-learning-stochastic-processes" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="meta-learning-sp">
<a class="reference internal image-reference" href="../_images/MetaStochasticProcess.svg"><img alt="Neural Processes as meta learning stochastic processes" src="../_images/MetaStochasticProcess.svg" width="100%" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Comparison between meta learning vs supervised learning, and modeling functions vs modeling stochastic processes. Neural Processes are in the lower-right quadrant.</span><a class="headerlink" href="#meta-learning-sp" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="meta-learning">
<h3>Meta-learning<a class="headerlink" href="#meta-learning" title="Permalink to this headline">¶</a></h3>
<p>In a (deep) supervised learning, a neural network is trained to model a target function.
Specifically, a network is trained on a single dataset <span class="math notranslate nohighlight">\(\mathcal{C} := \{(x^{(c)}, y^{(c)})\}_{c=1}^C\)</span> (which we will refer to as a <strong>context set</strong>), and give rise to a predictor, <span class="math notranslate nohighlight">\(f(\cdot)\)</span>.
A supervised learning algorithm can thus be seen as a function mapping a dataset to a predictor <span class="math notranslate nohighlight">\(\mathcal{C} \mapsto f(x)\)</span>.
At test time, a prediction at a target location <span class="math notranslate nohighlight">\(x^{(t)}\)</span> can be made by feeding it into the predictor to obtain <span class="math notranslate nohighlight">\(f(x^{(t)})\)</span>.
By doing so for the entire test set (which we call <strong>target inputs</strong>) <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}} := \{x^{(t)}\}_{t=1}^T\)</span>, we get a set of predictions <span class="math notranslate nohighlight">\(f(\mathbf{x}_{\mathcal{T}}):= \{f(x^{(t)})\}_{t=1}^T\)</span>.
The predictor is evaluated by comparing <span class="math notranslate nohighlight">\(f(\mathbf{x}_{\mathcal{T}})\)</span> to the real <strong>target outputs</strong> <span class="math notranslate nohighlight">\(\mathbf{y}_{\mathcal{T}} := \{y^{(t)}\}_{t=1}^T\)</span>.
We will refer to a context and target set as a <em>task</em>  <span class="math notranslate nohighlight">\(\mathcal{D} := (\mathcal{C}, \mathbf{x}_{\mathcal{T}}, \mathbf{y}_{\mathcal{T}})\)</span>.
The process is summarised in the upper left quadrant quadrant of <a class="reference internal" href="#meta-learning-sp"><span class="std std-numref">Fig. 3</span></a>.</p>
<p>The idea of meta-learning is <em>learning to learn</em>, i.e., learning how to rapidly adapt to new supervised tasks.
The key insight is that, as we just saw, a supervised learning algorithm is itself a function.
As a result we can use supervised learning to model a supervised learning algorithm, hence the name <em>meta</em>.</p>
<p>When would such a scheme be useful in practice? When we have access to a large collection <span class="math notranslate nohighlight">\(\mathcal{M}= \{ \mathcal{D_i} \}_{i=1}^{N_{\mathrm{tasks}}}\)</span> of related datasets. This collection of tasks forms the meta-dataset, or dataset of datasets, on which the meta-learning algorithm is (meta-)trained.
The result of meta-training is a supervised learning algorithm, i.e., a map <span class="math notranslate nohighlight">\(\mathcal{C} \mapsto f(x; \mathcal{C})\)</span>.
At meta-test time, we’ll adapt the predictor to a task it has never seen before by providing it a new context set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.
In this blog we will only consider cases where the output of meta-training is a neural network, meaning that the adaptation to a new task is done with a single forward pass, without any gradient updates!
The resulting predictor <span class="math notranslate nohighlight">\(f(\cdot; \mathcal{C})\)</span> will use the information obtained during meta-learning to make predictions on this new task.
The whole process is illustrated in the bottom left quadrant of <a class="reference internal" href="#meta-learning-sp"><span class="std std-numref">Fig. 3</span></a>.</p>
<p>Because it shares information across tasks, meta-learning is especially well-suited to situations where each task is a <em>small</em> dataset, as in, e.g., few-shot learning.
However, this raises the question: if the context set is small, can we really expect to obtain a unique predictor <span class="math notranslate nohighlight">\(f(\cdot; \mathcal{C})\)</span> from it?
To relate this back to our examples, if we only observe an audio signal at a few timestamps, or an image at a few pixels, can we really uniquely reconstruct the original?
What we need is to express our <em>uncertainty</em>, and this leads us naturally to <em>stochastic processes</em>.</p>
<div class="note dropdown admonition">
<p class="admonition-title">Note<span class="math notranslate nohighlight">\(\qquad\)</span>Summary of Terminology</p>
<table class="table" id="notation">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Summary of NPF meta-learning terminology and notation</span><a class="headerlink" href="#notation" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathcal{C} := \{(x^{(c)}, y^{(c)})\}_{c=1}^C\)</span></p></th>
<td><p>Context set</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}} := \{x^{(t)}\}_{t=1}^T\)</span></p></th>
<td><p>Target inputs</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathbf{y}_{\mathcal{T}} := \{y^{(t)}\}_{t=1}^T\)</span></p></th>
<td><p>Target outputs</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathcal{T} := (\mathbf{x}_{\mathcal{T}}, \mathbf{y}_{\mathcal{T}}) = \{(x^{(t)}, y^{(t)})\}_{t=1}^T\)</span></p></th>
<td><p>Target set</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><span class="math notranslate nohighlight">\(f(\mathbf{x}_{\mathcal{T}}; \mathcal{C}) :=  \{f(x^{(t)}; \mathcal{C})\}_{t=1}^T\)</span></p></th>
<td><p>Predictions</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathcal{D} := (\mathcal{C}, \mathcal{T}) = \{(x^{(n)}, y^{(n)})\}_{n=1}^{T+C}\)</span></p></th>
<td><p>Dataset/task</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><span class="math notranslate nohighlight">\(\mathcal{M} := \{ \mathcal{D}^{(i)} \}_{i=1}^{N_{\mathrm{tasks}}}\)</span></p></th>
<td><p>Meta-dataset</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="stochastic-process-prediction">
<h3>Stochastic Process Prediction<a class="headerlink" href="#stochastic-process-prediction" title="Permalink to this headline">¶</a></h3>
<p>We’ve seen that we can think of meta-learning as learning a map directly from context sets <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> to predictor functions <span class="math notranslate nohighlight">\(f(\cdot; \mathcal{C})\)</span>.
However, there are many situations where a single predictor without error-bars isn’t good enough.
Quantifying our uncertainty is crucial for decision-making, and has many applications such as in active learning, Bayesian optimisation.
It is especially crucial in the small context-set setting, which is often the case in meta-learning.</p>
<p>What we need is not a set of single predictions <span class="math notranslate nohighlight">\(f(\mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> at desired target locations, but rather a <em>distribution over predictions</em> <span class="math notranslate nohighlight">\(p(\mathbf{y}_{\mathcal{T}}| \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span>.
As long as these distributions are consistent with each other for any choices of <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span>, specifying <span class="math notranslate nohighlight">\(p(\mathbf{y}_{\mathcal{T}}| \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> for all finite sets of target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> is actually equivalent to specifying a distribution of predictors.
Each predictor sampled from this distribution would represent a plausible interpolation of the data, and the diversity of the samples would reflect the <em>uncertainty</em> in our predictions — think back to <a class="reference internal" href="#convlnp"><span class="std std-numref">Fig. 1</span></a>.
Since each predictor <span class="math notranslate nohighlight">\(f(\cdot; \mathcal{C})\)</span> is a function, this is a <em>distribution over functions</em>.
In mathematics, this is known as a <em>stochastic process</em> (SP).
Hence, <strong>the NPF can generally be seen as meta-learning neural networks to map from datasets to stochastic processes</strong>.
This is where the name Neural Process comes from, and is illustrated in the bottom right quadrant of <a class="reference internal" href="#meta-learning-sp"><span class="std std-numref">Fig. 3</span></a>.</p>
<div class="hint dropdown admonition">
<p class="admonition-title">Advanced<span class="math notranslate nohighlight">\(\qquad\)</span>Stochastic Process Consistency</p>
<p>In the previous discussion, we considered specifying a stochastic process (SP) by specifying <span class="math notranslate nohighlight">\(p(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> for all finite collections of target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span>.
Each  distribution for a given <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> is referred to as a <em>finite marginal</em> of the SP.
Can we stitch together all of these finite marginals to obtain a single SP?
The <em>Kolmogorov extension theorem</em> tells us that we can, as long as the marginals are consistent with each other under <em>permutation</em> and <em>marginalisation</em>:</p>
<p>To illustrate these consistency conditions, let’s look at some artificial examples of finite marginals that are <em>not</em> consistent.
Let <span class="math notranslate nohighlight">\(x^{(1)}, x^{(2)}\)</span> be two target inputs, with <span class="math notranslate nohighlight">\(y^{(1)}, y^{(2)}\)</span> the corresponding random outputs.</p>
<ol class="simple">
<li><p>Consider a collection of finite marginals with <span class="math notranslate nohighlight">\(y^{(1)} \sim \mathcal{N}(0, 1)\)</span> and <span class="math notranslate nohighlight">\([y^{(1)}, y^{(2)}] \sim \mathcal{N}([10, 0], \mathbf{I})\)</span>. What is the mean of <span class="math notranslate nohighlight">\(y^{(1)}\)</span>?</p></li>
<li><p>Consider a collection with <span class="math notranslate nohighlight">\([y^{(1)}, y^{(2)}] \sim \mathcal{N}([0, 0], \mathbf{I})\)</span> and <span class="math notranslate nohighlight">\([y^{(2)}, y^{(1)}] \sim \mathcal{N}([1, 1], \mathbf{I})\)</span>. What is the mean of <span class="math notranslate nohighlight">\(y^{(1)}\)</span>? What is the mean of <span class="math notranslate nohighlight">\(y^{(2)}\)</span>?</p></li>
</ol>
<p>We see the problem here: inconsistent marginals lead to self-contradictory predictions!
In the first example, the marginals were not <em>consistent under marginalisation</em>: marginalising out <span class="math notranslate nohighlight">\(y^{(2)}\)</span> from the distribution of <span class="math notranslate nohighlight">\([y^{(1)}, y^{(2)}]\)</span> did not yield the distribution of <span class="math notranslate nohighlight">\(y^{(1)}\)</span>.
In the second case, the marginals were not <em>consistent under permutation</em>: the distributions differed depending on whether you considered <span class="math notranslate nohighlight">\(y^{(1)}\)</span> first or <span class="math notranslate nohighlight">\(y^{(2)}\)</span> first.
Later we’ll prove that this problem will never occur for NPs — for a fixed context set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>, the NPF predictive distributions <span class="math notranslate nohighlight">\(p(y|x;\mathcal{C})\)</span> always define a consistent stochastic process.</p>
<p>So far, we’ve only considered what happens when you fix the context set and vary the target inputs.
There is one more kind of consistency that we might expect SP predictions to satisfy: consistency among predictions with <em>different context sets</em>.
Consider two input-output pairs, <span class="math notranslate nohighlight">\((x^{(1)}, y^{(1)})\)</span> and <span class="math notranslate nohighlight">\((x^{(2)}, y^{(2)})\)</span>.
The product rule of probability tells us that the joint predictive density must satisfy</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p(y^{(1)}, y^{(2)}| x^{(1)}, x^{(2)}) &amp;= p(y^{(1)}| x^{(1)}) p(y^{(2)}| x^{(2)}, y^{(1)}, x^{(1)}) \\
&amp;= p(y^{(2)}| x^{(2)}) p(y^{(1)}| x^{(1)}, y^{(2)}, x^{(2)}).
\end{align}
\end{split}\]</div>
<p>This essentially states that the distribution over <span class="math notranslate nohighlight">\(y^{(1)}, y^{(2)}\)</span> obtained by autoregressive sampling should be independent of the order in which the sampling is performed.
Unfortunately, this is <em>not</em> guaranteed to be the case NPs, i.e., it is possible that</p>
<div class="math notranslate nohighlight">
\[
p(y^{(1)}| x^{(1)}) p(y^{(2)}| x^{(2)} ; \{x^{(1)},  y^{(1)} \} ) \neq p(y^{(2)}| x^{(2)}) p(y^{(1)}| x^{(1)} ; \{x^{(2)},  y^{(2)}\} ).
\]</div>
<p>The lack of consistency for different context sets is the reason we use the notation <span class="math notranslate nohighlight">\(p(y|x;\mathcal{C})\)</span> instead of <span class="math notranslate nohighlight">\(p(y|x,\mathcal{C})\)</span> as standard rules of probabilities cannot be used for <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.
In practice, NPs yields good predictive performance even though they can violate this consistency.</p>
</div>
<p>This point of view of NPs as modeling a mapping from a dataset to stochastic process by specifying <span class="math notranslate nohighlight">\(p(\mathbf{y}_{\mathcal{T}}| \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> for any target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> is helpful for making theoretical statements about the NPF.
It also helps us contrast the NPF with another classical machine learning method for stochastic process prediction, <em>Gaussian processes</em> (GPs), which we use mainly as a benchmark.
In contrast to GP prediction, in NPs we want to make use of the expressivity of deep neural networks in our mapping.
In order to do this, each member of the NPF has to address these questions: 1) How can we use neural networks to parameterise a map from datasets to predictive distributions over arbitrary target sets? 2) How can we learn this map?</p>
<div class="note dropdown admonition">
<p class="admonition-title">Note<span class="math notranslate nohighlight">\(\qquad\)</span>Gaussian Processes</p>
<p><a class="reference internal" href="#convlnp"><span class="std std-numref">Fig. 1</span></a> also shows the predictive mean and error-bars of the ground truth <em>Gaussian process</em> (GP) used to generate the data.
Unlike NPs, GPs require the user to specify a kernel function to model the data.
GPs are attractive due to the fact that exact prediction in GPs can be done <em>in closed form</em>.
However, this has computational complexity <span class="math notranslate nohighlight">\(\mathcal{O}(N^3)\)</span> in the dataset size, which limits the application of exact GPs to large datasets.
Many accessible introductions to GPs are available online.
Some prime examples are <a class="reference external" href="https://distill.pub/2019/visual-exploration-gaussian-processes/">Distill’s visual exploration</a>, <a class="reference external" href="http://inverseprobability.com/talks/notes/gaussian-processes.html">Neil Lawrence’s post</a>, or <a class="reference external" href="https://www.youtube.com/watch?v=NegVuuHwa8Q">David Mackay’s video lecture</a>.</p>
<p>We note that there is a close relationship between GPs and NPs.
Recall that given an appropriate kernel function <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>, and any collection of target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span>, a GP defines the following posterior predictive distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p (\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}, \mathcal{C}) &amp;=
\mathcal{N} \left( \mathbf{y}_{\mathcal{T}}; \mu_{\text{post}}, \Sigma_{\text{post}} \right), \\
\mu_{\text{post}} &amp; = K_{\mathcal{T}, \mathcal{C}} K_{\mathcal{C}, \mathcal{C}}^{-1} \mathbf{y}_{\mathcal{C}}, \\
\Sigma_{\text{post}} &amp; = K_{\mathcal{T}, \mathcal{T}} - K_{\mathcal{T}, \mathcal{C}} K_{\mathcal{C}, \mathcal{C}}^{-1} K_{\mathcal{C}, \mathcal{T}},
\end{align}
\end{split}\]</div>
<p>where we denote <span class="math notranslate nohighlight">\(K_{\mathcal{T}, \mathcal{C}}\)</span> as the matrix constructed by evaluating the kernel at the inputs of the target set with those of the context set, and similarly for <span class="math notranslate nohighlight">\(K_{\mathcal{C}, \mathcal{C}}\)</span>, <span class="math notranslate nohighlight">\(K_{\mathcal{C}, \mathcal{T}}\)</span>, and <span class="math notranslate nohighlight">\(K_{\mathcal{T}, \mathcal{T}}\)</span>.
Thus, we can think of posterior inference in GPs as a map from context sets <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> to distribution over predictive functions, just as we are considering for NPs.</p>
<p>In this tutorial, we mainly use GPs to specify simple synthetic stochastic processes for benchmarking.
We then train NPs to perform GP prediction.
Since we can obtain the <em>exact</em> GP predictive distribution in closed form, we can use GPs to test the efficacy of NPs.
It is important to remember, however, that NPs can model a much broader range of SPs than GPs can (e.g. natural images, SPs with multimodal marginals), are more computationally efficient at test time, and can learn directly from data without the need to hand-specify a kernel.</p>
</div>
</div>
</div>
<div class="section" id="parameterising-neural-processes">
<span id="parametrizing-npf"></span><h2>Parameterising Neural Processes<a class="headerlink" href="#parameterising-neural-processes" title="Permalink to this headline">¶</a></h2>
<p>Here we will discuss how to parametrise NPs.
As a reminder, there are three constraints that any NP should satisfy:</p>
<ol class="simple">
<li><p><strong>Use neural networks.</strong> The map from context set to predictive distributions should be parametrized by a neural network. We will use a subscript <span class="math notranslate nohighlight">\(\theta\)</span> to denote all the parameters of the network, <span class="math notranslate nohighlight">\(p_{\theta}(y|x; \mathcal{C})\)</span>.</p></li>
<li><p><strong>The context set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> should be treated as a set.</strong> This differs from standard vector-valued in that: i) a set may have <em>varying sizes</em>; ii) a set has no intrinsic ordering. The second point means that NPs should be <em>permutation invariant</em>, i.e., <span class="math notranslate nohighlight">\(p_{\theta}(y|x; \mathcal{C}) = p_{\theta}(y|x; \pi ( \mathcal{C})) \)</span> for any permutation operator <span class="math notranslate nohighlight">\(\pi\)</span>.</p></li>
<li><p><strong>Consistency.</strong> The resulting posterior predictive <span class="math notranslate nohighlight">\(p_{\theta}(\mathbf{y}_{\mathcal{T}}| \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> should be consistent for any <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> to ensure that NPs give rise to proper stochastic processes — see advanced dropdown above for more details.</p></li>
</ol>
<p>To satisfy these requirements, members of NPs map the context set to global representation, <span class="math notranslate nohighlight">\(R\)</span>, using a set neural network encoder <span class="math notranslate nohighlight">\(\mathrm{Enc}_{\theta}\)</span>.
Specifically, the encoder is always going to be of form <span class="math notranslate nohighlight">\(\mathrm{Enc}_{\theta}(\mathcal{C}) = \rho \left ( \sum_{c=1}^C w \phi(x^{(c)}, y^{(c)}) \right)\)</span> for appropriate <span class="math notranslate nohighlight">\(w\)</span>, <span class="math notranslate nohighlight">\(\rho\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span>.
The sum operation in the encoder is key as it ensures permutation invariance — due to the commutativity of the sum operation — and that the resulting <span class="math notranslate nohighlight">\(R\)</span> “lives” in the same space regardless of the number of context points <span class="math notranslate nohighlight">\(C\)</span>.
The encoder of various members of the NPF is theoretically well justified as we will later highlight.</p>
<p>The global representation <span class="math notranslate nohighlight">\(R\)</span> will then be used with the target input <span class="math notranslate nohighlight">\(x^{(t)}\)</span> by a decoder <span class="math notranslate nohighlight">\(\mathrm{Dec}_{\theta}\)</span> to parametrise the predictive distribution <span class="math notranslate nohighlight">\(\mathrm{Dec}_{\theta}: R,x^{(t)} \mapsto p_{\theta}(\cdot| x^{(t)}; R)\)</span>, typically the predictive distribution is Gaussian meaning that the decoder predicts a mean <span class="math notranslate nohighlight">\(\mu^{(t)}\)</span> and a variance <span class="math notranslate nohighlight">\(\sigma^{2(t)}\)</span>.
As seen in the next paragraph, the decoder of NPs will always make some factorisation assumption to ensure that the posterior predictive is consistent.</p>
<div class="note admonition">
<p class="admonition-title">Concrete Example</p>
<p>As a concrete example of what a Neural Process looks like, <a class="reference internal" href="#cnp"><span class="std std-numref">Fig. 4</span></a> shows a schematic animation of the forward pass of a <em>Conditional Neural Process</em> (CNP), the first Neural Process to be introduced.
We see that every <span class="math notranslate nohighlight">\((x, y)\)</span> pair in the context set (here with three datapoints) is passed through an MLP <span class="math notranslate nohighlight">\(e\)</span> to obtain a local encoding.
The local encodings <span class="math notranslate nohighlight">\(\{r_1, r_2, r_3\}\)</span> are then aggregated by a mean pooling <span class="math notranslate nohighlight">\(a\)</span> to a global representation <span class="math notranslate nohighlight">\(r\)</span>.
Finally, the representation <span class="math notranslate nohighlight">\(r\)</span> is fed into another MLP <span class="math notranslate nohighlight">\(d\)</span> along with the target input to yield the mean and variance of the predictive distribution of the target output <span class="math notranslate nohighlight">\(y\)</span>.
We’ll take a much more detailed look at the CNP <a class="reference internal" href="#cnp"><span class="std std-ref">later</span></a>.</p>
<div class="figure align-default" id="cnp">
<a class="reference internal image-reference" href="../_images/NPFs.gif"><img alt="Schematic representation of CNP forward pass." src="../_images/NPFs.gif" style="width: 30em;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Schematic representation of CNP forward pass taken from <a class="reference external" href="https://www.martagarnelo.com/conditional-neural-processes">Marta Garnelo</a>.</span><a class="headerlink" href="#cnp" title="Permalink to this image">¶</a></p>
</div>
</div>
<p>The NPF splits into two sub-families depending on whether or not the global representation is (used to define) a latent variable: the <em>conditional</em> Neural Process family (CNPF), and the <em>latent</em> Neural Process family (LNPF):</p>
<ul class="simple">
<li><p>In the CNPF, the predictive distribution at any set of target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> is <em>factorised</em> conditioned on <span class="math notranslate nohighlight">\(R\)</span>. That is, <span class="math notranslate nohighlight">\(p_{\theta}(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C}) = \prod_{t=1}^T p_{\theta}(y^{(t)} | x^{(t)}, R)\)</span>.</p></li>
<li><p>In the LNPF, the encoding <span class="math notranslate nohighlight">\(R\)</span> is used to define a global <em>latent variable</em> <span class="math notranslate nohighlight">\(\mathbf{z} \sim p_{\theta}(\mathbf{z} | R)\)</span>. The predictive distribution is then factorised <em>conditioned on</em> <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>. That is, <span class="math notranslate nohighlight">\(p_{\theta}(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C}) = \int \prod_{t=1}^T p_{\theta}(y^{(t)} | x^{(t)}, \mathbf{z}) p_{\theta}(\mathbf{z} | R) \, \mathrm{d}\mathbf{z}\)</span>.</p></li>
</ul>
<p>The forward pass for members of both the CNPF and LNPF is represented schematically in <a class="reference internal" href="#computational-graph-npfs"><span class="std std-numref">Fig. 5</span></a>.
For the LNPF there is an extra step of sampling the latent variable <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> in between <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(\mathrm{Dec}_{\theta}\)</span>.<a class="footnote-reference brackets" href="#det" id="id1">1</a></p>
<div class="figure align-default" id="computational-graph-npfs">
<a class="reference internal image-reference" href="text/../images/computational_graph_NPFs.svg"><img alt="high level computational graph of NPF" src="text/../images/computational_graph_NPFs.svg" width="400em" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">High level computational graph of the Neural Process Family.</span><a class="headerlink" href="#computational-graph-npfs" title="Permalink to this image">¶</a></p>
</div>
<p>As we’ll see in the following pages of this tutorial, both the CNPF and LNPF come with their specific advantages and disadvantages.
Roughly speaking, the LNPF allows us to model <em>dependencies</em> in the predictive distribution over the target set, at the cost of requiring us to approximate an intractable objective function.</p>
<p>Furthermore, even <em>within</em> each family, there are myriad choices that can be made. The most important of which is the choice of encoder.
Each of these choices will lead to neural processes with different inductive biases and capabilities.
As a teaser, we provide a very brief summary of the neural processes considered in this tutorial (This should be skimmed for now, but feel free to return here to get a quick overview once each model has been introduced. Clicking on each model brings you to the Reproducibility page which includes code for running the model):</p>
<table class="table" id="summary-npf">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Summary of different members of the Neural Process Family</span><a class="headerlink" href="#summary-npf" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head stub"><p>Model</p></th>
<th class="head"><p>Encoder</p></th>
<th class="head"><p>Spatial generalisation</p></th>
<th class="head"><p>Predictive fit quality</p></th>
<th class="head"><p>Additional Assumption</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><th class="stub"><p><a class="reference internal" href="../reproducibility/CNP.html"><span class="doc">Conditional NP</span></a><a class="footnote-reference brackets" href="#id9" id="id2">2</a>, <a class="reference internal" href="../reproducibility/LNP.html"><span class="doc">Latent NP</span></a><a class="footnote-reference brackets" href="#lnp" id="id3">3</a></p></th>
<td><p>MLP + Mean-pooling</p></td>
<td><p>No</p></td>
<td><p>Underfits</p></td>
<td><p>None</p></td>
</tr>
<tr class="row-odd"><th class="stub"><p><a class="reference internal" href="../reproducibility/AttnCNP.html"><span class="doc">Attentive CNP</span></a><a class="footnote-reference brackets" href="#attncnp" id="id4">4</a>, <a class="reference internal" href="../reproducibility/AttnLNP.html"><span class="doc">Attentive LNP</span></a><a class="footnote-reference brackets" href="#attnlnp" id="id5">5</a></p></th>
<td><p>MLP + Attention</p></td>
<td><p>No</p></td>
<td><p>Less underfitting, jagged samples</p></td>
<td><p>None</p></td>
</tr>
<tr class="row-even"><th class="stub"><p><a class="reference internal" href="../reproducibility/ConvCNP.html"><span class="doc">Convolutional CNP</span></a><a class="footnote-reference brackets" href="#convcnp" id="id6">6</a>, <a class="reference internal" href="../reproducibility/ConvLNP.html"><span class="doc">Convolutional LNP</span></a><a class="footnote-reference brackets" href="#id15" id="id7">7</a></p></th>
<td><p>SetConv + CNN + SetConv</p></td>
<td><p>Yes</p></td>
<td><p>Less underfitting, smooth samples</p></td>
<td><p>Translation Equivariance</p></td>
</tr>
</tbody>
</table>
<p>In the <a class="reference internal" href="CNPF.html"><span class="doc">CNPF</span></a> and <a class="reference internal" href="LNPF.html"><span class="doc">LNPF</span></a> pages of this tutorial, we’ll dig into the details of how all these members of the NPF are specified in practice, and what these terms really mean.
For now, we simply note the range of options and tradeoffs.
To recap, we’ve (schematically!) thought about how to parameterise a map from observed context sets <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> to predictive distributions at any target inputs <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathcal{T}}\)</span> with neural networks.
Next, we consider how to <em>train</em> such a map, i.e. how to learn the parameters <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
<div class="section" id="meta-training-in-the-npf">
<span id="meta-training"></span><h2>Meta-Training in the NPF<a class="headerlink" href="#meta-training-in-the-npf" title="Permalink to this headline">¶</a></h2>
<p>To perform <em>meta</em>-learning, we require a <em>meta</em>-dataset or a <em>dataset of datasets</em>.
In the meta-learning literature, each dataset in the meta-dataset is referred to as a <em>task</em>.
For the NPF, this means having access to many independent samples of functions from the data-generating process.
Each sampled function is then a task.
For example, we may have a large collection of audio waveforms <span class="math notranslate nohighlight">\(\mathcal{M} := \{ \mathcal{D}_i \}_{i=1}^{N_{\mathrm{tasks}}}\)</span> from different speakers.
Each of these waveforms is itself a time-series <span class="math notranslate nohighlight">\(\mathcal{D} = \{(x^{(n)}, y^{(n)})\}_{n=1}^N\)</span>, where each <span class="math notranslate nohighlight">\(x^{(n)}, y^{(n)}\)</span> is a timestamp/audio amplitude pair.
Or we might have a large collection of natural images.
Then each <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> would be a single image consisting of pixel-location/pixel-value pairs.</p>
<p>We would like to use this meta-dataset to learn how to make predictions at a target set upon observing a context set. To do this, we use an <em>episodic training procedure</em>, common in meta-learning, for the NPF. Each episode can be summarised in five steps:</p>
<ol class="simple">
<li><p>Sample a task <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> from <span class="math notranslate nohighlight">\(\{ \mathcal{D}_i \}_{i=1}^{N_{\mathrm{tasks}}}\)</span>.</p></li>
<li><p>Randomly split the task into context and target sets: <span class="math notranslate nohighlight">\(\mathcal{D} = \mathcal{C} \cup \mathcal{T}\)</span>.</p></li>
<li><p>Pass <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> through the Neural Process to obtain the predictive distribution at the target inputs, <span class="math notranslate nohighlight">\(p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span>.</p></li>
<li><p>Compute the log likelihood <span class="math notranslate nohighlight">\(\mathcal{L} = \log p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> which measures the predictive performance on the target set.<a class="footnote-reference brackets" href="#objective" id="id8">8</a>
Note that for the <span class="math notranslate nohighlight">\(LNPF\)</span>, we will have to compute an approximation or a lower bound of the log-likelihood objective.</p></li>
<li><p>Compute the gradient <span class="math notranslate nohighlight">\(\nabla_{\theta}\mathcal{L}\)</span> for stochastic gradient optimisation.</p></li>
</ol>
<p>The episodes are repeated until training converges.
Intuitively, this procedure encourages the NPF to produce predictions that fit an unseen target set, given access to only the context set.
Once meta-training is complete, if the Neural Process generalises well, it will be able to do this for brand new, unseen context sets.
To recap, we’ve seen how the NPF can be thought of as a family of meta-learning algorithms, taking entire datasets as input, and providing predictions with a single forward pass.</p>
<div class="hint dropdown admonition">
<p class="admonition-title">Advanced<span class="math notranslate nohighlight">\(\qquad\)</span>Maximum-Likelihood Training</p>
<p>To better understand the objective <span class="math notranslate nohighlight">\(\mathcal{L}(\theta ; \mathcal{C}, \mathcal{T} ) = \log p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> —which we refer to as <em>maximum-likelihood</em> training— let <span class="math notranslate nohighlight">\(p(\mathcal{D}) = p(\mathcal{C}, \mathcal{T})\)</span> be the <em>task distribution</em>, that is, the distribution from which we sample tasks in the episodic training procedure.
Then, we can express the meta-objective as an expectation over the task distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}_{p(\mathcal{D})} [\mathcal{L}(\theta ;\mathcal{C}, \mathcal{T})] &amp;= \mathbb{E}_{p(\mathcal{C} , \mathbf{x}_{\mathcal{T}} , \mathbf{y}_{\mathcal{T}} )} [\log p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})] \\
&amp;= \mathbb{E}_{p(\mathcal{C} , \mathbf{x}_{\mathcal{T}})} \left[  \mathbb{E}_{p(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}} , \mathcal{C})}  [ \log p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C}) ]  \right] \\
&amp;= - \mathbb{E}_{p(\mathcal{C} , \mathbf{x}_{\mathcal{T}})} \left[ \mathrm{KL} (p(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}} , \mathcal{C}) \| p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})  ) \right] + \mathrm{const.}
\end{align}
\end{split}\]</div>
<p>Here <span class="math notranslate nohighlight">\(\mathrm{KL}\)</span> is the KL-divergence, which is a measure of how different two distributions are, and <span class="math notranslate nohighlight">\(\mathrm{const.}\)</span> is a constant that is independent of <span class="math notranslate nohighlight">\(\theta\)</span>.
Hence we can see that maximising the meta-learning objective is equivalent to <em>minimising the task averaged KL-divergence</em> between the NPF predictive <span class="math notranslate nohighlight">\(p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}; \mathcal{C})\)</span> and the conditional distribution <span class="math notranslate nohighlight">\(p(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}} , \mathcal{C})\)</span> of the task distribution.</p>
<p>This point of view also helps us see the potential issues with maximum-likelihood training if <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> is not truly representative of the data-generating process.
For example, if all of the tasks sampled from <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> have their <span class="math notranslate nohighlight">\(x\)</span>-values bounded in a range <span class="math notranslate nohighlight">\([-a, a]\)</span>, then the expected KL will not include any contributions from <span class="math notranslate nohighlight">\(p_\theta(y| x; \mathcal{C})\)</span> when <span class="math notranslate nohighlight">\(x\)</span> is outside of that range.
Thus there is no direct incentive for the algorithm to learn a reasonable predictive distribution for that value of <span class="math notranslate nohighlight">\(x\)</span>.
To avoid this problem, we should make our meta-dataset as representative of the tasks we expect to encounter in the future as possible.</p>
<p>Another way of addressing some of these issues is to bake appropriate <em>inductive biases</em> into the Neural Process.
In the next page of this tutorial, we will see that Convolutional Neural Processes use <em>translation equivariance</em> to make accurate predictions for <span class="math notranslate nohighlight">\(x\)</span>-values outside the training range when the underlying data-generating process is stationary.</p>
</div>
<!-- ## Stochastic Process Prediction

Let's look back to {numref}`ConvLNP`. Intuitively speaking, we can think of the context points as being observations of an _unknown, random function_. The solid blue lines of the NP are then samples from the predictive distribution of that function _conditioned on_ the observed context points. In mathematical terms, a probability distribution over a random function is called a _stochastic process_. This is where the name Neural Process comes from! The NPF is a method of using neural networks to specify a distribution over a random function.

How does this relate to the description we gave earlier? In the previous section we thought of the NPF as returning a predictive distribution $p_\theta(\mathbf{y}_{\mathcal{T}} | \mathbf{x}_{\mathcal{T}}, \mathcal{C})$ given a context set $\mathcal{C}$. However, in this expression, we are free to choose $\mathbf{x}_{\mathcal{T}}$ to be any target inputs we like. If we then choose the target inputs to be _the entire real line_, we are effectively specifying a distribution over $y(x)$ _for all_ $x$ --- in other words, a random function, i.e. a stochastic process. Hence the NPF can be thought of as learning a map from observed context sets to predictive stochastic processes.

This point of view of the NPF can provide good intuition and is helpful for making theoretical statements about the NPF. It also helps us contrast the Neural Process Family with another classical machine learning method for stochastic process prediction, _Gaussian processes_.

There are, however, several technical conditions that need to be satisfied to ensure that the NPF specifies a genuinely consistent stochastic process. These conditions are prominent in the original literature on Neural Processes, and help motivate some of the design choices in the NPF, such as the factorisation assumption in the CNPF. We provide a discussion of some of these issues in the dropdown box below. However, it is possible to follow the rest of this tutorial without covering this more technical section, so **feel free to skim or skip it on a first reading**. In summary, for a fixed context set $\mathcal{C}$, the NPF predictive distribution indeed defines a single consistent predictive stochastic process, although this may not be the case for varying context sets. -->
</div>
<div class="section" id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Permalink to this headline">¶</a></h2>
<p>What tasks can a trained Neural Process be applied to?
Broadly speaking, they can be used in any situation where predictions need to be made under uncertainty.
We list a few examples here.</p>
<ul class="simple">
<li><p><strong>Regression with uncertainty</strong>. Imagine you’re writing an algorithm to predict rainfall in the future, or to forecast demand for materials in your supply chain. These are all regression tasks where a well-trained Neural Process could exploit intricate structure in the data to make predictions and provide crucial uncertainty estimates.</p></li>
<li><p><strong>Interpolating missing values</strong>. This is closely related to the previous use case. Given a corrupted image or audio signal, we may want to see what the plausible interpolations are. Moreover, if the corrupted region is large, we want to be aware of the whole range of plausible interpolations, not just one guess. If the image is, say, a medical scan, this could be crucial for decision-making.</p></li>
<li><p><strong>Active learning</strong>. In active learning, our goal is to provide accurate predictions with as few measurements as possible. This is typically done by performing measurements at points with the greatest uncertainty. A Neural Process can be used to provide these uncertainty estimates. Once the measurement is taken, the new context point can be fed back into the Neural Process, and the uncertainty estimates can be updated for the next measurement.</p></li>
<li><p><strong>Bayesian optimisation</strong>. In Bayesian optimisation, the goal is to perform black-box optimisation of an unknown function when gradient information is unavailable, and each evaluation of the objective function is expensive. Most algorithms for Bayesian optimisation rely on querying points which have high expected reward and also high uncertainty, thus trading off exploration and exploitation.</p></li>
</ul>
</div>
<div class="section" id="summary-of-npf-properties">
<h2>Summary of NPF Properties<a class="headerlink" href="#summary-of-npf-properties" title="Permalink to this headline">¶</a></h2>
<p>Would an NPF be a good fit for your machine learning problem? To summarise, we note the advantages and disadvantages of the NPF:</p>
<ul class="simple">
<li><p>✓ <strong>Fast predictions</strong> on new context sets at test time. Often, training a machine learning model on a new dataset is computationally expensive. However, meta-learning allows the NPF to incorporate information from a new context set and make predictions with a <em>single</em> forward pass. Typically the complexity will be linear or quadratic in the context set size instead of cubic as with standard Gaussian process regression.</p></li>
<li><p>✓ <strong>Well calibrated uncertainty</strong>. Often meta-learning is applied to situations where each task has only a small number of examples at test time (also known as <em>few-shot learning</em>). These are exactly the situations where we should have uncertainty in our predictions, since there are many possible ways to interpolate a context set with few points. The NPF <em>learns</em> to represent this uncertainty during episodic training.</p></li>
<li><p>✓ <strong>Data-driven expressivity</strong>. The enormous flexibility of deep learning architectures means that the NPF can learn to model very intricate predictive distributions directly from the data. The user mainly has to specify the inductive biases of the network architecture, e.g. convolutional vs attentive.</p></li>
</ul>
<p>However, these advantages come at the cost of the following disadvantages:</p>
<ul class="simple">
<li><p>✗ <strong>The need for a large dataset for meta-training</strong>. Meta-learning requires training on a large dataset of target and context points sampled from different functions, i.e., a large dataset of datasets. In some situations, a dataset of datasets may simply not be available. Furthermore, although predicting on a new context set after meta-training is fast, meta-training itself can be computationally expensive depending on the size of the network and the meta-dataset.</p></li>
<li><p>✗ <strong>Underfitting and smoothness issues</strong>. The NPF predictive distribution has been known to underfit the context set, and also sometimes to provide unusually jagged predictions for regression tasks. The sharpness and diversity of the image samples for the LNPF could also be improved. However, improvements are being made on this front, with both the attentive and convolutional variants of the NPF providing significant advances.</p></li>
</ul>
<p>In summary, we’ve taken a bird’s eye view of the Neural Process Family and seen how they specify a map from datasets to stochastic processes, and how this map can be trained via meta-learning. We’ve also seen some of their use-cases and properties. Let’s now dive into the actual architectures! In the next two pages we’ll cover everything you need to know to get started with the models in Conditional and Neural Process Families.</p>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="det"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>The general computational graph of the NPF actually has a latent variable <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>. Indeed, the CNPF may be thought of as the LNPF in the case when the latent variable <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is constrained to be deterministic (<span class="math notranslate nohighlight">\(p_{\theta}(\mathbf{z} | R)\)</span> is a Dirac delta function).</p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#garnelo2018conditional" id="id10">[GRM+18]</a>.</p>
</dd>
<dt class="label" id="lnp"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#garnelo2018neural" id="id11">[GSR+18]</a> — in this paper and elsewhere in the Neural Process literature, the authors refer to latent neural processes simply as neural processes. In this tutorial we use the term ‘neural process’ to refer to both conditional neural processes and latent neural processes. We reserve the term ‘latent neural process’ specifically for the case when there is a stochastic latent variable <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>.</p>
</dd>
<dt class="label" id="attncnp"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id12">[KMS+19]</a> — this paper only introduced the latent variable Attentive LNP, but one can easily drop the latent variable to obtain the Attentive CNP.</p>
</dd>
<dt class="label" id="attnlnp"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id13">[KMS+19]</a>.</p>
</dd>
<dt class="label" id="convcnp"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id14">[GBF+19]</a>.</p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#foong2020convnp" id="id16">[FBG+20]</a>.</p>
</dd>
<dt class="label" id="objective"><span class="brackets"><a class="fn-backref" href="#id8">8</a></span></dt>
<dd><p>During training the performance is usually measured on both the context and target set, i.e. we append the context set to the target set.</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./text"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='right-next' id="next-link" href="CNPF.html" title="next page">Conditional NPF</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois, Jonathan Gordon, ‪Andrew Foong<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>