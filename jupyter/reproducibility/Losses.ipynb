{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteria for LNPF\n",
    "\n",
    "In this notebook we will investigate the inpact of using the ML or the ELBO objective for training members of LNPF.\n",
    "We will also investigate the effect and/or need of using a lower bound for the standard deviation of the the latent variable and the posterior predictive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "\n",
    "N_THREADS = 8\n",
    "IS_FORCE_CPU = False  # Nota Bene : notebooks don't deallocate GPU memory\n",
    "\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Let's load the data, here we will only be working with Gaussian Processes from a single underlying kernel. For more details, see the {doc}`data <Datasets>` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ntbks_helpers import get_datasets_single_gp\n",
    "\n",
    "# DATASET\n",
    "gp_datasets, gp_test_datasets, gp_valid_datasets = get_datasets_single_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npf.utils.datasplit import CntxtTrgtGetter, GetRandomIndcs\n",
    "from utils.data import cntxt_trgt_collate\n",
    "\n",
    "# CONTEXT TARGET SPLIT\n",
    "get_cntxt_trgt_1d = cntxt_trgt_collate(\n",
    "    CntxtTrgtGetter(contexts_getter=GetRandomIndcs(a=0.0, b=50))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now make the model. We will make make one model for every member of LNPF. For each we will train them with both losses, with or without lower bound on the the std of the latent distribution, and with or without lower bound on the std of the predictive distribution.\n",
    "This is a total of 24 models, so we will do in a loop. Note that besides training, the same models are used as in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from npf import LNP,ConvLNP, AttnLNP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from npf.architectures import (\n",
    "    CNN,\n",
    "    MLP,\n",
    "    ResConvBlock,\n",
    "    SetConv,\n",
    "    discard_ith_arg,\n",
    "    merge_flat_input,\n",
    ")\n",
    "from utils.helpers import count_parameters\n",
    "\n",
    "R_DIM = 128\n",
    "KWARGS = dict(\n",
    "    XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=R_DIM),\n",
    "    Decoder=merge_flat_input(  # MLP takes single input but we give x and R so merge them\n",
    "        partial(MLP, n_hidden_layers=4, hidden_size=R_DIM), is_sum_merge=True,\n",
    "    ),\n",
    "    r_dim=R_DIM,\n",
    ")\n",
    "\n",
    "\n",
    "def get_std_processing_kwargs(min_sigma_pred=0.01, min_lat=None):\n",
    "    \"\"\"Function returning kwarhs for processing std\"\"\"\n",
    "    kwargs = dict(\n",
    "        p_y_scale_transformer=lambda y_scale: min_sigma_pred\n",
    "        + (1 - min_sigma_pred) * F.softplus(y_scale)\n",
    "    )\n",
    "\n",
    "    if min_lat is not None:\n",
    "        kwargs[\"q_z_scale_transformer\"] = lambda y_scale: min_lat + (\n",
    "            1 - min_lat\n",
    "        ) * F.softplus(y_scale)\n",
    "\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def get_lnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None,\n",
    "):\n",
    "\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=32 if is_mle else 1,  # going to be more expensive\n",
    "        n_z_samples_test=32,\n",
    "        XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=R_DIM),\n",
    "        Decoder=merge_flat_input(  # MLP takes single input but we give x and R so merge them\n",
    "            partial(MLP, n_hidden_layers=4, hidden_size=R_DIM), is_sum_merge=True,\n",
    "        ),\n",
    "        r_dim=R_DIM,\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        LNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "            partial(MLP, n_hidden_layers=2, hidden_size=R_DIM * 2), is_sum_merge=True,\n",
    "        ),\n",
    "        **KWARGS,\n",
    "    )\n",
    "    \n",
    "    return model_1d\n",
    "\n",
    "\n",
    "def get_attnlnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None,\n",
    "):\n",
    "\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=8 if is_mle else 1,  # going to be more expensive\n",
    "        n_z_samples_test=8,\n",
    "        r_dim=R_DIM,\n",
    "        attention=\"transformer\",\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        AttnLNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "            partial(MLP, n_hidden_layers=2, hidden_size=R_DIM), is_sum_merge=True,\n",
    "        ),\n",
    "        is_self_attn=False,\n",
    "        **KWARGS,\n",
    "    )\n",
    "\n",
    "    return model_1d\n",
    "\n",
    "\n",
    "def get_convlnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None,\n",
    "):\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=16 if is_mle else 1,  # going to be more expensive\n",
    "        n_z_samples_test=32,\n",
    "        r_dim=R_DIM,\n",
    "        Decoder=discard_ith_arg(\n",
    "            torch.nn.Linear, i=0\n",
    "        ),  # use small decoder because already went through CNN\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    CNN_KWARGS = dict(\n",
    "        ConvBlock=ResConvBlock,\n",
    "        is_chan_last=True,  # all computations are done with channel last in our code\n",
    "        n_conv_layers=2,\n",
    "        n_blocks=4,\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        ConvLNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        CNN=partial(\n",
    "            CNN,\n",
    "            Conv=torch.nn.Conv1d,\n",
    "            Normalization=torch.nn.BatchNorm1d,\n",
    "            kernel_size=19,\n",
    "            **CNN_KWARGS,\n",
    "        ),\n",
    "        density_induced=64,  # size of discretization\n",
    "        is_global=True,  # use some global representation in addition to local\n",
    "        **KWARGS,\n",
    "    )\n",
    "\n",
    "    return model_1d\n",
    "\n",
    "\n",
    "lnpf_getters = dict(LNP=get_lnp, AttnLNP=get_attnlnp, ConvLNP=get_convlnp)\n",
    "\n",
    "\n",
    "def get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB):\n",
    "    return f\"{lnpf}_ELBO{str(is_elbo)}_LatLB{str(is_lat_LB)}_SigLB{str(is_sigma_LB)}\"\n",
    "\n",
    "models = {\n",
    "    get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB): lnpf_getters[\n",
    "        lnpf\n",
    "    ](\n",
    "        is_mle=not is_elbo,\n",
    "        min_sigma_pred=0.01 if is_sigma_LB else 1e-4,\n",
    "        min_lat=None if is_lat_LB else 1e-4,\n",
    "    )\n",
    "    for lnpf in [\"LNP\", \"AttnLNP\", \"ConvLNP\"]\n",
    "    for is_elbo in [True, False]\n",
    "    for is_sigma_LB in [True, False]\n",
    "    for is_lat_LB in [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The main function for training is `train_models` which trains a dictionary of models on a dictionary of datasets and returns all the trained models.\n",
    "See its docstring for possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 60.4488 | valid loss: None | test log likelihood: -37.1932\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 123.2179 | valid loss: None | test log likelihood: -112.7289\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 75.7589 | valid loss: None | test log likelihood: -54.3272\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 84.1607 | valid loss: None | test log likelihood: -65.266\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 37.4266 | valid loss: None | test log likelihood: -42.7674\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 41.9216 | valid loss: None | test log likelihood: -46.8378\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 45.6183 | valid loss: None | test log likelihood: -50.7461\n",
      "\n",
      "--- Loading RBF_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 54.8559 | valid loss: None | test log likelihood: -59.0399\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: -166.447 | valid loss: None | test log likelihood: 153.6258\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: -160.6465 | valid loss: None | test log likelihood: 152.1176\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: -176.4192 | valid loss: None | test log likelihood: 154.917\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: -169.2222 | valid loss: None | test log likelihood: 168.5658\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: -172.1554 | valid loss: None | test log likelihood: 160.5525\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: -173.6011 | valid loss: None | test log likelihood: 157.3711\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: -185.8974 | valid loss: None | test log likelihood: 180.1441\n",
      "\n",
      "--- Loading RBF_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: -186.7489 | valid loss: None | test log likelihood: 170.8015\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 181.2939 | valid loss: None | test log likelihood: -181.2631\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 181.2944 | valid loss: None | test log likelihood: -181.2629\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 181.294 | valid loss: None | test log likelihood: -181.2589\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 181.2938 | valid loss: None | test log likelihood: -181.2617\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: -226.2634 | valid loss: None | test log likelihood: 232.0912\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: -223.9997 | valid loss: None | test log likelihood: 227.899\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: -252.7548 | valid loss: None | test log likelihood: 268.9263\n",
      "\n",
      "--- Loading RBF_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "RBF_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: -254.6531 | valid loss: None | test log likelihood: 263.1938\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 125.5136 | valid loss: None | test log likelihood: -122.6891\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 124.8491 | valid loss: None | test log likelihood: -122.1494\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 124.0944 | valid loss: None | test log likelihood: -121.9009\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 124.5481 | valid loss: None | test log likelihood: -122.0493\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 123.6635 | valid loss: None | test log likelihood: -125.1092\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 123.6465 | valid loss: None | test log likelihood: -124.7446\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 123.7328 | valid loss: None | test log likelihood: -124.85\n",
      "\n",
      "--- Loading Periodic_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 123.6948 | valid loss: None | test log likelihood: -124.6516\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 38.7724 | valid loss: None | test log likelihood: -44.8828\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: -31.0658 | valid loss: None | test log likelihood: 30.4702\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 9.5257 | valid loss: None | test log likelihood: -29.8762\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 45.8988 | valid loss: None | test log likelihood: -60.345\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 41.7642 | valid loss: None | test log likelihood: -34.7336\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 22.6952 | valid loss: None | test log likelihood: -45.3919\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: -29.4352 | valid loss: None | test log likelihood: -49.4196\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: -49.2517 | valid loss: None | test log likelihood: 38.205\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 180.6203 | valid loss: None | test log likelihood: -180.7769\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 180.6174 | valid loss: None | test log likelihood: -180.7768\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 180.6177 | valid loss: None | test log likelihood: -180.7768\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 180.618 | valid loss: None | test log likelihood: -180.7768\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: -293.7077 | valid loss: None | test log likelihood: 246.804\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: -292.0512 | valid loss: None | test log likelihood: 198.4237\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: -298.5726 | valid loss: None | test log likelihood: 254.0818\n",
      "\n",
      "--- Loading Periodic_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Periodic_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: -301.0052 | valid loss: None | test log likelihood: 32.2463\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 120.2593 | valid loss: None | test log likelihood: -105.8851\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 114.112 | valid loss: None | test log likelihood: -96.7696\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 113.3231 | valid loss: None | test log likelihood: -96.2756\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 112.9215 | valid loss: None | test log likelihood: -96.2563\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 118.7493 | valid loss: None | test log likelihood: -121.2618\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 115.1474 | valid loss: None | test log likelihood: -117.5961\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 116.6281 | valid loss: None | test log likelihood: -118.8525\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/LNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 114.7578 | valid loss: None | test log likelihood: -117.4008\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 88.0575 | valid loss: None | test log likelihood: -89.8116\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 85.3441 | valid loss: None | test log likelihood: -87.8445\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 89.5552 | valid loss: None | test log likelihood: -91.937\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 82.7164 | valid loss: None | test log likelihood: -83.8303\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 89.2093 | valid loss: None | test log likelihood: -92.0209\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 86.8299 | valid loss: None | test log likelihood: -97.3329\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 85.3126 | valid loss: None | test log likelihood: -92.0194\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 88.6315 | valid loss: None | test log likelihood: -93.8552\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 187.5635 | valid loss: None | test log likelihood: -187.6484\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 187.5614 | valid loss: None | test log likelihood: -187.6492\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 187.5616 | valid loss: None | test log likelihood: -187.6485\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOTrue_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 187.5627 | valid loss: None | test log likelihood: -187.6467\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBTrue/run_0 | best epoch: None | train loss: 85.3032 | valid loss: None | test log likelihood: -85.874\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBTrue/run_0 | best epoch: None | train loss: 85.2482 | valid loss: None | test log likelihood: -85.8776\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBTrue_SigLBFalse/run_0 | best epoch: None | train loss: 85.2625 | valid loss: None | test log likelihood: -85.9266\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/ConvLNP_ELBOFalse_LatLBFalse_SigLBFalse/run_0 | best epoch: None | train loss: 85.2805 | valid loss: None | test log likelihood: -86.1786\n"
     ]
    }
   ],
   "source": [
    "import skorch\n",
    "from npf import CNPFLoss\n",
    "from utils.ntbks_helpers import add_y_dim\n",
    "from utils.train import train_models\n",
    "\n",
    "KWARGS = dict(\n",
    "    is_retrain=False,  # whether to load precomputed model or retrain\n",
    "    criterion=CNPFLoss,  # Standard loss for conditional NPFs\n",
    "    chckpnt_dirname=\"results/pretrained/\",\n",
    "    device=None,  # use GPU if available\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    decay_lr=10,  # decrease learning rate by 10 during training\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "\n",
    "# 1D\n",
    "trainers_1d = train_models(\n",
    "    gp_datasets,\n",
    "    models,\n",
    "    test_datasets=gp_test_datasets,\n",
    "    train_split=None,  # No need for validation as the training data is generated on the fly\n",
    "    iterator_train__collate_fn=get_cntxt_trgt_1d,\n",
    "    iterator_valid__collate_fn=get_cntxt_trgt_1d,\n",
    "    max_epochs=100,\n",
    "    **KWARGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Let's visualize how well the model performs in different settings.\n",
    "\n",
    "#### GPs Dataset\n",
    "\n",
    "Let's define a plotting function that we will use in this section. We'll reuse the same function defined in {doc}`CNP notebook <CNP>`, but will use `n_samples = 20` to plot multiple posterior predictives conditioned on different latent samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.ntbks_helpers import PRETTY_RENAMER, plot_multi_posterior_samples_1d\n",
    "from utils.visualize import giffify\n",
    "\n",
    "\n",
    "def multi_posterior_gp_gif(filename, trainers, datasets, seed=123, **kwargs):\n",
    "    giffify(\n",
    "        save_filename=f\"jupyter/gifs/{filename}.gif\",\n",
    "        gen_single_fig=plot_multi_posterior_samples_1d,  # core plotting\n",
    "        sweep_parameter=\"n_cntxt\",  # param over which to sweep\n",
    "        sweep_values=[0, 2, 5, 7, 10, 15, 20, 30, 50, 100],\n",
    "        fps=0.5,  # gif speed\n",
    "        # PLOTTING KWARGS\n",
    "        trainers=trainers,\n",
    "        datasets=datasets,\n",
    "        is_plot_generator=True,  # plot underlying GP\n",
    "        is_plot_real=False,  # don't plot sampled / underlying function\n",
    "        is_plot_std=True,  # plot the predictive std\n",
    "        is_fill_generator_std=False,  # do not fill predictive of GP\n",
    "        pretty_renamer=PRETTY_RENAMER,  # pretiffy names of modulte + data\n",
    "        # Fix formatting for coherent GIF\n",
    "        plot_config_kwargs=dict(\n",
    "            set_kwargs=dict(ylim=[-3, 3]), rc={\"legend.loc\": \"upper right\"}\n",
    "        ),\n",
    "        seed=seed,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the CNP when it is trained on samples from a single GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_npf(d, lnpf, is_elbo, is_lat_LB, is_sigma_LB):\n",
    "    \"\"\"Select only data form single GP.\"\"\"\n",
    "    return {k: v for k, v in d.items() if \"/\"+get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB) in k}\n",
    "\n",
    "for lnpf in [\"LNP\", \"AttnLNP\", \"ConvLNP\"]:\n",
    "    for is_sigma_LB in [True, False]:\n",
    "        for is_lat_LB in [True, False]:\n",
    "            multi_posterior_gp_gif(\n",
    "                f\"singlegp_{lnpf}_LatLB{str(is_lat_LB)}_SigLB{str(is_sigma_LB)}\",\n",
    "                trainers=filter_npf(trainers_1d, lnpf, is_elbo=False, is_lat_LB=is_lat_LB, is_sigma_LB=is_sigma_LB),\n",
    "                trainers_compare=filter_npf(trainers_1d, lnpf, is_elbo=True, is_lat_LB=is_lat_LB, is_sigma_LB=is_sigma_LB),\n",
    "                datasets=gp_test_datasets,\n",
    "                n_samples=20,  # 20 samples from the latent\n",
    "                title=\"{model_name} | {data_name} | C={n_cntxt}\",\n",
    "                imgsize=(6, 3),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize all of these plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LNP\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "### AttnLNP\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "### ConvLNP\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "###### ADDITIONAL 1D PLOTS ######\n",
    "\n",
    "#TO Chose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
