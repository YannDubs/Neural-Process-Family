{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteria for LNPF\n",
    "\n",
    "In this notebook we will investigate the inpact of using the ML or the ELBO objective for training members of LNPF.\n",
    "We will also investigate the effect and/or need of using a lower bound for the standard deviation of the the latent variable and the posterior predictive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "\n",
    "N_THREADS = 8\n",
    "IS_FORCE_CPU = False  # Nota Bene : notebooks don't deallocate GPU memory\n",
    "\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Let's load the data, here we will only be working with Gaussian Processes from a single underlying kernel. For more details, see the {doc}`data <Datasets>` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ntbks_helpers import get_datasets_single_gp\n",
    "\n",
    "# DATASET\n",
    "gp_datasets, gp_test_datasets, gp_valid_datasets = get_datasets_single_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_datasets = {k:v for k,v in gp_datasets.items() if \"RBF\" in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npf.utils.datasplit import CntxtTrgtGetter, GetRandomIndcs\n",
    "from utils.data import cntxt_trgt_collate\n",
    "\n",
    "# CONTEXT TARGET SPLIT\n",
    "get_cntxt_trgt_1d = cntxt_trgt_collate(\n",
    "    CntxtTrgtGetter(contexts_getter=GetRandomIndcs(a=0.0, b=50))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now make the model. We will make make one model for every member of LNPF. For each we will train them with both losses, with or without lower bound on the the std of the latent distribution, and with or without lower bound on the std of the predictive distribution.\n",
    "This is a total of 24 models, so we will do in a loop. Note that besides training, the same models are used as in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from npf import LNP,ConvLNP, AttnLNP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from npf.architectures import (\n",
    "    CNN,\n",
    "    MLP,\n",
    "    ResConvBlock,\n",
    "    SetConv,\n",
    "    discard_ith_arg,\n",
    "    merge_flat_input,\n",
    ")\n",
    "from utils.helpers import count_parameters\n",
    "\n",
    "R_DIM = 128\n",
    "KWARGS = dict(\n",
    "    XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=R_DIM),\n",
    "    Decoder=merge_flat_input(  # MLP takes single input but we give x and R so merge them\n",
    "        partial(MLP, n_hidden_layers=4, hidden_size=R_DIM), is_sum_merge=True,\n",
    "    ),\n",
    "    r_dim=R_DIM,\n",
    ")\n",
    "\n",
    "\n",
    "def get_std_processing_kwargs(min_sigma_pred=0.01, min_lat=None):\n",
    "    \"\"\"Function returning kwarhs for processing std\"\"\"\n",
    "    kwargs = dict(\n",
    "        p_y_scale_transformer=lambda y_scale: min_sigma_pred\n",
    "        + (1 - min_sigma_pred) * F.softplus(y_scale)\n",
    "    )\n",
    "\n",
    "    if min_lat is not None:\n",
    "        kwargs[\"q_z_scale_transformer\"] = lambda z_scale: min_lat + (\n",
    "            1 - min_lat\n",
    "        ) * F.softplus(z_scale)\n",
    "\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def get_lnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None,\n",
    "):\n",
    "\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=32 if is_mle else 1,  # going to be more expensive with MLE\n",
    "        n_z_samples_test=32,\n",
    "        XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=R_DIM),\n",
    "        Decoder=merge_flat_input(  # MLP takes single input but we give x and R so merge them\n",
    "            partial(MLP, n_hidden_layers=4, hidden_size=R_DIM), is_sum_merge=True,\n",
    "        ),\n",
    "        r_dim=R_DIM,\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        LNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "            partial(MLP, n_hidden_layers=2, hidden_size=R_DIM * 2), is_sum_merge=True,\n",
    "        ),\n",
    "        **KWARGS,\n",
    "    )\n",
    "    \n",
    "    return model_1d\n",
    "\n",
    "\n",
    "def get_attnlnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None,\n",
    "):\n",
    "\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=8 if is_mle else 1,  # going to be more expensive\n",
    "        n_z_samples_test=8,\n",
    "        r_dim=R_DIM,\n",
    "        attention=\"transformer\",\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        AttnLNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "            partial(MLP, n_hidden_layers=2, hidden_size=R_DIM), is_sum_merge=True,\n",
    "        ),\n",
    "        is_self_attn=False,\n",
    "        **KWARGS,\n",
    "    )\n",
    "\n",
    "    return model_1d\n",
    "\n",
    "\n",
    "def get_convlnp(\n",
    "    is_mle=True, min_sigma_pred=0.01, min_lat=None, z_dim=None\n",
    "):\n",
    "    KWARGS = dict(\n",
    "        is_q_zCct=not is_mle,  # use MLE instead of ELBO\n",
    "        n_z_samples_train=16 if is_mle else 1, # going to be more expensive\n",
    "        n_z_samples_test=16, #! DEV\n",
    "        r_dim=R_DIM,\n",
    "        Decoder=discard_ith_arg(\n",
    "            torch.nn.Linear, i=0\n",
    "        ),  # use small decoder because already went through CNN\n",
    "        z_dim=16, #! NPVI requires smaller number of latent channels due to the KL\n",
    "        **get_std_processing_kwargs(min_sigma_pred=min_sigma_pred, min_lat=min_lat),\n",
    "    )\n",
    "\n",
    "    CNN_KWARGS = dict(\n",
    "        ConvBlock=ResConvBlock,\n",
    "        is_chan_last=True,  # all computations are done with channel last in our code\n",
    "        n_conv_layers=2,\n",
    "        n_blocks=4,\n",
    "    )\n",
    "\n",
    "    # 1D case\n",
    "    model_1d = partial(\n",
    "        ConvLNP,\n",
    "        x_dim=1,\n",
    "        y_dim=1,\n",
    "        CNN=partial(\n",
    "            CNN,\n",
    "            Conv=torch.nn.Conv1d,\n",
    "            Normalization=torch.nn.BatchNorm1d,\n",
    "            kernel_size=19,\n",
    "            **CNN_KWARGS,\n",
    "        ),\n",
    "        density_induced=64,  # size of discretization\n",
    "        is_global=False, #! Global representation does not work well with NPVI because KL before pooling\n",
    "        **KWARGS,\n",
    "    )\n",
    "\n",
    "    return model_1d\n",
    "\n",
    "\n",
    "lnpf_getters = dict(LNP=get_lnp, AttnLNP=get_attnlnp, ConvLNP=get_convlnp)\n",
    "\n",
    "\n",
    "def get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB):\n",
    "    return f\"{lnpf}_ELBO{str(is_elbo)}_LatLB{str(is_lat_LB)}_SigLB{str(is_sigma_LB)}\"\n",
    "\n",
    "models = {\n",
    "    get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB): lnpf_getters[\n",
    "        lnpf\n",
    "    ](\n",
    "        is_mle=not is_elbo,\n",
    "        min_sigma_pred=0.01 if is_sigma_LB else 1e-4,\n",
    "        min_lat=None if is_lat_LB else 1e-4,\n",
    "    )\n",
    "    for lnpf in [\"LNP\"] \n",
    "    for is_elbo in [True, False]\n",
    "    for is_sigma_LB in [True]\n",
    "    for is_lat_LB in [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The main function for training is `train_models` which trains a dictionary of models on a dictionary of datasets and returns all the trained models.\n",
    "See its docstring for possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training RBF_Kernel/LNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f2306397254e07b01398b0dcad72cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1563.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                    \u001b[0;34mf\"Features during training should be in [-1,1]. {X_cntxt.min()} <= X_cntxt <= {X_cntxt.max()} ; {X_trgt.min()} <= X_trgt <= {X_trgt.max()}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.reshaper_z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** torch.nn.modules.module.ModuleAttributeError: 'LNP' object has no attribute 'reshaper_z'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.z_dim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.r_dim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.encoded_path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'latent'\n"
     ]
    }
   ],
   "source": [
    "import skorch\n",
    "from npf import NLLLossLNPF, ELBOLossLNPF\n",
    "from utils.ntbks_helpers import add_y_dim\n",
    "from utils.train import train_models\n",
    "\n",
    "KWARGS = dict(\n",
    "    is_retrain=True, # whether to load precomputed model or retrain\n",
    "    chckpnt_dirname=\"results/pretrained/\",\n",
    "    device=None,  # use GPU if available\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    decay_lr=10,  # decrease learning rate by 10 during training\n",
    "    seed=123,\n",
    "    #test_datasets=gp_test_datasets,\n",
    "    train_split=None,  # No need for validation as the training data is generated on the fly\n",
    "    iterator_train__collate_fn=get_cntxt_trgt_1d,\n",
    "    iterator_valid__collate_fn=get_cntxt_trgt_1d,\n",
    "    max_epochs=100,\n",
    ")\n",
    "\n",
    "# NPVI\n",
    "trainers_1d_NPVI = train_models(\n",
    "    gp_datasets,\n",
    "    {k:v for k,v in models.items() if \"ELBOTrue\" in k},\n",
    "    criterion=ELBOLossLNPF,  # NPVI\n",
    "    is_continue_train=True,\n",
    "    **KWARGS\n",
    ")\n",
    "\n",
    "#NPML\n",
    "trainers_1d_NPML = train_models(\n",
    "    gp_datasets,\n",
    "    {k:v for k,v in models.items() if \"ELBOTrue\" not in k},\n",
    "    criterion=NLLLossLNPF,  # NPML\n",
    "    **KWARGS\n",
    ")\n",
    "\n",
    "\n",
    "trainers_1d = {**trainers_1d_NPML, **trainers_1d_NPVI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Let's visualize how well the model performs in different settings.\n",
    "\n",
    "#### GPs Dataset\n",
    "\n",
    "Let's define a plotting function that we will use in this section. We'll reuse the same function defined in {doc}`CNP notebook <CNP>`, but will use `n_samples = 20` to plot multiple posterior predictives conditioned on different latent samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ntbks_helpers import PRETTY_RENAMER, plot_multi_posterior_samples_1d\n",
    "from utils.visualize import giffify\n",
    "\n",
    "\n",
    "def multi_posterior_gp_gif(filename, trainers, datasets, seed=1234, **kwargs):\n",
    "    giffify(\n",
    "        save_filename=f\"jupyter/gifs/{filename}.gif\",\n",
    "        gen_single_fig=plot_multi_posterior_samples_1d,  # core plotting\n",
    "        sweep_parameter=\"n_cntxt\",  # param over which to sweep\n",
    "        sweep_values=[0, 2, 5, 7, 10, 15, 20, 30, 50, 100],\n",
    "        fps=0.5,  # gif speed\n",
    "        # PLOTTING KWARGS\n",
    "        trainers=trainers,\n",
    "        datasets=datasets,\n",
    "        is_plot_generator=True,  # plot underlying GP\n",
    "        is_plot_real=False,  # don't plot sampled / underlying function\n",
    "        is_plot_std=True,  # plot the predictive std\n",
    "        is_fill_generator_std=False,  # do not fill predictive of GP\n",
    "        pretty_renamer=PRETTY_RENAMER,  # pretiffy names of modulte + data\n",
    "        # Fix formatting for coherent GIF\n",
    "        plot_config_kwargs=dict(\n",
    "            set_kwargs=dict(ylim=[-3, 3]), rc={\"legend.loc\": \"upper right\"}\n",
    "        ),\n",
    "        seed=seed,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the CNP when it is trained on samples from a single GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(1, 0, 1))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_trgt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9922],\n",
      "         [-0.9907],\n",
      "         [-0.9861],\n",
      "         [-0.9781],\n",
      "         [-0.9767],\n",
      "         [-0.9767],\n",
      "         [-0.9711],\n",
      "         [-0.9673],\n",
      "         [-0.9670],\n",
      "         [-0.9615],\n",
      "         [-0.9612],\n",
      "         [-0.9421],\n",
      "         [-0.9350],\n",
      "         [-0.9260],\n",
      "         [-0.9187],\n",
      "         [-0.9170],\n",
      "         [-0.9074],\n",
      "         [-0.8965],\n",
      "         [-0.8883],\n",
      "         [-0.8801],\n",
      "         [-0.8753],\n",
      "         [-0.8647],\n",
      "         [-0.8639],\n",
      "         [-0.8595],\n",
      "         [-0.8552],\n",
      "         [-0.8552],\n",
      "         [-0.8549],\n",
      "         [-0.8503],\n",
      "         [-0.8403],\n",
      "         [-0.8368],\n",
      "         [-0.8337],\n",
      "         [-0.8243],\n",
      "         [-0.8197],\n",
      "         [-0.8160],\n",
      "         [-0.8107],\n",
      "         [-0.8085],\n",
      "         [-0.8038],\n",
      "         [-0.7900],\n",
      "         [-0.7868],\n",
      "         [-0.7757],\n",
      "         [-0.7752],\n",
      "         [-0.7707],\n",
      "         [-0.7646],\n",
      "         [-0.7509],\n",
      "         [-0.7502],\n",
      "         [-0.7458],\n",
      "         [-0.7434],\n",
      "         [-0.7326],\n",
      "         [-0.7317],\n",
      "         [-0.7309],\n",
      "         [-0.7188],\n",
      "         [-0.7143],\n",
      "         [-0.7089],\n",
      "         [-0.6989],\n",
      "         [-0.6930],\n",
      "         [-0.6921],\n",
      "         [-0.6911],\n",
      "         [-0.6847],\n",
      "         [-0.6833],\n",
      "         [-0.6785],\n",
      "         [-0.6654],\n",
      "         [-0.6582],\n",
      "         [-0.6527],\n",
      "         [-0.6446],\n",
      "         [-0.6430],\n",
      "         [-0.6411],\n",
      "         [-0.6297],\n",
      "         [-0.6239],\n",
      "         [-0.6233],\n",
      "         [-0.6159],\n",
      "         [-0.6156],\n",
      "         [-0.6139],\n",
      "         [-0.5978],\n",
      "         [-0.5977],\n",
      "         [-0.5846],\n",
      "         [-0.5764],\n",
      "         [-0.5620],\n",
      "         [-0.5595],\n",
      "         [-0.5555],\n",
      "         [-0.5543],\n",
      "         [-0.5458],\n",
      "         [-0.5388],\n",
      "         [-0.5302],\n",
      "         [-0.5274],\n",
      "         [-0.5251],\n",
      "         [-0.5096],\n",
      "         [-0.5071],\n",
      "         [-0.5033],\n",
      "         [-0.5014],\n",
      "         [-0.4934],\n",
      "         [-0.4896],\n",
      "         [-0.4837],\n",
      "         [-0.4835],\n",
      "         [-0.4760],\n",
      "         [-0.4621],\n",
      "         [-0.4581],\n",
      "         [-0.4489],\n",
      "         [-0.4468],\n",
      "         [-0.4449],\n",
      "         [-0.4424],\n",
      "         [-0.4389],\n",
      "         [-0.4355],\n",
      "         [-0.4312],\n",
      "         [-0.4220],\n",
      "         [-0.4203],\n",
      "         [-0.4192],\n",
      "         [-0.4174],\n",
      "         [-0.4099],\n",
      "         [-0.3997],\n",
      "         [-0.3929],\n",
      "         [-0.3926],\n",
      "         [-0.3911],\n",
      "         [-0.3880],\n",
      "         [-0.3839],\n",
      "         [-0.3834],\n",
      "         [-0.3697],\n",
      "         [-0.3626],\n",
      "         [-0.3618],\n",
      "         [-0.3538],\n",
      "         [-0.3494],\n",
      "         [-0.3386],\n",
      "         [-0.3368],\n",
      "         [-0.3332],\n",
      "         [-0.3305],\n",
      "         [-0.3297],\n",
      "         [-0.3231],\n",
      "         [-0.3223],\n",
      "         [-0.3219],\n",
      "         [-0.3156],\n",
      "         [-0.3067],\n",
      "         [-0.3015],\n",
      "         [-0.2718],\n",
      "         [-0.2693],\n",
      "         [-0.2689],\n",
      "         [-0.2688],\n",
      "         [-0.2641],\n",
      "         [-0.2620],\n",
      "         [-0.2545],\n",
      "         [-0.2526],\n",
      "         [-0.2498],\n",
      "         [-0.2479],\n",
      "         [-0.2258],\n",
      "         [-0.2220],\n",
      "         [-0.2151],\n",
      "         [-0.2061],\n",
      "         [-0.2059],\n",
      "         [-0.2014],\n",
      "         [-0.1949],\n",
      "         [-0.1930],\n",
      "         [-0.1889],\n",
      "         [-0.1864],\n",
      "         [-0.1750],\n",
      "         [-0.1719],\n",
      "         [-0.1653],\n",
      "         [-0.1644],\n",
      "         [-0.1614],\n",
      "         [-0.1571],\n",
      "         [-0.1481],\n",
      "         [-0.1475],\n",
      "         [-0.1449],\n",
      "         [-0.1443],\n",
      "         [-0.1380],\n",
      "         [-0.1362],\n",
      "         [-0.1313],\n",
      "         [-0.1291],\n",
      "         [-0.1287],\n",
      "         [-0.1244],\n",
      "         [-0.1195],\n",
      "         [-0.1136],\n",
      "         [-0.1121],\n",
      "         [-0.1088],\n",
      "         [-0.1065],\n",
      "         [-0.1047],\n",
      "         [-0.1032],\n",
      "         [-0.1026],\n",
      "         [-0.0955],\n",
      "         [-0.0901],\n",
      "         [-0.0860],\n",
      "         [-0.0853],\n",
      "         [-0.0799],\n",
      "         [-0.0790],\n",
      "         [-0.0678],\n",
      "         [-0.0637],\n",
      "         [-0.0631],\n",
      "         [-0.0431],\n",
      "         [-0.0400],\n",
      "         [-0.0390],\n",
      "         [-0.0374],\n",
      "         [-0.0263],\n",
      "         [-0.0208],\n",
      "         [-0.0044],\n",
      "         [-0.0041],\n",
      "         [-0.0037],\n",
      "         [-0.0011],\n",
      "         [ 0.0126],\n",
      "         [ 0.0302],\n",
      "         [ 0.0339],\n",
      "         [ 0.0379],\n",
      "         [ 0.0381],\n",
      "         [ 0.0382],\n",
      "         [ 0.0542],\n",
      "         [ 0.0640],\n",
      "         [ 0.0701],\n",
      "         [ 0.0727],\n",
      "         [ 0.0762],\n",
      "         [ 0.0852],\n",
      "         [ 0.0938],\n",
      "         [ 0.0987],\n",
      "         [ 0.1133],\n",
      "         [ 0.1193],\n",
      "         [ 0.1229],\n",
      "         [ 0.1236],\n",
      "         [ 0.1326],\n",
      "         [ 0.1383],\n",
      "         [ 0.1404],\n",
      "         [ 0.1433],\n",
      "         [ 0.1473],\n",
      "         [ 0.1483],\n",
      "         [ 0.1483],\n",
      "         [ 0.1514],\n",
      "         [ 0.1538],\n",
      "         [ 0.1549],\n",
      "         [ 0.1627],\n",
      "         [ 0.1654],\n",
      "         [ 0.1660],\n",
      "         [ 0.1703],\n",
      "         [ 0.1769],\n",
      "         [ 0.1790],\n",
      "         [ 0.1864],\n",
      "         [ 0.2012],\n",
      "         [ 0.2022],\n",
      "         [ 0.2036],\n",
      "         [ 0.2039],\n",
      "         [ 0.2113],\n",
      "         [ 0.2158],\n",
      "         [ 0.2203],\n",
      "         [ 0.2221],\n",
      "         [ 0.2303],\n",
      "         [ 0.2420],\n",
      "         [ 0.2496],\n",
      "         [ 0.2514],\n",
      "         [ 0.2552],\n",
      "         [ 0.2614],\n",
      "         [ 0.2686],\n",
      "         [ 0.2716],\n",
      "         [ 0.2728],\n",
      "         [ 0.2754],\n",
      "         [ 0.2764],\n",
      "         [ 0.2852],\n",
      "         [ 0.2881],\n",
      "         [ 0.2882],\n",
      "         [ 0.2915],\n",
      "         [ 0.3009],\n",
      "         [ 0.3024],\n",
      "         [ 0.3131],\n",
      "         [ 0.3136],\n",
      "         [ 0.3145],\n",
      "         [ 0.3163],\n",
      "         [ 0.3227],\n",
      "         [ 0.3259],\n",
      "         [ 0.3273],\n",
      "         [ 0.3289],\n",
      "         [ 0.3303],\n",
      "         [ 0.3348],\n",
      "         [ 0.3458],\n",
      "         [ 0.3541],\n",
      "         [ 0.3560],\n",
      "         [ 0.3574],\n",
      "         [ 0.3625],\n",
      "         [ 0.3654],\n",
      "         [ 0.3664],\n",
      "         [ 0.3727],\n",
      "         [ 0.3755],\n",
      "         [ 0.3871],\n",
      "         [ 0.3905],\n",
      "         [ 0.3918],\n",
      "         [ 0.3961],\n",
      "         [ 0.3979],\n",
      "         [ 0.3988],\n",
      "         [ 0.4035],\n",
      "         [ 0.4063],\n",
      "         [ 0.4126],\n",
      "         [ 0.4137],\n",
      "         [ 0.4150],\n",
      "         [ 0.4269],\n",
      "         [ 0.4277],\n",
      "         [ 0.4375],\n",
      "         [ 0.4440],\n",
      "         [ 0.4523],\n",
      "         [ 0.4662],\n",
      "         [ 0.4849],\n",
      "         [ 0.4991],\n",
      "         [ 0.5099],\n",
      "         [ 0.5127],\n",
      "         [ 0.5156],\n",
      "         [ 0.5166],\n",
      "         [ 0.5183],\n",
      "         [ 0.5235],\n",
      "         [ 0.5250],\n",
      "         [ 0.5268],\n",
      "         [ 0.5271],\n",
      "         [ 0.5346],\n",
      "         [ 0.5350],\n",
      "         [ 0.5435],\n",
      "         [ 0.5463],\n",
      "         [ 0.5490],\n",
      "         [ 0.5491],\n",
      "         [ 0.5690],\n",
      "         [ 0.5720],\n",
      "         [ 0.5835],\n",
      "         [ 0.5847],\n",
      "         [ 0.5878],\n",
      "         [ 0.5878],\n",
      "         [ 0.5909],\n",
      "         [ 0.5972],\n",
      "         [ 0.5992],\n",
      "         [ 0.6033],\n",
      "         [ 0.6116],\n",
      "         [ 0.6173],\n",
      "         [ 0.6180],\n",
      "         [ 0.6262],\n",
      "         [ 0.6350],\n",
      "         [ 0.6367],\n",
      "         [ 0.6491],\n",
      "         [ 0.6578],\n",
      "         [ 0.6681],\n",
      "         [ 0.6760],\n",
      "         [ 0.6779],\n",
      "         [ 0.6821],\n",
      "         [ 0.6939],\n",
      "         [ 0.6977],\n",
      "         [ 0.7024],\n",
      "         [ 0.7095],\n",
      "         [ 0.7232],\n",
      "         [ 0.7382],\n",
      "         [ 0.7427],\n",
      "         [ 0.7461],\n",
      "         [ 0.7522],\n",
      "         [ 0.7555],\n",
      "         [ 0.7565],\n",
      "         [ 0.7587],\n",
      "         [ 0.7652],\n",
      "         [ 0.7688],\n",
      "         [ 0.7772],\n",
      "         [ 0.7882],\n",
      "         [ 0.7891],\n",
      "         [ 0.7947],\n",
      "         [ 0.8059],\n",
      "         [ 0.8086],\n",
      "         [ 0.8089],\n",
      "         [ 0.8133],\n",
      "         [ 0.8156],\n",
      "         [ 0.8158],\n",
      "         [ 0.8174],\n",
      "         [ 0.8302],\n",
      "         [ 0.8304],\n",
      "         [ 0.8336],\n",
      "         [ 0.8364],\n",
      "         [ 0.8413],\n",
      "         [ 0.8417],\n",
      "         [ 0.8651],\n",
      "         [ 0.8665],\n",
      "         [ 0.8806],\n",
      "         [ 0.8958],\n",
      "         [ 0.9018],\n",
      "         [ 0.9028],\n",
      "         [ 0.9053],\n",
      "         [ 0.9082],\n",
      "         [ 0.9128],\n",
      "         [ 0.9136],\n",
      "         [ 0.9356],\n",
      "         [ 0.9414],\n",
      "         [ 0.9468],\n",
      "         [ 0.9476],\n",
      "         [ 0.9495],\n",
      "         [ 0.9672],\n",
      "         [ 0.9677],\n",
      "         [ 0.9678],\n",
      "         [ 0.9845],\n",
      "         [ 0.9851],\n",
      "         [ 0.9881],\n",
      "         [ 0.9889],\n",
      "         [ 0.9929],\n",
      "         [ 0.9946]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(1, 0, 1))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110],\n",
      "         [-0.7904],\n",
      "         [-0.0267]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110],\n",
      "         [-0.7904],\n",
      "         [-0.0267]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110],\n",
      "         [-0.7904],\n",
      "         [-0.0267]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m(244)\u001b[0;36m_validate_inputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    242 \u001b[0;31m        \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 244 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    246 \u001b[0;31m                raise ValueError(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_cntxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3275],\n",
      "         [ 0.8921],\n",
      "         [ 0.5115],\n",
      "         [-0.7023],\n",
      "         [-0.6110],\n",
      "         [-0.7904],\n",
      "         [-0.0267],\n",
      "         [-0.1213],\n",
      "         [-0.9772],\n",
      "         [ 0.7362]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_trgt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9965],\n",
      "         [-0.9962],\n",
      "         [-0.9854],\n",
      "         [-0.9833],\n",
      "         [-0.9822],\n",
      "         [-0.9807],\n",
      "         [-0.9780],\n",
      "         [-0.9772],\n",
      "         [-0.9715],\n",
      "         [-0.9714],\n",
      "         [-0.9657],\n",
      "         [-0.9656],\n",
      "         [-0.9607],\n",
      "         [-0.9585],\n",
      "         [-0.9575],\n",
      "         [-0.9454],\n",
      "         [-0.9426],\n",
      "         [-0.9378],\n",
      "         [-0.9335],\n",
      "         [-0.9315],\n",
      "         [-0.9289],\n",
      "         [-0.9233],\n",
      "         [-0.9194],\n",
      "         [-0.9056],\n",
      "         [-0.9035],\n",
      "         [-0.9008],\n",
      "         [-0.8991],\n",
      "         [-0.8939],\n",
      "         [-0.8934],\n",
      "         [-0.8847],\n",
      "         [-0.8803],\n",
      "         [-0.8779],\n",
      "         [-0.8757],\n",
      "         [-0.8714],\n",
      "         [-0.8668],\n",
      "         [-0.8541],\n",
      "         [-0.8457],\n",
      "         [-0.8396],\n",
      "         [-0.8395],\n",
      "         [-0.8269],\n",
      "         [-0.8179],\n",
      "         [-0.8043],\n",
      "         [-0.8018],\n",
      "         [-0.7904],\n",
      "         [-0.7823],\n",
      "         [-0.7781],\n",
      "         [-0.7633],\n",
      "         [-0.7581],\n",
      "         [-0.7558],\n",
      "         [-0.7510],\n",
      "         [-0.7358],\n",
      "         [-0.7357],\n",
      "         [-0.7277],\n",
      "         [-0.7236],\n",
      "         [-0.7193],\n",
      "         [-0.7145],\n",
      "         [-0.7030],\n",
      "         [-0.7023],\n",
      "         [-0.6912],\n",
      "         [-0.6848],\n",
      "         [-0.6837],\n",
      "         [-0.6817],\n",
      "         [-0.6814],\n",
      "         [-0.6766],\n",
      "         [-0.6756],\n",
      "         [-0.6594],\n",
      "         [-0.6539],\n",
      "         [-0.6480],\n",
      "         [-0.6451],\n",
      "         [-0.6243],\n",
      "         [-0.6227],\n",
      "         [-0.6188],\n",
      "         [-0.6119],\n",
      "         [-0.6110],\n",
      "         [-0.6069],\n",
      "         [-0.6030],\n",
      "         [-0.5862],\n",
      "         [-0.5768],\n",
      "         [-0.5667],\n",
      "         [-0.5625],\n",
      "         [-0.5615],\n",
      "         [-0.5576],\n",
      "         [-0.5564],\n",
      "         [-0.5476],\n",
      "         [-0.5438],\n",
      "         [-0.5434],\n",
      "         [-0.5428],\n",
      "         [-0.5424],\n",
      "         [-0.5424],\n",
      "         [-0.5367],\n",
      "         [-0.5304],\n",
      "         [-0.5289],\n",
      "         [-0.5196],\n",
      "         [-0.5155],\n",
      "         [-0.5070],\n",
      "         [-0.5055],\n",
      "         [-0.5013],\n",
      "         [-0.5013],\n",
      "         [-0.4942],\n",
      "         [-0.4933],\n",
      "         [-0.4928],\n",
      "         [-0.4885],\n",
      "         [-0.4869],\n",
      "         [-0.4844],\n",
      "         [-0.4820],\n",
      "         [-0.4808],\n",
      "         [-0.4664],\n",
      "         [-0.4651],\n",
      "         [-0.4632],\n",
      "         [-0.4541],\n",
      "         [-0.4495],\n",
      "         [-0.4476],\n",
      "         [-0.4437],\n",
      "         [-0.4373],\n",
      "         [-0.4260],\n",
      "         [-0.4211],\n",
      "         [-0.4205],\n",
      "         [-0.4196],\n",
      "         [-0.4190],\n",
      "         [-0.4103],\n",
      "         [-0.3971],\n",
      "         [-0.3958],\n",
      "         [-0.3948],\n",
      "         [-0.3929],\n",
      "         [-0.3907],\n",
      "         [-0.3868],\n",
      "         [-0.3847],\n",
      "         [-0.3801],\n",
      "         [-0.3784],\n",
      "         [-0.3699],\n",
      "         [-0.3682],\n",
      "         [-0.3649],\n",
      "         [-0.3616],\n",
      "         [-0.3594],\n",
      "         [-0.3557],\n",
      "         [-0.3554],\n",
      "         [-0.3509],\n",
      "         [-0.3294],\n",
      "         [-0.3275],\n",
      "         [-0.3239],\n",
      "         [-0.3232],\n",
      "         [-0.3207],\n",
      "         [-0.3148],\n",
      "         [-0.3085],\n",
      "         [-0.3065],\n",
      "         [-0.2962],\n",
      "         [-0.2926],\n",
      "         [-0.2888],\n",
      "         [-0.2836],\n",
      "         [-0.2744],\n",
      "         [-0.2743],\n",
      "         [-0.2734],\n",
      "         [-0.2728],\n",
      "         [-0.2622],\n",
      "         [-0.2600],\n",
      "         [-0.2593],\n",
      "         [-0.2508],\n",
      "         [-0.2399],\n",
      "         [-0.2208],\n",
      "         [-0.2143],\n",
      "         [-0.2135],\n",
      "         [-0.2087],\n",
      "         [-0.2042],\n",
      "         [-0.2032],\n",
      "         [-0.2029],\n",
      "         [-0.1959],\n",
      "         [-0.1887],\n",
      "         [-0.1830],\n",
      "         [-0.1741],\n",
      "         [-0.1662],\n",
      "         [-0.1494],\n",
      "         [-0.1458],\n",
      "         [-0.1435],\n",
      "         [-0.1421],\n",
      "         [-0.1354],\n",
      "         [-0.1331],\n",
      "         [-0.1315],\n",
      "         [-0.1314],\n",
      "         [-0.1305],\n",
      "         [-0.1215],\n",
      "         [-0.1213],\n",
      "         [-0.1212],\n",
      "         [-0.1129],\n",
      "         [-0.1077],\n",
      "         [-0.0938],\n",
      "         [-0.0938],\n",
      "         [-0.0931],\n",
      "         [-0.0931],\n",
      "         [-0.0813],\n",
      "         [-0.0755],\n",
      "         [-0.0671],\n",
      "         [-0.0554],\n",
      "         [-0.0505],\n",
      "         [-0.0504],\n",
      "         [-0.0465],\n",
      "         [-0.0465],\n",
      "         [-0.0388],\n",
      "         [-0.0292],\n",
      "         [-0.0267],\n",
      "         [-0.0206],\n",
      "         [-0.0105],\n",
      "         [-0.0093],\n",
      "         [ 0.0018],\n",
      "         [ 0.0109],\n",
      "         [ 0.0197],\n",
      "         [ 0.0220],\n",
      "         [ 0.0310],\n",
      "         [ 0.0321],\n",
      "         [ 0.0334],\n",
      "         [ 0.0434],\n",
      "         [ 0.0560],\n",
      "         [ 0.0595],\n",
      "         [ 0.0640],\n",
      "         [ 0.0721],\n",
      "         [ 0.0734],\n",
      "         [ 0.0760],\n",
      "         [ 0.0841],\n",
      "         [ 0.0876],\n",
      "         [ 0.1000],\n",
      "         [ 0.1105],\n",
      "         [ 0.1189],\n",
      "         [ 0.1203],\n",
      "         [ 0.1216],\n",
      "         [ 0.1284],\n",
      "         [ 0.1303],\n",
      "         [ 0.1407],\n",
      "         [ 0.1439],\n",
      "         [ 0.1445],\n",
      "         [ 0.1449],\n",
      "         [ 0.1492],\n",
      "         [ 0.1510],\n",
      "         [ 0.1535],\n",
      "         [ 0.1596],\n",
      "         [ 0.1620],\n",
      "         [ 0.1735],\n",
      "         [ 0.1772],\n",
      "         [ 0.1775],\n",
      "         [ 0.1799],\n",
      "         [ 0.1827],\n",
      "         [ 0.1995],\n",
      "         [ 0.2018],\n",
      "         [ 0.2035],\n",
      "         [ 0.2115],\n",
      "         [ 0.2250],\n",
      "         [ 0.2363],\n",
      "         [ 0.2416],\n",
      "         [ 0.2488],\n",
      "         [ 0.2534],\n",
      "         [ 0.2568],\n",
      "         [ 0.2691],\n",
      "         [ 0.2698],\n",
      "         [ 0.2703],\n",
      "         [ 0.2796],\n",
      "         [ 0.2815],\n",
      "         [ 0.2822],\n",
      "         [ 0.2853],\n",
      "         [ 0.2898],\n",
      "         [ 0.2927],\n",
      "         [ 0.2931],\n",
      "         [ 0.2939],\n",
      "         [ 0.2982],\n",
      "         [ 0.3063],\n",
      "         [ 0.3097],\n",
      "         [ 0.3232],\n",
      "         [ 0.3317],\n",
      "         [ 0.3363],\n",
      "         [ 0.3456],\n",
      "         [ 0.3477],\n",
      "         [ 0.3521],\n",
      "         [ 0.3552],\n",
      "         [ 0.3741],\n",
      "         [ 0.3786],\n",
      "         [ 0.3787],\n",
      "         [ 0.3803],\n",
      "         [ 0.3830],\n",
      "         [ 0.3913],\n",
      "         [ 0.3923],\n",
      "         [ 0.3970],\n",
      "         [ 0.4026],\n",
      "         [ 0.4063],\n",
      "         [ 0.4095],\n",
      "         [ 0.4168],\n",
      "         [ 0.4174],\n",
      "         [ 0.4219],\n",
      "         [ 0.4308],\n",
      "         [ 0.4312],\n",
      "         [ 0.4327],\n",
      "         [ 0.4439],\n",
      "         [ 0.4561],\n",
      "         [ 0.4575],\n",
      "         [ 0.4580],\n",
      "         [ 0.4668],\n",
      "         [ 0.4678],\n",
      "         [ 0.4679],\n",
      "         [ 0.4679],\n",
      "         [ 0.4720],\n",
      "         [ 0.4726],\n",
      "         [ 0.4775],\n",
      "         [ 0.4781],\n",
      "         [ 0.5115],\n",
      "         [ 0.5209],\n",
      "         [ 0.5259],\n",
      "         [ 0.5363],\n",
      "         [ 0.5367],\n",
      "         [ 0.5454],\n",
      "         [ 0.5606],\n",
      "         [ 0.5683],\n",
      "         [ 0.5784],\n",
      "         [ 0.5795],\n",
      "         [ 0.5849],\n",
      "         [ 0.5873],\n",
      "         [ 0.5878],\n",
      "         [ 0.5979],\n",
      "         [ 0.6010],\n",
      "         [ 0.6041],\n",
      "         [ 0.6089],\n",
      "         [ 0.6151],\n",
      "         [ 0.6153],\n",
      "         [ 0.6267],\n",
      "         [ 0.6296],\n",
      "         [ 0.6297],\n",
      "         [ 0.6379],\n",
      "         [ 0.6400],\n",
      "         [ 0.6407],\n",
      "         [ 0.6446],\n",
      "         [ 0.6446],\n",
      "         [ 0.6562],\n",
      "         [ 0.6568],\n",
      "         [ 0.6688],\n",
      "         [ 0.6712],\n",
      "         [ 0.6718],\n",
      "         [ 0.6752],\n",
      "         [ 0.6809],\n",
      "         [ 0.6978],\n",
      "         [ 0.6999],\n",
      "         [ 0.7094],\n",
      "         [ 0.7215],\n",
      "         [ 0.7284],\n",
      "         [ 0.7285],\n",
      "         [ 0.7362],\n",
      "         [ 0.7491],\n",
      "         [ 0.7586],\n",
      "         [ 0.7605],\n",
      "         [ 0.7745],\n",
      "         [ 0.8020],\n",
      "         [ 0.8077],\n",
      "         [ 0.8095],\n",
      "         [ 0.8106],\n",
      "         [ 0.8113],\n",
      "         [ 0.8159],\n",
      "         [ 0.8337],\n",
      "         [ 0.8459],\n",
      "         [ 0.8521],\n",
      "         [ 0.8561],\n",
      "         [ 0.8564],\n",
      "         [ 0.8569],\n",
      "         [ 0.8580],\n",
      "         [ 0.8608],\n",
      "         [ 0.8795],\n",
      "         [ 0.8824],\n",
      "         [ 0.8851],\n",
      "         [ 0.8890],\n",
      "         [ 0.8921],\n",
      "         [ 0.8940],\n",
      "         [ 0.8966],\n",
      "         [ 0.9057],\n",
      "         [ 0.9101],\n",
      "         [ 0.9114],\n",
      "         [ 0.9157],\n",
      "         [ 0.9208],\n",
      "         [ 0.9310],\n",
      "         [ 0.9326],\n",
      "         [ 0.9335],\n",
      "         [ 0.9428],\n",
      "         [ 0.9492],\n",
      "         [ 0.9586],\n",
      "         [ 0.9589],\n",
      "         [ 0.9680],\n",
      "         [ 0.9710],\n",
      "         [ 0.9760],\n",
      "         [ 0.9762],\n",
      "         [ 0.9833],\n",
      "         [ 0.9901],\n",
      "         [ 0.9927]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2d73b6921062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mis_sigma_LB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mis_lat_LB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             multi_posterior_gp_gif(\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0;34mf\"test_singlegp_{lnpf}_LatLB{str(is_lat_LB)}_SigLB{str(is_sigma_LB)}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mtrainers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_npf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainers_1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnpf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_elbo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_lat_LB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lat_LB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sigma_LB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_sigma_LB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-585666296566>\u001b[0m in \u001b[0;36mmulti_posterior_gp_gif\u001b[0;34m(filename, trainers, datasets, seed, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmulti_posterior_gp_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     giffify(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msave_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"jupyter/gifs/{filename}.gif\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgen_single_fig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_multi_posterior_samples_1d\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# core plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/utils/visualize/helpers.py\u001b[0m in \u001b[0;36mgiffify\u001b[0;34m(save_filename, gen_single_fig, sweep_parameter, sweep_values, fps, quality, is_transparent, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_single_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0msweep_parameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig2img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_transparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_transparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/utils/ntbks_helpers.py\u001b[0m in \u001b[0;36mplot_multi_posterior_samples_1d\u001b[0;34m(trainers, datasets, n_cntxt, trainers_compare, plot_config_kwargs, title, left_extrap, right_extrap, pretty_renamer, is_plot_generator, imgsize, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 )  # use higher density for plotting\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 plot_posterior_samples_1d(\n\u001b[0m\u001b[1;32m    424\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/utils/visualize/visualize_1d.py\u001b[0m in \u001b[0;36mplot_posterior_samples_1d\u001b[0;34m(X, Y, get_cntxt_trgt, model, compare_model, model_labels, generator, is_plot_real, train_min_max, ax, seed, is_fill_generator_std, y_lim, plot_config_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0malpha_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompare_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         ax = _plot_posterior_predefined_cntxt(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/utils/visualize/visualize_1d.py\u001b[0m in \u001b[0;36m_plot_posterior_predefined_cntxt\u001b[0;34m(model, X_cntxt, Y_cntxt, X_trgt, Y_trgt, n_samples, is_plot_std, train_min_max, model_label, alpha_init, mean_std_colors, title, figsize, ax, is_smooth, scatter_kwargs, kwargs_std, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     for i, (mean_y, std_y) in enumerate(\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mgen_p_y_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     ):\n",
      "\u001b[0;32m/Neural-Process-Family/utils/visualize/visualize_1d.py\u001b[0m in \u001b[0;36mgen_p_y_pred\u001b[0;34m(model, X_cntxt, Y_cntxt, X_trgt, n_samples)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mold_n_z_samples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_z_samples_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_z_samples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mp_yCc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_z_samples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_n_z_samples_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_cntxt, Y_cntxt, X_trgt, Y_trgt)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mis_q_zCct\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# size = [batch_size, *n_cntxt, x_transf_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m in \u001b[0;36m_validate_inputs\u001b[0;34m(self, X_cntxt, Y_cntxt, X_trgt, Y_trgt)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlatent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m in \u001b[0;36m_validate_inputs\u001b[0;34m(self, X_cntxt, Y_cntxt, X_trgt, Y_trgt)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 raise ValueError(\n\u001b[1;32m    246\u001b[0m                     \u001b[0;34mf\"Features during training should be in [-1,1]. {X_cntxt.min()} <= X_cntxt <= {X_cntxt.max()} ; {X_trgt.min()} <= X_trgt <= {X_trgt.max()}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Neural-Process-Family/npf/neuralproc/base.py\u001b[0m in \u001b[0;36m_validate_inputs\u001b[0;34m(self, X_cntxt, Y_cntxt, X_trgt, Y_trgt)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;34m\"\"\"Validates the inputs by checking if features are rescaled to [-1,1] during training.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cntxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misin_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 raise ValueError(\n\u001b[1;32m    246\u001b[0m                     \u001b[0;34mf\"Features during training should be in [-1,1]. {X_cntxt.min()} <= X_cntxt <= {X_cntxt.max()} ; {X_trgt.min()} <= X_trgt <= {X_trgt.max()}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 200,
       "width": 719
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_npf(d, lnpf, is_elbo, is_lat_LB, is_sigma_LB):\n",
    "    \"\"\"Select only data form single GP.\"\"\"\n",
    "    return {k: v for k, v in d.items() if \"/\"+get_name(lnpf, is_elbo, is_lat_LB, is_sigma_LB) in k}\n",
    "\n",
    "for lnpf in [\"LNP\"]:\n",
    "    for is_sigma_LB in [True]:\n",
    "        for is_lat_LB in [True]:\n",
    "            multi_posterior_gp_gif(\n",
    "                f\"test_singlegp_{lnpf}_LatLB{str(is_lat_LB)}_SigLB{str(is_sigma_LB)}\",\n",
    "                trainers=filter_npf(trainers_1d, lnpf, is_elbo=False, is_lat_LB=is_lat_LB, is_sigma_LB=is_sigma_LB),\n",
    "                trainers_compare=filter_npf(trainers_1d, lnpf, is_elbo=True, is_lat_LB=is_lat_LB, is_sigma_LB=is_sigma_LB),\n",
    "                datasets=gp_datasets,\n",
    "                n_samples=20,  # 20 samples from the latent\n",
    "                title=\"{model_name} | {data_name} | C={n_cntxt}\",\n",
    "                imgsize=(6, 3),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_datasets['RBF_Kernel'].n_points = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize all of these plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LNP\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_LNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_LNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "### AttnLNP\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_AttnLNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_AttnLNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "### ConvLNP\n",
    "\n",
    "\n",
    "```{warning} \n",
    "\n",
    "For NPVI to train with ConvLNP we had to remove the global representation and decrease the number of channels to `z_dim=16`.\n",
    "The models for NPVI and NPML are thus slighlty different.\n",
    "```\n",
    "\n",
    "\n",
    "#### No Lower bounds\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBFalse_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBFalse_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of latent\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBTrue_SigLBFalse.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBTrue_SigLBFalse\n",
    "---\n",
    "```\n",
    "\n",
    "#### Lower bounded std of predictive\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBFalse_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBFalse_SigLBTrue\n",
    "---\n",
    "```\n",
    "\n",
    "#### Both Lower Bounds\n",
    "\n",
    "\n",
    "```{figure} ../gifs/singlegp_ConvLNP_LatLBTrue_SigLBTrue.gif\n",
    "---\n",
    "width: 60em\n",
    "name: singlegp_ConvLNP_LatLBTrue_SigLBTrue\n",
    "---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "###### ADDITIONAL 1D PLOTS ######\n",
    "\n",
    "#TO Chose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
