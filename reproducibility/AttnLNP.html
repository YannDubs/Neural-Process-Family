
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Attentive Latent Neural Process (AttnLNP) &#8212; Neural Process Family</title>
    
  <link rel="stylesheet" href="../_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://yanndubs.github.io/Neural-Process-Family/reproducibility/AttnLNP.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convolutional Latent Neural Process (ConvLNP)" href="ConvLNP.html" />
    <link rel="prev" title="Latent Neural Process (LNP)" href="LNP.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://yanndubs.github.io/Neural-Process-Family/reproducibility/AttnLNP.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Attentive Latent Neural Process (AttnLNP)" />
<meta property="og:description" content="Attentive Latent Neural Process (AttnLNP)  Computational graph of AttnLNP  Computational graph for Attentive Latent Neural Processes.  In this notebook we will " />
<meta property="og:image"       content="https://yanndubs.github.io/Neural-Process-Family/_static/logo.gif" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../text/Intro.html">
   The Neural Process Family
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Sub-Families
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../text/CNPF.html">
   Conditional NPF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../text/LNPF.html">
   Latent NPF
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reproducibility
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Datasets.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CNP.html">
   CNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="AttnCNP.html">
   AttnCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ConvCNP.html">
   ConvCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="LNP.html">
   LNP
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   AttnLNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ConvLNP.html">
   ConvLNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Losses.html">
   LNPF Losses
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../zbibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/YannDubs/Neural-Process-Family">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/reproducibility/AttnLNP.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/YannDubs/Neural-Process-Family"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/YannDubs/Neural-Process-Family/master?urlpath=tree/reproducibility/AttnLNP.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/YannDubs/Neural-Process-Family/blob/master/reproducibility/AttnLNP.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialization">
   Initialization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plots">
     Plots
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gps-dataset">
       GPs Dataset
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-dataset">
       Image Dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="attentive-latent-neural-process-attnlnp">
<h1>Attentive Latent Neural Process (AttnLNP)<a class="headerlink" href="#attentive-latent-neural-process-attnlnp" title="Permalink to this headline">¶</a></h1>
<div class="figure align-default" id="computational-graph-attnlnps">
<a class="reference internal image-reference" href="../_images/computational_graph_AttnLNPs.png"><img alt="Computational graph of AttnLNP" src="../_images/computational_graph_AttnLNPs.png" style="width: 25em;" /></a>
<p class="caption"><span class="caption-number">Fig. 66 </span><span class="caption-text">Computational graph for Attentive Latent Neural Processes.</span><a class="headerlink" href="#computational-graph-attnlnps" title="Permalink to this image">¶</a></p>
</div>
<p>In this notebook we will show how to train a AttnLNP on samples from GPs and images using our framework, as well as how to make nice visualizations of sampled from AttnLNPs.
We will follow quite closely the previous <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a> and <a class="reference internal" href="AttnCNP.html"><span class="doc">AttnCNP notebook</span></a>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;../..&quot;</span><span class="p">)</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">disable</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="n">N_THREADS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">IS_FORCE_CPU</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Nota Bene : notebooks don&#39;t deallocate GPU memory</span>

<span class="k">if</span> <span class="n">IS_FORCE_CPU</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">N_THREADS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="initialization">
<h2>Initialization<a class="headerlink" href="#initialization" title="Permalink to this headline">¶</a></h2>
<p>Let’s load all the data. For more details about the data and some samples, see the <a class="reference internal" href="Datasets.html"><span class="doc">data</span></a> notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">get_all_gp_datasets</span><span class="p">,</span> <span class="n">get_img_datasets</span>

<span class="c1"># DATASETS</span>
<span class="c1"># gp</span>
<span class="n">gp_datasets</span><span class="p">,</span> <span class="n">gp_test_datasets</span><span class="p">,</span> <span class="n">gp_valid_datasets</span> <span class="o">=</span> <span class="n">get_all_gp_datasets</span><span class="p">()</span>
<span class="c1"># image</span>
<span class="n">img_datasets</span><span class="p">,</span> <span class="n">img_test_datasets</span> <span class="o">=</span> <span class="n">get_img_datasets</span><span class="p">([</span><span class="s2">&quot;celeba32&quot;</span><span class="p">,</span> <span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="s2">&quot;zsmms&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s define the context target splitters, which given a data point will return the context set and target set by selecting randomly selecting some points and preprocessing them so that the features are in <span class="math notranslate nohighlight">\([-1,1]\)</span>.
We use the same as in <a class="reference internal" href="CNP.html"><span class="doc">CNP notebook</span></a>, namely all target points and uniformly sampling in <span class="math notranslate nohighlight">\([0,50]\)</span> and <span class="math notranslate nohighlight">\([0,n\_pixels * 0.3]\)</span> for 1D and 2D respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">npf.utils.datasplit</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CntxtTrgtGetter</span><span class="p">,</span>
    <span class="n">GetRandomIndcs</span><span class="p">,</span>
    <span class="n">GridCntxtTrgtGetter</span><span class="p">,</span>
    <span class="n">RandomMasker</span><span class="p">,</span>
    <span class="n">get_all_indcs</span><span class="p">,</span>
    <span class="n">no_masker</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">utils.data</span> <span class="kn">import</span> <span class="n">cntxt_trgt_collate</span><span class="p">,</span> <span class="n">get_test_upscale_factor</span>

<span class="c1"># CONTEXT TARGET SPLIT</span>
<span class="n">get_cntxt_trgt_1d</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">CntxtTrgtGetter</span><span class="p">(</span>
        <span class="n">contexts_getter</span><span class="o">=</span><span class="n">GetRandomIndcs</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span> <span class="n">targets_getter</span><span class="o">=</span><span class="n">get_all_indcs</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">get_cntxt_trgt_2d</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">GridCntxtTrgtGetter</span><span class="p">(</span>
        <span class="n">context_masker</span><span class="o">=</span><span class="n">RandomMasker</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span> <span class="n">target_masker</span><span class="o">=</span><span class="n">no_masker</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># for ZSMMS you need the pixels to not be in [-1,1] but [-1.75,1.75] (i.e 56 / 32) because you are extrapolating</span>
<span class="n">get_cntxt_trgt_2d_extrap</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">GridCntxtTrgtGetter</span><span class="p">(</span>
        <span class="n">context_masker</span><span class="o">=</span><span class="n">RandomMasker</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
        <span class="n">target_masker</span><span class="o">=</span><span class="n">no_masker</span><span class="p">,</span>
        <span class="n">upscale_factor</span><span class="o">=</span><span class="n">get_test_upscale_factor</span><span class="p">(</span><span class="s2">&quot;zsmms&quot;</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now define the models. We use the same architecture as in <a class="reference internal" href="AttnCNP.html"><span class="doc">AttnCNP notebook</span></a>. The only differences are that we replace <code class="docutils literal notranslate"><span class="pre">AttnCNP</span></code> with <code class="docutils literal notranslate"><span class="pre">AttnLNP</span></code>, as a result we will use two paths (<a class="reference internal" href="AttnCNP.html#computational-graph-attncnps"><span class="std std-numref">Fig. 52</span></a>):</p>
<ul class="simple">
<li><p><strong>Deterministic Path</strong>: this is the same  as in <a class="reference internal" href="AttnCNP.html"><span class="doc">AttnCNP notebook</span></a>.</p></li>
<li><p><strong>Latent Path</strong>: this is the same as in <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a>.</p></li>
</ul>
<p>As in <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a> we will train the model using NPVI and thus set <code class="docutils literal notranslate"><span class="pre">is_q_zCct</span></code> to infer the latent variable using BOTH the context and target set (posterior sampling). This also means that when evaluating we will evaluate the log likelihood using posterior sampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">AttnLNP</span>
<span class="kn">from</span> <span class="nn">npf.architectures</span> <span class="kn">import</span> <span class="n">MLP</span><span class="p">,</span> <span class="n">merge_flat_input</span>
<span class="kn">from</span> <span class="nn">utils.helpers</span> <span class="kn">import</span> <span class="n">count_parameters</span>

<span class="n">R_DIM</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">is_q_zCct</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># will use NPVI =&gt; posterior sampling</span>
    <span class="n">n_z_samples_train</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_z_samples_test</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># small number of sampled because Attn is memory intensive</span>
    <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
    <span class="n">attention</span><span class="o">=</span><span class="s2">&quot;transformer&quot;</span><span class="p">,</span>  <span class="c1"># multi headed attention with normalization and skip connections</span>
<span class="p">)</span>

<span class="c1"># 1D case</span>
<span class="n">model_1d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">AttnLNP</span><span class="p">,</span>
    <span class="n">x_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">y_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">XYEncoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and y so merge them</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">is_self_attn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># image (2D) case</span>
<span class="n">model_2d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">AttnLNP</span><span class="p">,</span> <span class="n">x_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">is_self_attn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>  <span class="c1"># don&#39;t add y_dim yet because depends on data</span>

<span class="n">n_params_1d</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model_1d</span><span class="p">())</span>
<span class="n">n_params_2d</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model_2d</span><span class="p">(</span><span class="n">y_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number Parameters (1D): </span><span class="si">{</span><span class="n">n_params_1d</span><span class="si">:</span><span class="s2">,d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number Parameters (2D): </span><span class="si">{</span><span class="n">n_params_2d</span><span class="si">:</span><span class="s2">,d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number Parameters (1D): 335,170
Number Parameters (2D): 468,486
</pre></div>
</div>
</div>
</div>
<p>Note that there are more parameters than in <code class="docutils literal notranslate"><span class="pre">CNP</span> <span class="pre">notebook</span> <span class="pre">&lt;CNP&gt;</span></code> because of the latent path.
For more details about all the possible parameters, refer to the docstrings of <code class="docutils literal notranslate"><span class="pre">AttnLNP</span></code>.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># AttnLNP Docstring</span>

<span class="nb">print</span><span class="p">(</span><span class="n">AttnLNP</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    Attentive (latent) neural process [1].

    Parameters
    ----------
    x_dim : int
        Dimension of features.

    y_dim : int
        Dimension of y values.

    LatentEncoder : nn.Module, optional
        Encoder which maps r -&gt; z_suffstat. It should be constructed via
        `LatentEncoder(r_dim, n_out)`.  If `None` uses an MLP.

    kwargs :
        Additional arguments to `AttnCNP` and `NeuralProcessFamily`.

    References
    ----------
    [1] Kim, Hyunjik, et al. &quot;Attentive neural processes.&quot; arXiv preprint
        arXiv:1901.05761 (2019).
    
</pre></div>
</div>
</div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>The main function for training is <code class="docutils literal notranslate"><span class="pre">train_models</span></code> which trains a dictionary of models on a dictionary of datasets and returns all the trained models.
See its docstring for possible parameters. As in <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a> we train the latent variable model with NPVI<code class="docutils literal notranslate"><span class="pre">ELBOLossLNPF</span></code>.</p>
<p>Computational Notes :</p>
<ul class="simple">
<li><p>the following will either train all the models (<code class="docutils literal notranslate"><span class="pre">is_retrain=True</span></code>) or load the pretrained models (<code class="docutils literal notranslate"><span class="pre">is_retrain=False</span></code>)</p></li>
<li><p>the code will use a (single) GPU if available</p></li>
<li><p>decrease the batch size if you don’t have enough memory</p></li>
<li><p>30 epochs should give you descent results for the GP datasets (instead of 100)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">skorch</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">ELBOLossLNPF</span>
<span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">add_y_dim</span>
<span class="kn">from</span> <span class="nn">utils.train</span> <span class="kn">import</span> <span class="n">train_models</span>

<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">is_retrain</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># whether to load precomputed model or retrain</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">ELBOLossLNPF</span><span class="p">,</span>  <span class="c1"># NPVI</span>
    <span class="n">chckpnt_dirname</span><span class="o">=</span><span class="s2">&quot;results/pretrained/&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># use GPU if available</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">decay_lr</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># decrease learning rate by 10 during training</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># 1D</span>
<span class="n">trainers_1d</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">gp_datasets</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;AttnLNP&quot;</span><span class="p">:</span> <span class="n">model_1d</span><span class="p">},</span>
    <span class="n">test_datasets</span><span class="o">=</span><span class="n">gp_test_datasets</span><span class="p">,</span>
    <span class="n">iterator_train__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>


<span class="c1"># 2D</span>
<span class="n">trainers_2d</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">img_datasets</span><span class="p">,</span>
    <span class="n">add_y_dim</span><span class="p">({</span><span class="s2">&quot;AttnLNP&quot;</span><span class="p">:</span> <span class="n">model_2d</span><span class="p">},</span> <span class="n">img_datasets</span><span class="p">),</span>  <span class="c1"># y_dim (channels) depend on data</span>
    <span class="n">test_datasets</span><span class="o">=</span><span class="n">img_test_datasets</span><span class="p">,</span>
    <span class="n">train_split</span><span class="o">=</span><span class="n">skorch</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">CVSplit</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>  <span class="c1"># use 10% of training for valdiation</span>
    <span class="n">iterator_train__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_2d</span><span class="p">,</span>
    <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_2d</span><span class="p">,</span>
    <span class="n">datasets_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">zsmms</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_2d_extrap</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">),</span>  <span class="c1"># for zsmm use extrapolation</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Loading RBF_Kernel/AttnLNP/run_0 ---

RBF_Kernel/AttnLNP/run_0 | best epoch: None | train loss: -166.447 | valid loss: None | test log likelihood: 153.6258

--- Loading Periodic_Kernel/AttnLNP/run_0 ---

Periodic_Kernel/AttnLNP/run_0 | best epoch: None | train loss: 38.7724 | valid loss: None | test log likelihood: -44.8828

--- Loading Noisy_Matern_Kernel/AttnLNP/run_0 ---

Noisy_Matern_Kernel/AttnLNP/run_0 | best epoch: None | train loss: 88.0575 | valid loss: None | test log likelihood: -89.8116

--- Loading Variable_Matern_Kernel/AttnLNP/run_0 ---

Variable_Matern_Kernel/AttnLNP/run_0 | best epoch: None | train loss: -223.9907 | valid loss: None | test log likelihood: -3670.0447

--- Loading All_Kernels/AttnLNP/run_0 ---

All_Kernels/AttnLNP/run_0 | best epoch: None | train loss: 62.6881 | valid loss: None | test log likelihood: -73.8714

--- Loading celeba32/AttnLNP/run_0 ---

celeba32/AttnLNP/run_0 | best epoch: 43 | train loss: -5109.2837 | valid loss: -5339.7405 | test log likelihood: 5238.1549

--- Loading mnist/AttnLNP/run_0 ---

mnist/AttnLNP/run_0 | best epoch: 39 | train loss: -2454.4001 | valid loss: -2587.4961 | test log likelihood: 2507.8981

--- Loading zsmms/AttnLNP/run_0 ---

zsmms/AttnLNP/run_0 | best epoch: 1 | train loss: -631.6774 | valid loss: 1575.477 | test log likelihood: -6000.3571
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plots">
<h3>Plots<a class="headerlink" href="#plots" title="Permalink to this headline">¶</a></h3>
<p>Let’s visualize how well the model performs in different settings.</p>
<div class="section" id="gps-dataset">
<h4>GPs Dataset<a class="headerlink" href="#gps-dataset" title="Permalink to this headline">¶</a></h4>
<p>Let’s define a plotting function that we will use in this section. We’ll reuse the same plotting procedure as in <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">PRETTY_RENAMER</span><span class="p">,</span> <span class="n">plot_multi_posterior_samples_1d</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">giffify</span>


<span class="k">def</span> <span class="nf">multi_posterior_gp_gif</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">giffify</span><span class="p">(</span>
        <span class="n">save_filename</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;jupyter/gifs/</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.gif&quot;</span><span class="p">,</span>
        <span class="n">gen_single_fig</span><span class="o">=</span><span class="n">plot_multi_posterior_samples_1d</span><span class="p">,</span>  <span class="c1"># core plotting</span>
        <span class="n">sweep_parameter</span><span class="o">=</span><span class="s2">&quot;n_cntxt&quot;</span><span class="p">,</span>  <span class="c1"># param over which to sweep</span>
        <span class="n">sweep_values</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">fps</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>  <span class="c1"># gif speed</span>
        <span class="c1"># PLOTTING KWARGS</span>
        <span class="n">trainers</span><span class="o">=</span><span class="n">trainers</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
        <span class="n">is_plot_generator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># plot underlying GP</span>
        <span class="n">is_plot_real</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># don&#39;t plot sampled / underlying function</span>
        <span class="n">is_plot_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># plot the predictive std</span>
        <span class="n">is_fill_generator_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># do not fill predictive of GP</span>
        <span class="n">pretty_renamer</span><span class="o">=</span><span class="n">PRETTY_RENAMER</span><span class="p">,</span>  <span class="c1"># pretiffy names of modulte + data</span>
        <span class="c1"># Fix formatting for coherent GIF</span>
        <span class="n">plot_config_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">set_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;legend.loc&quot;</span><span class="p">:</span> <span class="s2">&quot;upper right&quot;</span><span class="p">}</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us visualize samples from the LNP when it is trained on samples from a single GP.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">filter_single_gp</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Select only data form single GP.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;All&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;Variable&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)}</span>


<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;AttnLNP_single_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">gp_test_datasets</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># 20 samples from the latent</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="attnlnp-single-gp">
<a class="reference internal image-reference" href="../_images/AttnLNP_single_gp.gif"><img alt="AttnLNP on single GP" src="../_images/AttnLNP_single_gp.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 67 </span><span class="caption-text">Posterior predictive of AttnLNPs conditioned on 20 different sampled latents (Blue line with shaded area for <span class="math notranslate nohighlight">\(\mu \pm \sigma | z\)</span>) and the oracle GP (Green line with dashes for <span class="math notranslate nohighlight">\(\mu \pm \sigma\)</span>) when conditioned on contexts points (Black) from an underlying function sampled from a GP. Each row corresponds to a different kernel and AttnLNP trained on samples for the corresponding GP.</span><a class="headerlink" href="#attnlnp-single-gp" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#attnlnp-single-gp"><span class="std std-numref">Fig. 67</span></a> we see that although AttnLNP do not underfit like LNPs (<a class="reference internal" href="LNP.html#lnp-single-gp"><span class="std std-numref">Fig. 64</span></a>). The samples: (i) are not very smooth (the “kinks” seed in <a class="reference internal" href="AttnCNP.html#attncnp-single-gp"><span class="std std-numref">Fig. 53</span></a> are even more obvious when sampling); (ii) lack diversity and seem to be shifted versions of each other. In addition AttnLNP will not be able to extrapolate for the same reasons as AttnCNP.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###### ADDITIONAL 1D PLOTS ######</span>

<span class="c1">### Extrap ###</span>
<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;AttnLNP_single_gp_extrap&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">gp_test_datasets</span><span class="p">),</span>
    <span class="n">left_extrap</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># shift signal 2 to the right for extrapolation</span>
    <span class="n">right_extrap</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># shift signal 2 to the right for extrapolation</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">### Varying hyperparam ###</span>
<span class="k">def</span> <span class="nf">filter_hyp_gp</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;Variable&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)}</span>


<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;AttnLNP_vary_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">filter_hyp_gp</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">filter_hyp_gp</span><span class="p">(</span><span class="n">gp_test_datasets</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">model_labels</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">main</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="s2">&quot;Fitted GP&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1">### All kernels ###</span>
<span class="c1"># data with varying kernels simply merged single kernels</span>
<span class="n">single_gp_datasets</span> <span class="o">=</span> <span class="n">filter_single_gp</span><span class="p">(</span><span class="n">gp_test_datasets</span><span class="p">)</span>

<span class="c1"># use same trainer for all, but have to change their name to be the same as datasets</span>
<span class="n">base_trainer_name</span> <span class="o">=</span> <span class="s2">&quot;All_Kernels/AttnLNP/run_0&quot;</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">trainers_1d</span><span class="p">[</span><span class="n">base_trainer_name</span><span class="p">]</span>
<span class="n">replicated_trainers</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">single_gp_datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">replicated_trainers</span><span class="p">[</span><span class="n">base_trainer_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;All_Kernels&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)]</span> <span class="o">=</span> <span class="n">trainer</span>

<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;AttnLNP_kernel_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">replicated_trainers</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">single_gp_datasets</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="image-dataset">
<h4>Image Dataset<a class="headerlink" href="#image-dataset" title="Permalink to this headline">¶</a></h4>
<p>Let us now look at images. We again will use the same plotting procedure as in <a class="reference internal" href="LNP.html"><span class="doc">LNP notebook</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">plot_multi_posterior_samples_imgs</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">giffify</span>


<span class="k">def</span> <span class="nf">multi_posterior_imgs_gif</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">giffify</span><span class="p">(</span>
        <span class="n">save_filename</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;jupyter/gifs/</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.gif&quot;</span><span class="p">,</span>
        <span class="n">gen_single_fig</span><span class="o">=</span><span class="n">plot_multi_posterior_samples_imgs</span><span class="p">,</span>  <span class="c1"># core plotting</span>
        <span class="n">sweep_parameter</span><span class="o">=</span><span class="s2">&quot;n_cntxt&quot;</span><span class="p">,</span>  <span class="c1"># param over which to sweep</span>
        <span class="n">sweep_values</span><span class="o">=</span><span class="p">[</span>
            <span class="mi">0</span><span class="p">,</span>  
            <span class="mf">0.005</span><span class="p">,</span>
            <span class="mf">0.01</span><span class="p">,</span>
            <span class="mf">0.02</span><span class="p">,</span>
            <span class="mf">0.05</span><span class="p">,</span>
            <span class="mf">0.1</span><span class="p">,</span>
            <span class="mf">0.15</span><span class="p">,</span>
            <span class="mf">0.2</span><span class="p">,</span>
            <span class="mf">0.3</span><span class="p">,</span>
            <span class="mf">0.5</span><span class="p">,</span>
            <span class="s2">&quot;hhalf&quot;</span><span class="p">,</span>  <span class="c1"># horizontal half of the image</span>
            <span class="s2">&quot;vhalf&quot;</span><span class="p">,</span>  <span class="c1"># vertival half of the image</span>
        <span class="p">],</span>
        <span class="n">fps</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>  <span class="c1"># gif speed</span>
        <span class="c1"># PLOTTING KWARGS</span>
        <span class="n">trainers</span><span class="o">=</span><span class="n">trainers</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
        <span class="n">n_plots</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># images per datasets</span>
        <span class="n">is_plot_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># plot the predictive std</span>
        <span class="n">pretty_renamer</span><span class="o">=</span><span class="n">PRETTY_RENAMER</span><span class="p">,</span>  <span class="c1"># pretiffy names of modulte + data</span>
        <span class="n">plot_config_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;font_scale&quot;</span><span class="p">:</span><span class="mf">0.7</span><span class="p">},</span>
        <span class="c1"># Fix formatting for coherent GIF</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">multi_posterior_imgs_gif</span><span class="p">(</span>
    <span class="s2">&quot;AttnLNP_img&quot;</span><span class="p">,</span> <span class="n">trainers</span><span class="o">=</span><span class="n">trainers_2d</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="n">img_test_datasets</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="attnlnp-img">
<a class="reference internal image-reference" href="../_images/AttnLNP_img.gif"><img alt="AttnLNP on CelebA, MNIST, ZSMM" src="../_images/AttnLNP_img.gif" style="width: 45em;" /></a>
<p class="caption"><span class="caption-number">Fig. 68 </span><span class="caption-text">3 samples (means conditioned on different samples from the latent) of the posterior predictive of a AttnLNP_img for CelebA <span class="math notranslate nohighlight">\(32\times32\)</span>, MNIST, and ZSMM for different context sets. The last row shows the standard deviation of the posterior predictive corresponding to the last sample.</span><a class="headerlink" href="#attnlnp-img" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#attnlnp-img"><span class="std std-numref">Fig. 68</span></a> shows descent sampling and good performances when the model does not require generalization (CelebA <span class="math notranslate nohighlight">\(32\times32\)</span>, MNIST) but breaks for ZSMM.</p>
<p>Here are more samples, corresponding to specific percentiles of the test log loss.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">PRETTY_RENAMER</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">plot_qualitative_with_kde</span>


<span class="n">n_trainers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainers_2d</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainers_2d</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">data_name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">img_test_datasets</span><span class="p">[</span><span class="n">data_name</span><span class="p">]</span>

    <span class="n">plot_qualitative_with_kde</span><span class="p">(</span>
        <span class="p">[</span><span class="n">PRETTY_RENAMER</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">trainer</span><span class="p">],</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
        <span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>  <span class="c1"># desired test percentile</span>
        <span class="n">height_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>  <span class="c1"># kde / image ratio</span>
        <span class="n">is_smallest_xrange</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># rescale X axis based on percentile</span>
        <span class="n">h_pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># padding</span>
        <span class="n">title</span><span class="o">=</span><span class="n">PRETTY_RENAMER</span><span class="p">[</span><span class="n">data_name</span><span class="p">],</span>
        <span class="n">upscale_factor</span><span class="o">=</span><span class="n">get_test_upscale_factor</span><span class="p">(</span><span class="n">data_name</span><span class="p">),</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/AttnLNP_22_0.png" src="../_images/AttnLNP_22_0.png" />
<img alt="../_images/AttnLNP_22_1.png" src="../_images/AttnLNP_22_1.png" />
<img alt="../_images/AttnLNP_22_2.png" src="../_images/AttnLNP_22_2.png" />
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./reproducibility"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="LNP.html" title="previous page">Latent Neural Process (LNP)</a>
    <a class='right-next' id="next-link" href="ConvLNP.html" title="next page">Convolutional Latent Neural Process (ConvLNP)</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois, Jonathan Gordon, ‪Andrew Foong<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.30270b6e4c972e43c488.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-108456313-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>