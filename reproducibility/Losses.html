
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Criteria for LNPF &#8212; Neural Process Family</title>
    
  <link rel="stylesheet" href="../_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://yanndubs.github.io/Neural-Process-Family/reproducibility/Losses.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bibliography" href="../zbibliography.html" />
    <link rel="prev" title="Convolutional Latent Neural Process (ConvLNP)" href="ConvLNP.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://yanndubs.github.io/Neural-Process-Family/reproducibility/Losses.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Criteria for LNPF" />
<meta property="og:description" content="Criteria for LNPF  In this notebook we will investigate the inpact of using the ML or the ELBO objective for training members of LNPF. We will also investigate " />
<meta property="og:image"       content="https://yanndubs.github.io/Neural-Process-Family/_static/logo.gif" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../text/Intro.html">
   The Neural Process Family
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Sub-Families
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../text/CNPF.html">
   Conditional NPF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../text/LNPF.html">
   Latent NPF
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reproducibility
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Datasets.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CNP.html">
   CNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="AttnCNP.html">
   AttnCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ConvCNP.html">
   ConvCNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="LNP.html">
   LNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="AttnLNP.html">
   AttnLNP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ConvLNP.html">
   ConvLNP
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   LNPF Losses
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../zbibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/YannDubs/Neural-Process-Family">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/reproducibility/Losses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/YannDubs/Neural-Process-Family"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/YannDubs/Neural-Process-Family/master?urlpath=tree/reproducibility/Losses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/YannDubs/Neural-Process-Family/blob/master/reproducibility/Losses.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialization">
   Initialization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plots">
     Plots
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gps-dataset">
       GPs Dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lnp">
     LNP
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#no-lower-bounds">
       No Lower bounds
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lower-bounded-std-of-latent">
       Lower bounded std of latent
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lower-bounded-std-of-predictive">
       Lower bounded std of predictive
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#both-lower-bounds">
       Both Lower Bounds
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attnlnp">
     AttnLNP
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       No Lower bounds
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Lower bounded std of latent
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Lower bounded std of predictive
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Both Lower Bounds
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convlnp">
     ConvLNP
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       No Lower bounds
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Lower bounded std of latent
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Lower bounded std of predictive
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Both Lower Bounds
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="criteria-for-lnpf">
<h1>Criteria for LNPF<a class="headerlink" href="#criteria-for-lnpf" title="Permalink to this headline">¶</a></h1>
<p>In this notebook we will investigate the inpact of using the ML or the ELBO objective for training members of LNPF.
We will also investigate the effect and/or need of using a lower bound for the standard deviation of the the latent variable and the posterior predictive.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;../..&quot;</span><span class="p">)</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">disable</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="n">N_THREADS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">IS_FORCE_CPU</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Nota Bene : notebooks don&#39;t deallocate GPU memory</span>

<span class="k">if</span> <span class="n">IS_FORCE_CPU</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">N_THREADS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="initialization">
<h2>Initialization<a class="headerlink" href="#initialization" title="Permalink to this headline">¶</a></h2>
<p>Let’s load the data, here we will only be working with Gaussian Processes from a single underlying kernel. For more details, see the <a class="reference internal" href="Datasets.html"><span class="doc">data</span></a> notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">get_datasets_single_gp</span>

<span class="c1"># DATASET</span>
<span class="n">gp_datasets</span><span class="p">,</span> <span class="n">gp_test_datasets</span><span class="p">,</span> <span class="n">gp_valid_datasets</span> <span class="o">=</span> <span class="n">get_datasets_single_gp</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">npf.utils.datasplit</span> <span class="kn">import</span> <span class="n">CntxtTrgtGetter</span><span class="p">,</span> <span class="n">GetRandomIndcs</span>
<span class="kn">from</span> <span class="nn">utils.data</span> <span class="kn">import</span> <span class="n">cntxt_trgt_collate</span>

<span class="c1"># CONTEXT TARGET SPLIT</span>
<span class="n">get_cntxt_trgt_1d</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">CntxtTrgtGetter</span><span class="p">(</span><span class="n">contexts_getter</span><span class="o">=</span><span class="n">GetRandomIndcs</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now make the model. We will make make one model for every member of LNPF. For each we will train them with both losses, with or without lower bound on the the std of the latent distribution, and with or without lower bound on the std of the predictive distribution.
This is a total of 24 models, so we will do in a loop. Note that besides training, the same models are used as in other notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">LNP</span><span class="p">,</span><span class="n">ConvLNP</span><span class="p">,</span> <span class="n">AttnLNP</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">npf.architectures</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CNN</span><span class="p">,</span>
    <span class="n">MLP</span><span class="p">,</span>
    <span class="n">ResConvBlock</span><span class="p">,</span>
    <span class="n">SetConv</span><span class="p">,</span>
    <span class="n">discard_ith_arg</span><span class="p">,</span>
    <span class="n">merge_flat_input</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">utils.helpers</span> <span class="kn">import</span> <span class="n">count_parameters</span>

<span class="n">R_DIM</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">XEncoder</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span>
    <span class="n">Decoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and R so merge them</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">get_std_processing_kwargs</span><span class="p">(</span><span class="n">min_sigma_pred</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Function returning kwarhs for processing std&quot;&quot;&quot;</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">p_y_scale_transformer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">y_scale</span><span class="p">:</span> <span class="n">min_sigma_pred</span>
        <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">min_sigma_pred</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">y_scale</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">min_lat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;q_z_scale_transformer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">y_scale</span><span class="p">:</span> <span class="n">min_lat</span> <span class="o">+</span> <span class="p">(</span>
            <span class="mi">1</span> <span class="o">-</span> <span class="n">min_lat</span>
        <span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">y_scale</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">kwargs</span>


<span class="k">def</span> <span class="nf">get_lnp</span><span class="p">(</span>
    <span class="n">is_mle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_sigma_pred</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>

    <span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">is_q_zCct</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_mle</span><span class="p">,</span>  <span class="c1"># use MLE instead of ELBO</span>
        <span class="n">n_z_samples_train</span><span class="o">=</span><span class="mi">32</span> <span class="k">if</span> <span class="n">is_mle</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># going to be more expensive</span>
        <span class="n">n_z_samples_test</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">XEncoder</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span>
        <span class="n">Decoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and R so merge them</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
        <span class="o">**</span><span class="n">get_std_processing_kwargs</span><span class="p">(</span><span class="n">min_sigma_pred</span><span class="o">=</span><span class="n">min_sigma_pred</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="n">min_lat</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># 1D case</span>
    <span class="n">model_1d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">LNP</span><span class="p">,</span>
        <span class="n">x_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">y_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">XYEncoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and y so merge them</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model_1d</span>


<span class="k">def</span> <span class="nf">get_attnlnp</span><span class="p">(</span>
    <span class="n">is_mle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_sigma_pred</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>

    <span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">is_q_zCct</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_mle</span><span class="p">,</span>  <span class="c1"># use MLE instead of ELBO</span>
        <span class="n">n_z_samples_train</span><span class="o">=</span><span class="mi">8</span> <span class="k">if</span> <span class="n">is_mle</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># going to be more expensive</span>
        <span class="n">n_z_samples_test</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
        <span class="n">attention</span><span class="o">=</span><span class="s2">&quot;transformer&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">get_std_processing_kwargs</span><span class="p">(</span><span class="n">min_sigma_pred</span><span class="o">=</span><span class="n">min_sigma_pred</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="n">min_lat</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># 1D case</span>
    <span class="n">model_1d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">AttnLNP</span><span class="p">,</span>
        <span class="n">x_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">y_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">XYEncoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and y so merge them</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">is_self_attn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model_1d</span>


<span class="k">def</span> <span class="nf">get_convlnp</span><span class="p">(</span>
    <span class="n">is_mle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_sigma_pred</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">z_dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
    <span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">is_q_zCct</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_mle</span><span class="p">,</span>  <span class="c1"># use MLE instead of ELBO</span>
        <span class="n">n_z_samples_train</span><span class="o">=</span><span class="mi">16</span> <span class="k">if</span> <span class="n">is_mle</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># going to be more expensive</span>
        <span class="n">n_z_samples_test</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
        <span class="n">Decoder</span><span class="o">=</span><span class="n">discard_ith_arg</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">),</span>  <span class="c1"># use small decoder because already went through CNN</span>
        <span class="n">z_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="c1">#! NPVI requires smaller number of latent channels due to the KL</span>
        <span class="o">**</span><span class="n">get_std_processing_kwargs</span><span class="p">(</span><span class="n">min_sigma_pred</span><span class="o">=</span><span class="n">min_sigma_pred</span><span class="p">,</span> <span class="n">min_lat</span><span class="o">=</span><span class="n">min_lat</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">CNN_KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">ConvBlock</span><span class="o">=</span><span class="n">ResConvBlock</span><span class="p">,</span>
        <span class="n">is_chan_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># all computations are done with channel last in our code</span>
        <span class="n">n_conv_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">n_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 1D case</span>
    <span class="n">model_1d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">ConvLNP</span><span class="p">,</span>
        <span class="n">x_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">y_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">CNN</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
            <span class="n">CNN</span><span class="p">,</span>
            <span class="n">Conv</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">,</span>
            <span class="n">Normalization</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span>
            <span class="o">**</span><span class="n">CNN_KWARGS</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">density_induced</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># size of discretization</span>
        <span class="n">is_global</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1">#! Global representation does not work well with NPVI</span>
        <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model_1d</span>


<span class="n">lnpf_getters</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">LNP</span><span class="o">=</span><span class="n">get_lnp</span><span class="p">,</span> <span class="n">AttnLNP</span><span class="o">=</span><span class="n">get_attnlnp</span><span class="p">,</span> <span class="n">ConvLNP</span><span class="o">=</span><span class="n">get_convlnp</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_name</span><span class="p">(</span><span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">lnpf</span><span class="si">}</span><span class="s2">_ELBO</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">is_elbo</span><span class="p">)</span><span class="si">}</span><span class="s2">_LatLB</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">is_lat_LB</span><span class="p">)</span><span class="si">}</span><span class="s2">_SigLB</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">is_sigma_LB</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">get_name</span><span class="p">(</span><span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="p">):</span> <span class="n">lnpf_getters</span><span class="p">[</span>
        <span class="n">lnpf</span>
    <span class="p">](</span>
        <span class="n">is_mle</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_elbo</span><span class="p">,</span>
        <span class="n">min_sigma_pred</span><span class="o">=</span><span class="mf">0.01</span> <span class="k">if</span> <span class="n">is_sigma_LB</span> <span class="k">else</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">min_lat</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">is_lat_LB</span> <span class="k">else</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">lnpf</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;LNP&quot;</span><span class="p">,</span> <span class="s2">&quot;AttnLNP&quot;</span><span class="p">,</span> <span class="s2">&quot;ConvLNP&quot;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">is_elbo</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">is_sigma_LB</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">is_lat_LB</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
</pre></div>
</div>
</div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>The main function for training is <code class="docutils literal notranslate"><span class="pre">train_models</span></code> which trains a dictionary of models on a dictionary of datasets and returns all the trained models.
See its docstring for possible parameters.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">skorch</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">NLLLossLNPF</span><span class="p">,</span> <span class="n">ELBOLossLNPF</span>
<span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">add_y_dim</span>
<span class="kn">from</span> <span class="nn">utils.train</span> <span class="kn">import</span> <span class="n">train_models</span>

<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">is_retrain</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># whether to load precomputed model or retrain</span>
    <span class="n">chckpnt_dirname</span><span class="o">=</span><span class="s2">&quot;results/pretrained/&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># use GPU if available</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">decay_lr</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># decrease learning rate by 10 during training</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">test_datasets</span><span class="o">=</span><span class="n">gp_test_datasets</span><span class="p">,</span>
    <span class="n">train_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># No need for validation as the training data is generated on the fly</span>
    <span class="n">iterator_train__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># NPVI</span>
<span class="n">trainers_1d_NPVI</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">gp_datasets</span><span class="p">,</span>
    <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;ELBOTrue&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">},</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">ELBOLossLNPF</span><span class="p">,</span>  <span class="c1"># NPVI</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>

<span class="c1">#NPML</span>
<span class="n">trainers_1d_NPML</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">gp_datasets</span><span class="p">,</span>
    <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;ELBOTrue&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">},</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">NLLLossLNPF</span><span class="p">,</span>  <span class="c1"># NPML</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>

<span class="n">trainers_1d</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">trainers_1d_NPML</span><span class="p">,</span> <span class="o">**</span><span class="n">trainers_1d_NPVI</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Training RBF_Kernel/ConvLNP_ELBOTrue_LatLBTrue_SigLBTrue/run_0 ---
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  epoch    train_loss    cp       dur
-------  ------------  ----  --------
      1      <span class=" -Color -Color-Cyan">129.7038</span>     +  239.3549
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      2      <span class=" -Color -Color-Cyan">101.4122</span>     +  238.1240
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      3       <span class=" -Color -Color-Cyan">97.4390</span>     +  238.3368
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      4       <span class=" -Color -Color-Cyan">92.0397</span>     +  238.1451
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      5       <span class=" -Color -Color-Cyan">87.2336</span>     +  238.0833
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      6       <span class=" -Color -Color-Cyan">84.0536</span>     +  238.4104
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      7       <span class=" -Color -Color-Cyan">79.8557</span>     +  238.3659
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      8       83.7127     +  238.3537
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      9       81.0838     +  238.0101
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     10       80.6303     +  238.3044
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     11       <span class=" -Color -Color-Cyan">76.1241</span>     +  238.4895
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     12       <span class=" -Color -Color-Cyan">75.7715</span>     +  238.7090
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     13       <span class=" -Color -Color-Cyan">72.1939</span>     +  238.3308
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     14       <span class=" -Color -Color-Cyan">57.8714</span>     +  238.4733
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     15       <span class=" -Color -Color-Cyan">54.2789</span>     +  238.5238
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     16       <span class=" -Color -Color-Cyan">44.9809</span>     +  238.2171
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     17       <span class=" -Color -Color-Cyan">40.3735</span>     +  238.2151
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     18       <span class=" -Color -Color-Cyan">37.7643</span>     +  238.8333
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     19       <span class=" -Color -Color-Cyan">32.3731</span>     +  238.4594
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     20       <span class=" -Color -Color-Cyan">26.4459</span>     +  238.3471
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     21       30.2063     +  238.1728
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     22       <span class=" -Color -Color-Cyan">21.5765</span>     +  238.5040
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     23       29.4292     +  238.0256
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     24       26.3641     +  238.4433
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     25       30.0697     +  238.1362
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     26       <span class=" -Color -Color-Cyan">18.7951</span>     +  238.4706
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     27       27.3368     +  238.1425
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     28       19.0851     +  238.8775
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     29       <span class=" -Color -Color-Cyan">16.5148</span>     +  238.7939
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     30       20.4330     +  244.5869
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     31       18.0716     +  242.0035
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     32       <span class=" -Color -Color-Cyan">14.7289</span>     +  238.3282
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     33       18.4413     +  238.1761
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     34       23.1330     +  238.7662
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     35        <span class=" -Color -Color-Cyan">7.4369</span>     +  238.5179
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     36       22.0328     +  238.4506
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     37       18.8443     +  238.4743
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     38       12.9400     +  238.5806
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     39       12.1659     +  238.3955
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     40       16.9035     +  238.0642
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     41       <span class=" -Color -Color-Cyan">-1.1496</span>     +  238.0272
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     42       15.4954     +  238.4320
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     43        5.0167     +  238.4243
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     44       15.3910     +  238.3112
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     45       11.9266     +  237.9933
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     46       17.7535     +  238.7897
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     47       15.8736     +  238.8321
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     48       13.3900     +  238.4870
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     49       12.9759     +  238.4963
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     50        0.9926     +  238.4289
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     51       10.8183     +  238.2757
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     52        0.6480     +  238.7333
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     53       10.0863     +  238.6328
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     54        8.7167     +  238.8326
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     55        6.4785     +  238.6568
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     56        6.8276     +  238.2139
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     57        8.8167     +  238.5518
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     58        8.1628     +  238.4619
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     59        4.0275     +  238.5637
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     60        6.7623     +  238.2706
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     61        5.9025     +  238.2616
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     62        5.2453     +  238.3772
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     63        9.3041     +  238.3914
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     64        0.3898     +  238.4141
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     65        0.4236     +  238.8593
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     66        3.1711     +  238.4839
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     67        7.8289     +  238.6293
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     68        4.1811     +  238.3139
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     69       <span class=" -Color -Color-Cyan">-5.6372</span>     +  238.2651
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     70       -1.3111     +  238.5241
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     71        4.3642     +  238.3230
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     72       -2.0597     +  238.5121
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     73       -4.1778     +  238.6974
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     74       -3.6988     +  238.4022
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     75        2.4047     +  238.4325
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     76        5.9431     +  238.6175
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     77       -2.3961     +  238.3699
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     78       <span class=" -Color -Color-Cyan">-7.9538</span>     +  238.2562
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     79        2.3153     +  238.4240
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     80       -4.7170     +  238.5504
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     81       -0.3072     +  238.5983
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     82       -4.7691     +  238.5618
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     83       -3.7401     +  238.2080
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     84      <span class=" -Color -Color-Cyan">-15.8007</span>     +  238.4962
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     85       -5.2551     +  238.7403
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     86      -10.2924     +  238.5412
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     87       -0.8481     +  243.8790
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     88       -6.0228     +  245.8084
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     89      -13.6405     +  237.6706
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     90       -2.3882     +  238.7418
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     91       -2.2633     +  238.7118
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     92       -7.2702     +  238.5521
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     93       -8.4949     +  238.5709
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     94       -4.8103     +  238.1701
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     95       -8.1157     +  238.0129
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     96      -10.1068     +  237.8133
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     97       -9.7320     +  238.2391
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     98       -3.6467     +  238.4105
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     99       -6.8139     +  237.9917
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    100       -8.0791     +  238.7962
Re-initializing module.
Re-initializing optimizer.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "c419741829c2415b8c61e3cf469ce371", "version_major": 2, "version_minor": 0}
</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">6</span><span class="o">-</span><span class="mi">6</span><span class="n">f3f90499dc6</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> 
<span class="g g-Whitespace">     </span><span class="mi">21</span> <span class="c1"># NPVI</span>
<span class="ne">---&gt; </span><span class="mi">22</span> <span class="n">trainers_1d_NPVI</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>     <span class="n">gp_datasets</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>     <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;ELBOTrue&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">},</span>

<span class="nn">/Neural-Process-Family/utils/train.py</span> in <span class="ni">train_models</span><span class="nt">(datasets, models, criterion, test_datasets, valid_datasets, chckpnt_dirname, is_continue_train, is_retrain, runs, starting_run, train_split, device, max_epochs, batch_size, lr, optimizer, callbacks, patience, decay_lr, is_reeval, seed, datasets_kwargs, models_kwargs, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">263</span>                 <span class="c1"># return the training rather than testing history as dflt</span>
<span class="g g-Whitespace">    </span><span class="mi">264</span>                 <span class="n">history</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">265</span>                 <span class="n">test_loglike</span> <span class="o">=</span> <span class="n">_eval_save_load</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">266</span>                     <span class="n">trainer</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>                     <span class="n">data_test</span><span class="p">,</span>

<span class="nn">/Neural-Process-Family/utils/train.py</span> in <span class="ni">_eval_save_load</span><span class="nt">(model, data_test, test_eval_file, is_force_rerun)</span>
<span class="g g-Whitespace">    </span><span class="mi">312</span> 
<span class="g g-Whitespace">    </span><span class="mi">313</span>         <span class="k">if</span> <span class="n">is_force_rerun</span> <span class="ow">or</span> <span class="n">test_loglike</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">314</span>             <span class="n">test_loglike</span> <span class="o">=</span> <span class="n">eval_loglike</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_test</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">315</span> 
<span class="g g-Whitespace">    </span><span class="mi">316</span>         <span class="k">if</span> <span class="n">test_eval_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/Neural-Process-Family/utils/evaluate.py</span> in <span class="ni">eval_loglike</span><span class="nt">(trainer, dataset, seed, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>         <span class="n">yi_res</span> <span class="o">=</span> <span class="n">yi</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">y_valid_is_ph</span> <span class="k">else</span> <span class="kc">None</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>         <span class="n">trainer</span><span class="o">.</span><span class="n">notify</span><span class="p">(</span><span class="s2">&quot;on_batch_begin&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xi</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">yi_res</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">23</span>         <span class="n">step</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_step</span><span class="p">(</span><span class="n">Xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>         <span class="n">trainer</span><span class="o">.</span><span class="n">notify</span><span class="p">(</span><span class="s2">&quot;on_batch_end&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xi</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">yi_res</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">step</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>         <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">step</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>  <span class="c1"># use log likelihood instead of NLLL</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/skorch/net.py</span> in <span class="ni">validation_step</span><span class="nt">(self, Xi, yi, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">569</span>         <span class="bp">self</span><span class="o">.</span><span class="n">module_</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">570</span>         <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">571</span>             <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">Xi</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">572</span>             <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xi</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">573</span>         <span class="k">return</span> <span class="p">{</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/skorch/net.py</span> in <span class="ni">infer</span><span class="nt">(self, x, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">996</span>         <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">997</span>             <span class="n">x_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_x_and_fit_params</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">998</span>             <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_</span><span class="p">(</span><span class="o">**</span><span class="n">x_dict</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">999</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1000</span> 

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">720</span>             <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slow_forward</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">721</span>         <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">722</span>             <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">723</span>         <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">724</span>                 <span class="n">_global_forward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span>

<span class="nn">/Neural-Process-Family/npf/neuralproc/base.py</span> in <span class="ni">forward</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">492</span>             <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">493</span> 
<span class="ne">--&gt; </span><span class="mi">494</span>         <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">495</span> 
<span class="g g-Whitespace">    </span><span class="mi">496</span>     <span class="k">def</span> <span class="nf">_validate_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_cntxt</span><span class="p">,</span> <span class="n">Y_cntxt</span><span class="p">,</span> <span class="n">X_trgt</span><span class="p">,</span> <span class="n">Y_trgt</span><span class="p">):</span>

<span class="nn">/Neural-Process-Family/npf/neuralproc/base.py</span> in <span class="ni">forward</span><span class="nt">(self, X_cntxt, Y_cntxt, X_trgt, Y_trgt)</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span> 
<span class="g g-Whitespace">    </span><span class="mi">237</span>         <span class="c1"># size = [n_z_samples, batch_size, *n_trgt, r_dim]</span>
<span class="ne">--&gt; </span><span class="mi">238</span>         <span class="n">R_trgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trgt_dependent_representation</span><span class="p">(</span><span class="n">X_cntxt</span><span class="p">,</span> <span class="n">z_samples</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">X_trgt</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">239</span> 
<span class="g g-Whitespace">    </span><span class="mi">240</span>         <span class="c1"># p(y|cntxt,trgt)</span>

<span class="nn">/Neural-Process-Family/npf/neuralproc/convnp.py</span> in <span class="ni">trgt_dependent_representation</span><span class="nt">(self, X_cntxt, z_samples, R_induced, X_trgt)</span>
<span class="g g-Whitespace">    </span><span class="mi">295</span> 
<span class="g g-Whitespace">    </span><span class="mi">296</span>             <span class="c1"># size = [n_z_samples * batch_size, n_trgt, r_dim]</span>
<span class="ne">--&gt; </span><span class="mi">297</span>             <span class="n">R_trgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">induced_to_trgt</span><span class="p">(</span><span class="n">X_induced</span><span class="p">,</span> <span class="n">X_trgt</span><span class="p">,</span> <span class="n">z_samples</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">298</span> 
<span class="g g-Whitespace">    </span><span class="mi">299</span>         <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoded_path</span> <span class="o">==</span> <span class="s2">&quot;both&quot;</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">720</span>             <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slow_forward</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">721</span>         <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">722</span>             <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">723</span>         <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">724</span>                 <span class="n">_global_forward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span>

<span class="nn">/Neural-Process-Family/npf/architectures/setcnn.py</span> in <span class="ni">forward</span><span class="nt">(self, keys, queries, values)</span>
<span class="g g-Whitespace">    </span><span class="mi">261</span> 
<span class="g g-Whitespace">    </span><span class="mi">262</span>         <span class="c1"># size = [batch_size, n_queries, value_size]</span>
<span class="ne">--&gt; </span><span class="mi">263</span>         <span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">264</span> 
<span class="g g-Whitespace">    </span><span class="mi">265</span>         <span class="c1"># size = [batch_size, n_queries, value_size+1]</span>

<span class="ne">RuntimeError</span>: CUDA out of memory. Tried to allocate 24.00 GiB (GPU 0; 10.92 GiB total capacity; 420.09 MiB already allocated; 1.43 GiB free; 1.17 GiB reserved in total by PyTorch)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plots">
<h3>Plots<a class="headerlink" href="#plots" title="Permalink to this headline">¶</a></h3>
<p>Let’s visualize how well the model performs in different settings.</p>
<div class="section" id="gps-dataset">
<h4>GPs Dataset<a class="headerlink" href="#gps-dataset" title="Permalink to this headline">¶</a></h4>
<p>Let’s define a plotting function that we will use in this section. We’ll reuse the same function defined in <a class="reference internal" href="CNP.html"><span class="doc">CNP notebook</span></a>, but will use <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">=</span> <span class="pre">20</span></code> to plot multiple posterior predictives conditioned on different latent samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">PRETTY_RENAMER</span><span class="p">,</span> <span class="n">plot_multi_posterior_samples_1d</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">giffify</span>


<span class="k">def</span> <span class="nf">multi_posterior_gp_gif</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">giffify</span><span class="p">(</span>
        <span class="n">save_filename</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;jupyter/gifs/</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.gif&quot;</span><span class="p">,</span>
        <span class="n">gen_single_fig</span><span class="o">=</span><span class="n">plot_multi_posterior_samples_1d</span><span class="p">,</span>  <span class="c1"># core plotting</span>
        <span class="n">sweep_parameter</span><span class="o">=</span><span class="s2">&quot;n_cntxt&quot;</span><span class="p">,</span>  <span class="c1"># param over which to sweep</span>
        <span class="n">sweep_values</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">fps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># gif speed</span>
        <span class="c1"># PLOTTING KWARGS</span>
        <span class="n">trainers</span><span class="o">=</span><span class="n">trainers</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
        <span class="n">is_plot_generator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># plot underlying GP</span>
        <span class="n">is_plot_real</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># don&#39;t plot sampled / underlying function</span>
        <span class="n">is_plot_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># plot the predictive std</span>
        <span class="n">is_fill_generator_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># do not fill predictive of GP</span>
        <span class="n">pretty_renamer</span><span class="o">=</span><span class="n">PRETTY_RENAMER</span><span class="p">,</span>  <span class="c1"># pretiffy names of modulte + data</span>
        <span class="c1"># Fix formatting for coherent GIF</span>
        <span class="n">plot_config_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">set_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;legend.loc&quot;</span><span class="p">:</span> <span class="s2">&quot;upper right&quot;</span><span class="p">}</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us visualize the CNP when it is trained on samples from a single GP.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">filter_npf</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Select only data form single GP.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="n">get_name</span><span class="p">(</span><span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="p">)</span> <span class="ow">in</span> <span class="n">k</span><span class="p">}</span>

<span class="k">for</span> <span class="n">lnpf</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;LNP&quot;</span><span class="p">,</span> <span class="s2">&quot;AttnLNP&quot;</span><span class="p">,</span> <span class="s2">&quot;ConvLNP&quot;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">is_sigma_LB</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">is_lat_LB</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
            <span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;singlegp_</span><span class="si">{</span><span class="n">lnpf</span><span class="si">}</span><span class="s2">_LatLB</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">is_lat_LB</span><span class="p">)</span><span class="si">}</span><span class="s2">_SigLB</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">is_sigma_LB</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">trainers</span><span class="o">=</span><span class="n">filter_npf</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">,</span> <span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="o">=</span><span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="o">=</span><span class="n">is_sigma_LB</span><span class="p">),</span>
                <span class="n">trainers_compare</span><span class="o">=</span><span class="n">filter_npf</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">,</span> <span class="n">lnpf</span><span class="p">,</span> <span class="n">is_elbo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_lat_LB</span><span class="o">=</span><span class="n">is_lat_LB</span><span class="p">,</span> <span class="n">is_sigma_LB</span><span class="o">=</span><span class="n">is_sigma_LB</span><span class="p">),</span>
                <span class="n">datasets</span><span class="o">=</span><span class="n">gp_test_datasets</span><span class="p">,</span>
                <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># 20 samples from the latent</span>
                <span class="n">title</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{model_name}</span><span class="s2"> | </span><span class="si">{data_name}</span><span class="s2"> | C=</span><span class="si">{n_cntxt}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">imgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now visualize all of these plots.</p>
</div>
</div>
<div class="section" id="lnp">
<h3>LNP<a class="headerlink" href="#lnp" title="Permalink to this headline">¶</a></h3>
<div class="section" id="no-lower-bounds">
<h4>No Lower bounds<a class="headerlink" href="#no-lower-bounds" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-lnp-latlbfalse-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_LNP_LatLBFalse_SigLBFalse.gif"><img alt="../_images/singlegp_LNP_LatLBFalse_SigLBFalse.gif" src="../_images/singlegp_LNP_LatLBFalse_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="lower-bounded-std-of-latent">
<h4>Lower bounded std of latent<a class="headerlink" href="#lower-bounded-std-of-latent" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-lnp-latlbtrue-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_LNP_LatLBTrue_SigLBFalse.gif"><img alt="../_images/singlegp_LNP_LatLBTrue_SigLBFalse.gif" src="../_images/singlegp_LNP_LatLBTrue_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="lower-bounded-std-of-predictive">
<h4>Lower bounded std of predictive<a class="headerlink" href="#lower-bounded-std-of-predictive" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-lnp-latlbfalse-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_LNP_LatLBFalse_SigLBTrue.gif"><img alt="../_images/singlegp_LNP_LatLBFalse_SigLBTrue.gif" src="../_images/singlegp_LNP_LatLBFalse_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="both-lower-bounds">
<h4>Both Lower Bounds<a class="headerlink" href="#both-lower-bounds" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-lnp-latlbtrue-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_LNP_LatLBTrue_SigLBTrue.gif"><img alt="../_images/singlegp_LNP_LatLBTrue_SigLBTrue.gif" src="../_images/singlegp_LNP_LatLBTrue_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
</div>
</div>
<div class="section" id="attnlnp">
<h3>AttnLNP<a class="headerlink" href="#attnlnp" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id1">
<h4>No Lower bounds<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-attnlnp-latlbfalse-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_AttnLNP_LatLBFalse_SigLBFalse.gif"><img alt="../_images/singlegp_AttnLNP_LatLBFalse_SigLBFalse.gif" src="../_images/singlegp_AttnLNP_LatLBFalse_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id2">
<h4>Lower bounded std of latent<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-attnlnp-latlbtrue-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_AttnLNP_LatLBTrue_SigLBFalse.gif"><img alt="../_images/singlegp_AttnLNP_LatLBTrue_SigLBFalse.gif" src="../_images/singlegp_AttnLNP_LatLBTrue_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id3">
<h4>Lower bounded std of predictive<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-attnlnp-latlbfalse-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_AttnLNP_LatLBFalse_SigLBTrue.gif"><img alt="../_images/singlegp_AttnLNP_LatLBFalse_SigLBTrue.gif" src="../_images/singlegp_AttnLNP_LatLBFalse_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id4">
<h4>Both Lower Bounds<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-attnlnp-latlbtrue-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_AttnLNP_LatLBTrue_SigLBTrue.gif"><img alt="../_images/singlegp_AttnLNP_LatLBTrue_SigLBTrue.gif" src="../_images/singlegp_AttnLNP_LatLBTrue_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
</div>
</div>
<div class="section" id="convlnp">
<h3>ConvLNP<a class="headerlink" href="#convlnp" title="Permalink to this headline">¶</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For NPVI to train with ConvLNP we had to remove the global representation and decrease the number of channels to <code class="docutils literal notranslate"><span class="pre">z_dim=16</span></code>.
The models for NPVI and NPML are thus slighlty different.</p>
</div>
<div class="section" id="id5">
<h4>No Lower bounds<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-convlnp-latlbfalse-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_ConvLNP_LatLBFalse_SigLBFalse.gif"><img alt="../_images/singlegp_ConvLNP_LatLBFalse_SigLBFalse.gif" src="../_images/singlegp_ConvLNP_LatLBFalse_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id6">
<h4>Lower bounded std of latent<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-convlnp-latlbtrue-siglbfalse">
<a class="reference internal image-reference" href="../_images/singlegp_ConvLNP_LatLBTrue_SigLBFalse.gif"><img alt="../_images/singlegp_ConvLNP_LatLBTrue_SigLBFalse.gif" src="../_images/singlegp_ConvLNP_LatLBTrue_SigLBFalse.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id7">
<h4>Lower bounded std of predictive<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-convlnp-latlbfalse-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_ConvLNP_LatLBFalse_SigLBTrue.gif"><img alt="../_images/singlegp_ConvLNP_LatLBFalse_SigLBTrue.gif" src="../_images/singlegp_ConvLNP_LatLBFalse_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
</div>
<div class="section" id="id8">
<h4>Both Lower Bounds<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<div class="figure align-default" id="singlegp-convlnp-latlbtrue-siglbtrue">
<a class="reference internal image-reference" href="../_images/singlegp_ConvLNP_LatLBTrue_SigLBTrue.gif"><img alt="../_images/singlegp_ConvLNP_LatLBTrue_SigLBTrue.gif" src="../_images/singlegp_ConvLNP_LatLBTrue_SigLBTrue.gif" style="width: 60em;" /></a>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###### ADDITIONAL 1D PLOTS ######</span>

<span class="c1">#TO Chose</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./reproducibility"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ConvLNP.html" title="previous page">Convolutional Latent Neural Process (ConvLNP)</a>
    <a class='right-next' id="next-link" href="../zbibliography.html" title="next page">Bibliography</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois, Jonathan Gordon, ‪Andrew Foong<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.30270b6e4c972e43c488.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-108456313-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>