{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run No Abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/yannd/projects/Neural-Process-Family\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "from train_imgs import main, parse_arguments\n",
    "\n",
    "log_folder=\"logs/%j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_list(l, n):\n",
    "    return [i for i in l for _ in range(n)]\n",
    "\n",
    "class Run:\n",
    "    def checkpoint(self, args):\n",
    "        \"\"\"Resubmits the same callable with the same arguments but makes sure continnue from last chckpnt.\"\"\"\n",
    "        args.is_continue_train=True \n",
    "        return submitit.utils.DelayedSubmission(self, args)\n",
    "    \n",
    "    def __call__(self, args):\n",
    "        job_env = submitit.utils.JobEnvironment()\n",
    "        args.starting_run = args.starting_run * job_env.num_tasks + job_env.local_rank\n",
    "        return main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_params =[(\"\", \"\"),\n",
    "               (\"_nonorm\", \"--is-no-normalization\")]\n",
    "\n",
    "datasets = [\"celeba32\", \"mnist\", \"svhn\", \"celeba64\", \"zs-multi-mnist\"]\n",
    "\n",
    "\n",
    "args = [parse_arguments(\"GridedCCP {} --name GridedCCP_noabs{} --starting-run {} --chckpnt-dirname results/iclr/ --is-no-abs {}\".format(d, sffx, s, param).split())\n",
    "        for s in range(6)\n",
    "        for d in datasets\n",
    "        for sffx,param in named_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor=submitit.SlurmExecutor(folder=log_folder, max_num_timeout=3)\n",
    "executor.update_parameters(num_gpus=1, \n",
    "                           time=60*24*2,\n",
    "                           cpus_per_task=10,  \n",
    "                           ntasks_per_node=1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = executor.map_array(Run(), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitit WARNING (2019-09-24 17:29:38,545) - Call #3 - Bypassing sacct error Command '['sacct', '-o', 'JobID,State', '-j', '17930894']' returned non-zero exit status 1., status may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitit WARNING (2019-09-24 17:29:38,545) - Call #3 - Bypassing sacct error Command '['sacct', '-o', 'JobID,State', '-j', '17930894']' returned non-zero exit status 1., status may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:submitit:Call #3 - Bypassing sacct error Command '['sacct', '-o', 'JobID,State', '-j', '17930894']' returned non-zero exit status 1., status may be inaccurate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SlurmJob<job_id=17930894_0, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_1, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_2, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_3, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_4, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_5, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_6, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_7, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_8, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_9, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_10, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_11, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_12, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_13, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_14, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_15, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_16, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_17, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_18, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_19, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_20, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_21, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_22, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_23, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_24, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_25, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_26, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_27, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_28, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_29, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_30, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_31, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_32, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_33, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_34, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_35, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_36, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_37, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_38, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_39, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_40, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_41, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_42, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_43, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_44, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_45, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_46, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_47, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_48, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_49, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_50, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_51, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_52, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_53, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_54, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_55, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_56, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_57, task_id=0, state=\"RUNNING\">,\n",
       " SlurmJob<job_id=17930894_58, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=17930894_59, task_id=0, state=\"COMPLETED\">]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = job[0]\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Starting with JobEnvironment(job_id=17930894_0, hostname=learnfair0214, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_0/17930894_0_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0334\u001b[0m       \u001b[32m-2.7157\u001b[0m     +  839.3820\n",
      "      2       \u001b[36m-2.8454\u001b[0m       \u001b[32m-2.8510\u001b[0m     +  399.8569\n",
      "      3       \u001b[36m-2.9273\u001b[0m       \u001b[32m-3.0208\u001b[0m     +  375.1538\n",
      "      4       \u001b[36m-2.9810\u001b[0m       -2.9733        373.4595\n",
      "      5       \u001b[36m-2.9872\u001b[0m       \u001b[32m-3.0322\u001b[0m     +  382.9210\n",
      "      6       \u001b[36m-3.0180\u001b[0m       -2.9996        396.3314\n",
      "      7       \u001b[36m-3.0290\u001b[0m       -3.0156        392.6032\n",
      "      8       \u001b[36m-3.0419\u001b[0m       \u001b[32m-3.0675\u001b[0m     +  409.7848\n",
      "      9       \u001b[36m-3.0440\u001b[0m       -3.0406        393.2299\n",
      "     10       \u001b[36m-3.0541\u001b[0m       -3.0407        395.1583\n",
      "     11       \u001b[36m-3.0594\u001b[0m       -3.0485        401.4255\n",
      "     12       \u001b[36m-3.0607\u001b[0m       -3.0387        403.0861\n",
      "     13       \u001b[36m-3.0754\u001b[0m       \u001b[32m-3.1181\u001b[0m     +  401.5155\n",
      "     14       \u001b[36m-3.0813\u001b[0m       -3.0599        403.9328\n",
      "     15       \u001b[36m-3.0876\u001b[0m       \u001b[32m-3.1500\u001b[0m     +  393.9521\n",
      "     16       -3.0866       \u001b[32m-3.1593\u001b[0m     +  372.5722\n",
      "     17       \u001b[36m-3.0889\u001b[0m       -3.0923        369.9885\n",
      "     18       \u001b[36m-3.0955\u001b[0m       -3.1364        388.4037\n",
      "     19       \u001b[36m-3.0980\u001b[0m       -3.0327        440.4097\n",
      "     20       \u001b[36m-3.1067\u001b[0m       \u001b[32m-3.1749\u001b[0m     +  407.0229\n",
      "     21       -3.0972       -3.1049        407.3269\n",
      "     22       -3.1032       -3.1587        404.9543\n",
      "     23       -3.0953       -3.0944        448.6642\n",
      "     24       -3.0986       -3.1061        442.1709\n",
      "     25       -3.0924       -3.1312        451.3474\n",
      "     26       \u001b[36m-3.1277\u001b[0m       -3.0970        606.4183\n",
      "     27       -3.1070       -3.0735        473.3381\n",
      "     28       -3.1109       -3.0792        427.9203\n",
      "     29       -3.0980       -3.1673        417.1149\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_0 | best epoch: 20 | train loss: -3.1067 | valid loss: -3.1749 | test log likelihood: 3.0762\n",
      "submitit INFO (2019-09-21 12:50:20,322) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Starting with JobEnvironment(job_id=17930894_1, hostname=learnfair0214, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_1/17930894_1_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.9291\u001b[0m       \u001b[32m-2.8180\u001b[0m     +  838.9651\n",
      "      2       \u001b[36m-2.8706\u001b[0m       \u001b[32m-2.9474\u001b[0m     +  398.1635\n",
      "      3       \u001b[36m-2.9875\u001b[0m       \u001b[32m-3.0764\u001b[0m     +  431.5178\n",
      "      4       \u001b[36m-3.0367\u001b[0m       -3.0167        475.5056\n",
      "      5       \u001b[36m-3.0568\u001b[0m       \u001b[32m-3.1088\u001b[0m     +  490.3517\n",
      "      6       \u001b[36m-3.0958\u001b[0m       -3.0815        413.9089\n",
      "      7       \u001b[36m-3.1069\u001b[0m       -3.0964        429.1553\n",
      "      8       \u001b[36m-3.1253\u001b[0m       \u001b[32m-3.1437\u001b[0m     +  413.4188\n",
      "      9       \u001b[36m-3.1269\u001b[0m       -3.1335        414.8147\n",
      "     10       \u001b[36m-3.1405\u001b[0m       -3.1219        414.1920\n",
      "     11       \u001b[36m-3.1493\u001b[0m       -3.1301        405.4839\n",
      "     12       \u001b[36m-3.1497\u001b[0m       -3.1164        399.2242\n",
      "     13       \u001b[36m-3.1610\u001b[0m       \u001b[32m-3.1887\u001b[0m     +  400.9549\n",
      "     14       \u001b[36m-3.1693\u001b[0m       -3.1448        400.3673\n",
      "     15       \u001b[36m-3.1777\u001b[0m       \u001b[32m-3.2295\u001b[0m     +  379.8128\n",
      "     16       \u001b[36m-3.1797\u001b[0m       \u001b[32m-3.2537\u001b[0m     +  372.7122\n",
      "     17       -3.1780       -3.1704        388.3946\n",
      "     18       \u001b[36m-3.1842\u001b[0m       -3.2254        457.5863\n",
      "     19       \u001b[36m-3.1869\u001b[0m       -3.1313        437.6965\n",
      "     20       \u001b[36m-3.1970\u001b[0m       \u001b[32m-3.2607\u001b[0m     +  436.6044\n",
      "     21       -3.1885       -3.1970        433.6372\n",
      "     22       -3.1929       -3.2388        521.3627\n",
      "     23       -3.1857       -3.1979        556.2852\n",
      "     24       -3.1883       -3.1877        696.1009\n",
      "     25       -3.1797       -3.2074        594.8308\n",
      "     26       \u001b[36m-3.2146\u001b[0m       -3.1847        539.8374\n",
      "     27       -3.1946       -3.1590        588.1399\n",
      "     28       -3.1972       -3.2346        860.1529\n",
      "     29       -3.1861       -3.2112        741.3813\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_0 | best epoch: 20 | train loss: -3.197 | valid loss: -3.2607 | test log likelihood: 3.1671\n",
      "submitit INFO (2019-09-21 13:21:49,417) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Starting with JobEnvironment(job_id=17930894_2, hostname=learnfair0214, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,592) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_2/17930894_2_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7721\u001b[0m       \u001b[32m-0.8948\u001b[0m     +  71.2096\n",
      "      2       \u001b[36m-0.9330\u001b[0m       \u001b[32m-0.9799\u001b[0m     +  72.6736\n",
      "      3       \u001b[36m-1.0011\u001b[0m       \u001b[32m-1.0275\u001b[0m     +  73.0816\n",
      "      4       \u001b[36m-1.0488\u001b[0m       \u001b[32m-1.0607\u001b[0m     +  73.3107\n",
      "      5       \u001b[36m-1.0674\u001b[0m       \u001b[32m-1.0797\u001b[0m     +  72.3292\n",
      "      6       \u001b[36m-1.0904\u001b[0m       -1.0743        74.2503\n",
      "      7       \u001b[36m-1.1016\u001b[0m       \u001b[32m-1.1015\u001b[0m     +  72.4144\n",
      "      8       \u001b[36m-1.1188\u001b[0m       \u001b[32m-1.1051\u001b[0m     +  73.6152\n",
      "      9       -1.1126       \u001b[32m-1.1239\u001b[0m     +  73.5586\n",
      "     10       \u001b[36m-1.1217\u001b[0m       \u001b[32m-1.1284\u001b[0m     +  73.0478\n",
      "     11       \u001b[36m-1.1332\u001b[0m       -1.1247        72.5353\n",
      "     12       -1.1327       \u001b[32m-1.1622\u001b[0m     +  72.8124\n",
      "     13       -1.1301       -1.1477        73.0925\n",
      "     14       \u001b[36m-1.1378\u001b[0m       -1.1321        71.6831\n",
      "     15       -1.1366       -1.1328        72.8005\n",
      "     16       \u001b[36m-1.1552\u001b[0m       -1.1529        72.6879\n",
      "     17       -1.1548       -1.1581        73.2509\n",
      "     18       -1.1540       -1.1586        72.7487\n",
      "     19       \u001b[36m-1.1604\u001b[0m       -1.1534        73.0495\n",
      "     20       \u001b[36m-1.1612\u001b[0m       \u001b[32m-1.1670\u001b[0m     +  72.0956\n",
      "     21       \u001b[36m-1.1648\u001b[0m       -1.1526        73.8095\n",
      "     22       \u001b[36m-1.1667\u001b[0m       \u001b[32m-1.1837\u001b[0m     +  74.6280\n",
      "     23       \u001b[36m-1.1725\u001b[0m       -1.1558        73.8853\n",
      "     24       -1.1665       \u001b[32m-1.1853\u001b[0m     +  75.0867\n",
      "     25       -1.1705       -1.1717        74.3045\n",
      "     26       -1.1667       -1.1649        74.0018\n",
      "     27       -1.1724       \u001b[32m-1.2041\u001b[0m     +  74.2803\n",
      "     28       \u001b[36m-1.1765\u001b[0m       -1.1864        75.0999\n",
      "     29       -1.1742       -1.1727        75.1516\n",
      "     30       -1.1751       -1.1535        74.4575\n",
      "     31       -1.1747       -1.1941        74.3414\n",
      "     32       \u001b[36m-1.1782\u001b[0m       -1.1787        75.2840\n",
      "     33       \u001b[36m-1.1784\u001b[0m       -1.1840        74.4938\n",
      "     34       \u001b[36m-1.1791\u001b[0m       -1.1616        75.3765\n",
      "     35       -1.1768       -1.1836        75.5097\n",
      "     36       \u001b[36m-1.1797\u001b[0m       -1.1900        75.3024\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_0 | best epoch: 27 | train loss: -1.1725 | valid loss: -1.2041 | test log likelihood: 1.1602\n",
      "submitit INFO (2019-09-21 09:55:27,061) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,627) - Starting with JobEnvironment(job_id=17930894_3, hostname=learnfair0238, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,627) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_3/17930894_3_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-0.7900\u001b[0m       \u001b[32m-1.0259\u001b[0m     +  105.3276\n",
      "      2       \u001b[36m-1.0802\u001b[0m       \u001b[32m-1.1344\u001b[0m     +  111.1200\n",
      "      3       \u001b[36m-1.1512\u001b[0m       \u001b[32m-1.1587\u001b[0m     +  124.3693\n",
      "      4       \u001b[36m-1.1629\u001b[0m       \u001b[32m-1.1646\u001b[0m     +  122.2729\n",
      "      5       \u001b[36m-1.1677\u001b[0m       \u001b[32m-1.1748\u001b[0m     +  122.3223\n",
      "      6       \u001b[36m-1.1780\u001b[0m       -1.1697        92.9182\n",
      "      7       \u001b[36m-1.1796\u001b[0m       \u001b[32m-1.1766\u001b[0m     +  104.0843\n",
      "      8       \u001b[36m-1.1945\u001b[0m       \u001b[32m-1.1885\u001b[0m     +  94.4789\n",
      "      9       -1.1885       \u001b[32m-1.1949\u001b[0m     +  105.0320\n",
      "     10       -1.1931       \u001b[32m-1.2033\u001b[0m     +  99.5357\n",
      "     11       \u001b[36m-1.1998\u001b[0m       -1.1973        91.0866\n",
      "     12       -1.1992       \u001b[32m-1.2201\u001b[0m     +  90.0427\n",
      "     13       -1.1965       -1.2099        89.7867\n",
      "     14       -1.1972       -1.1933        90.2444\n",
      "     15       -1.1984       -1.1964        95.9535\n",
      "     16       \u001b[36m-1.2078\u001b[0m       -1.2057        88.1328\n",
      "     17       -1.2035       -1.2091        88.9724\n",
      "     18       -1.2066       -1.1979        90.3507\n",
      "     19       -1.2063       -1.1951        93.0656\n",
      "     20       -1.2041       -1.2076        93.5350\n",
      "     21       -1.2045       -1.2140        88.8919\n",
      "     22       -1.2066       \u001b[32m-1.2249\u001b[0m     +  90.2723\n",
      "     23       \u001b[36m-1.2124\u001b[0m       -1.1996        90.4292\n",
      "     24       -1.2065       -1.2206        93.3540\n",
      "     25       -1.2082       -1.2085        90.6823\n",
      "     26       -1.2045       -1.2026        85.8038\n",
      "     27       -1.2101       \u001b[32m-1.2357\u001b[0m     +  90.6866\n",
      "     28       \u001b[36m-1.2135\u001b[0m       -1.2205        90.1489\n",
      "     29       -1.2104       -1.2099        92.6061\n",
      "     30       -1.2106       -1.1891        91.1933\n",
      "     31       -1.2103       -1.2256        89.1497\n",
      "     32       -1.2133       -1.2140        90.5594\n",
      "     33       -1.2126       -1.2183        89.3200\n",
      "     34       -1.2133       -1.1948        90.7383\n",
      "     35       -1.2131       -1.2174        91.2110\n",
      "     36       \u001b[36m-1.2138\u001b[0m       -1.2212        90.7640\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_0 | best epoch: 27 | train loss: -1.2124 | valid loss: -1.2357 | test log likelihood: 1.1942\n",
      "submitit INFO (2019-09-21 10:08:57,245) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,536) - Starting with JobEnvironment(job_id=17930894_4, hostname=learnfair0257, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,536) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_4/17930894_4_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0854\u001b[0m       \u001b[32m-2.9548\u001b[0m     +  445.3209\n",
      "      2       \u001b[36m-3.1886\u001b[0m       \u001b[32m-3.4110\u001b[0m     +  449.5243\n",
      "      3       \u001b[36m-3.5883\u001b[0m       \u001b[32m-3.6706\u001b[0m     +  463.5294\n",
      "      4       \u001b[36m-3.6786\u001b[0m       \u001b[32m-3.7118\u001b[0m     +  438.9165\n",
      "      5       \u001b[36m-3.7287\u001b[0m       \u001b[32m-3.7877\u001b[0m     +  457.2047\n",
      "      6       \u001b[36m-3.7566\u001b[0m       -3.7874        457.8833\n",
      "      7       \u001b[36m-3.7752\u001b[0m       \u001b[32m-3.8048\u001b[0m     +  444.4789\n",
      "      8       -3.7663       \u001b[32m-3.8268\u001b[0m     +  466.8583\n",
      "      9       \u001b[36m-3.7989\u001b[0m       -3.7469        379.3524\n",
      "     10       \u001b[36m-3.8004\u001b[0m       -3.8151        277.7113\n",
      "     11       -3.7990       -3.8054        271.3640\n",
      "     12       \u001b[36m-3.8131\u001b[0m       \u001b[32m-3.8303\u001b[0m     +  267.5234\n",
      "     13       \u001b[36m-3.8341\u001b[0m       -3.8055        252.4169\n",
      "     14       -3.8253       \u001b[32m-3.8363\u001b[0m     +  285.4292\n",
      "     15       -3.8246       -3.8325        262.4261\n",
      "     16       -3.8318       \u001b[32m-3.8385\u001b[0m     +  254.8978\n",
      "     17       -3.8273       -3.6467        184.5298\n",
      "     18       \u001b[36m-3.8348\u001b[0m       \u001b[32m-3.9062\u001b[0m     +  225.8165\n",
      "     19       \u001b[36m-3.8437\u001b[0m       -3.8842        199.1344\n",
      "     20       -3.8351       \u001b[32m-3.9092\u001b[0m     +  284.2648\n",
      "     21       -3.8241       -3.8487        372.1129\n",
      "     22       \u001b[36m-3.8448\u001b[0m       -3.8737        177.0489\n",
      "     23       \u001b[36m-3.8548\u001b[0m       -3.8450        140.4674\n",
      "     24       -3.8473       -3.8644        114.0979\n",
      "     25       -3.8451       -3.8984        128.5729\n",
      "     26       -3.8441       -3.8645        135.2254\n",
      "     27       \u001b[36m-3.8588\u001b[0m       -3.8485        124.9432\n",
      "     28       -3.8543       -3.8361        106.7662\n",
      "     29       \u001b[36m-3.8620\u001b[0m       -3.8333        106.4040\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_0 | best epoch: 20 | train loss: -3.8437 | valid loss: -3.9092 | test log likelihood: 3.8413\n",
      "submitit INFO (2019-09-21 11:28:50,990) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,536) - Starting with JobEnvironment(job_id=17930894_5, hostname=learnfair0257, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,536) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_5/17930894_5_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.9177\u001b[0m       \u001b[32m-3.1853\u001b[0m     +  103.9781\n",
      "      2       \u001b[36m-3.2955\u001b[0m       \u001b[32m-3.4624\u001b[0m     +  102.4985\n",
      "      3       \u001b[36m-3.5489\u001b[0m       \u001b[32m-3.6519\u001b[0m     +  102.8501\n",
      "      4       \u001b[36m-3.6144\u001b[0m       -3.3379        103.8349\n",
      "      5       \u001b[36m-3.6933\u001b[0m       \u001b[32m-3.7434\u001b[0m     +  102.5401\n",
      "      6       \u001b[36m-3.7460\u001b[0m       \u001b[32m-3.8294\u001b[0m     +  102.5555\n",
      "      7       \u001b[36m-3.7844\u001b[0m       \u001b[32m-3.8370\u001b[0m     +  102.9604\n",
      "      8       \u001b[36m-3.7881\u001b[0m       \u001b[32m-3.8387\u001b[0m     +  102.2565\n",
      "      9       \u001b[36m-3.8122\u001b[0m       -3.8025        102.6039\n",
      "     10       -3.8092       -3.8199        102.8285\n",
      "     11       \u001b[36m-3.8165\u001b[0m       -3.8284        103.6421\n",
      "     12       \u001b[36m-3.8362\u001b[0m       \u001b[32m-3.8424\u001b[0m     +  102.5222\n",
      "     13       \u001b[36m-3.8543\u001b[0m       -3.6662        102.8333\n",
      "     14       -3.8498       \u001b[32m-3.8626\u001b[0m     +  102.5596\n",
      "     15       -3.8468       -3.7681        99.1980\n",
      "     16       \u001b[36m-3.8567\u001b[0m       -3.8588        100.1727\n",
      "     17       \u001b[36m-3.8587\u001b[0m       \u001b[32m-3.8883\u001b[0m     +  100.1191\n",
      "     18       \u001b[36m-3.8605\u001b[0m       \u001b[32m-3.9186\u001b[0m     +  100.1352\n",
      "     19       \u001b[36m-3.8724\u001b[0m       -3.8967        102.8963\n",
      "     20       -3.8639       \u001b[32m-3.9242\u001b[0m     +  102.7215\n",
      "     21       -3.8494       -3.8627        102.5056\n",
      "     22       \u001b[36m-3.8743\u001b[0m       -3.8920        102.7315\n",
      "     23       \u001b[36m-3.8816\u001b[0m       -3.8364        102.9275\n",
      "     24       -3.8747       -3.8839        102.8835\n",
      "     25       -3.8753       -3.9162        102.6241\n",
      "     26       -3.8726       -3.8899        102.7985\n",
      "     27       \u001b[36m-3.8878\u001b[0m       -3.8907        103.1350\n",
      "     28       -3.8869       -3.8773        103.1214\n",
      "     29       \u001b[36m-3.8892\u001b[0m       -3.8473        103.3221\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_0 | best epoch: 20 | train loss: -3.8724 | valid loss: -3.9242 | test log likelihood: 3.8585\n",
      "submitit INFO (2019-09-21 10:01:29,738) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,497) - Starting with JobEnvironment(job_id=17930894_6, hostname=learnfair0265, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,497) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_6/17930894_6_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.5017\u001b[0m       \u001b[32m-3.2714\u001b[0m     +  1077.4143\n",
      "      2       \u001b[36m-3.3038\u001b[0m       \u001b[32m-3.4024\u001b[0m     +  720.4718\n",
      "      3       \u001b[36m-3.3963\u001b[0m       \u001b[32m-3.4713\u001b[0m     +  722.5090\n",
      "      4       \u001b[36m-3.4352\u001b[0m       -3.4220        778.5006\n",
      "      5       \u001b[36m-3.4441\u001b[0m       \u001b[32m-3.4853\u001b[0m     +  726.5082\n",
      "      6       \u001b[36m-3.4719\u001b[0m       -3.4493        737.4147\n",
      "      7       \u001b[36m-3.4816\u001b[0m       \u001b[32m-3.4897\u001b[0m     +  687.6991\n",
      "      8       \u001b[36m-3.4915\u001b[0m       \u001b[32m-3.5227\u001b[0m     +  673.0231\n",
      "      9       \u001b[36m-3.4959\u001b[0m       -3.4956        664.5462\n",
      "     10       \u001b[36m-3.5078\u001b[0m       \u001b[32m-3.5314\u001b[0m     +  653.4638\n",
      "     11       \u001b[36m-3.5182\u001b[0m       \u001b[32m-3.5407\u001b[0m     +  725.6960\n",
      "     12       -3.5177       -3.4200        693.4096\n",
      "     13       \u001b[36m-3.5284\u001b[0m       -3.4664        673.3231\n",
      "     14       \u001b[36m-3.5325\u001b[0m       -3.5183        714.1263\n",
      "     15       \u001b[36m-3.5427\u001b[0m       \u001b[32m-3.5645\u001b[0m     +  718.7358\n",
      "     16       -3.5418       -3.5333        657.3302\n",
      "     17       -3.5406       -3.5543        630.8301\n",
      "     18       \u001b[36m-3.5451\u001b[0m       -3.5636        670.8662\n",
      "     19       \u001b[36m-3.5507\u001b[0m       -3.5541        689.3350\n",
      "     20       \u001b[36m-3.5612\u001b[0m       \u001b[32m-3.6283\u001b[0m     +  654.1806\n",
      "     21       -3.5521       -3.5824        648.2664\n",
      "     22       -3.5547       -3.5366        652.2709\n",
      "     23       -3.5511       -3.5585        650.8046\n",
      "     24       -3.5499       -3.5683        644.3951\n",
      "     25       -3.5455       -3.5909        677.5557\n",
      "     26       \u001b[36m-3.5691\u001b[0m       -3.5921        800.0060\n",
      "     27       -3.5560       -3.5524        784.6502\n",
      "     28       -3.5645       -3.5577        823.4563\n",
      "     29       -3.5577       -3.4356        797.0121\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_0 | best epoch: 20 | train loss: -3.5612 | valid loss: -3.6283 | test log likelihood: 3.5558\n",
      "submitit INFO (2019-09-21 15:13:17,718) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,521) - Starting with JobEnvironment(job_id=17930894_7, hostname=learnfair0293, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,521) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_7/17930894_7_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.6547\u001b[0m       \u001b[32m-3.3496\u001b[0m     +  932.8541\n",
      "      2       \u001b[36m-3.3711\u001b[0m       \u001b[32m-3.4407\u001b[0m     +  555.1663\n",
      "      3       \u001b[36m-3.4637\u001b[0m       \u001b[32m-3.5355\u001b[0m     +  531.9914\n",
      "      4       \u001b[36m-3.5110\u001b[0m       -3.5070        534.8084\n",
      "      5       \u001b[36m-3.5241\u001b[0m       \u001b[32m-3.5571\u001b[0m     +  525.0424\n",
      "      6       \u001b[36m-3.5524\u001b[0m       -3.5322        547.2222\n",
      "      7       \u001b[36m-3.5598\u001b[0m       -3.5076        546.2767\n",
      "      8       \u001b[36m-3.5710\u001b[0m       \u001b[32m-3.5824\u001b[0m     +  558.7086\n",
      "      9       \u001b[36m-3.5787\u001b[0m       -3.5600        557.5477\n",
      "     10       \u001b[36m-3.5862\u001b[0m       \u001b[32m-3.5950\u001b[0m     +  553.8427\n",
      "     11       \u001b[36m-3.5939\u001b[0m       \u001b[32m-3.5981\u001b[0m     +  558.3320\n",
      "     12       -3.5922       -3.5665        543.9102\n",
      "     13       \u001b[36m-3.6039\u001b[0m       -3.5969        544.0380\n",
      "     14       \u001b[36m-3.6070\u001b[0m       -3.5807        577.8278\n",
      "     15       \u001b[36m-3.6146\u001b[0m       \u001b[32m-3.6382\u001b[0m     +  567.8523\n",
      "     16       \u001b[36m-3.6160\u001b[0m       -3.6259        555.3330\n",
      "     17       -3.6135       -3.6182        568.6663\n",
      "     18       \u001b[36m-3.6163\u001b[0m       -3.6234        583.8075\n",
      "     19       \u001b[36m-3.6195\u001b[0m       -3.6083        596.4170\n",
      "     20       \u001b[36m-3.6292\u001b[0m       \u001b[32m-3.6789\u001b[0m     +  573.6970\n",
      "     21       -3.6181       -3.6596        563.6836\n",
      "     22       -3.6243       -3.6150        548.7932\n",
      "     23       -3.6203       -3.6191        611.8599\n",
      "     24       -3.6206       -3.6297        605.1355\n",
      "     25       -3.6167       -3.6517        563.3327\n",
      "     26       \u001b[36m-3.6371\u001b[0m       -3.5746        560.8130\n",
      "     27       -3.6258       -3.6186        568.6321\n",
      "     28       -3.6299       -3.6265        566.7120\n",
      "     29       -3.6242       -3.6085        564.2281\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_0 | best epoch: 20 | train loss: -3.6292 | valid loss: -3.6789 | test log likelihood: 3.6138\n",
      "submitit INFO (2019-09-21 14:00:13,588) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,521) - Starting with JobEnvironment(job_id=17930894_8, hostname=learnfair0293, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,521) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_8/17930894_8_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-1.1556\u001b[0m       \u001b[32m-1.2158\u001b[0m     +  92.6744\n",
      "      2       \u001b[36m-1.2333\u001b[0m       \u001b[32m-1.2346\u001b[0m     +  95.6660\n",
      "      3       \u001b[36m-1.2440\u001b[0m       \u001b[32m-1.2487\u001b[0m     +  95.5174\n",
      "      4       \u001b[36m-1.2462\u001b[0m       -1.2482        94.6245\n",
      "      5       \u001b[36m-1.2534\u001b[0m       \u001b[32m-1.2597\u001b[0m     +  94.6364\n",
      "      6       \u001b[36m-1.2582\u001b[0m       \u001b[32m-1.2693\u001b[0m     +  94.6359\n",
      "      7       \u001b[36m-1.2584\u001b[0m       -1.2497        94.8044\n",
      "      8       \u001b[36m-1.2599\u001b[0m       \u001b[32m-1.2793\u001b[0m     +  94.5297\n",
      "      9       \u001b[36m-1.2621\u001b[0m       -1.2663        95.5519\n",
      "     10       \u001b[36m-1.2629\u001b[0m       -1.2532        95.5533\n",
      "     11       -1.2615       -1.2626        95.6611\n",
      "     12       \u001b[36m-1.2687\u001b[0m       -1.2741        95.6146\n",
      "     13       -1.2677       -1.2639        95.7402\n",
      "     14       -1.2683       -1.2604        95.7821\n",
      "     15       -1.2681       -1.2573        95.5745\n",
      "     16       -1.2672       \u001b[32m-1.2798\u001b[0m     +  95.7329\n",
      "     17       \u001b[36m-1.2698\u001b[0m       -1.2683        94.6762\n",
      "     18       \u001b[36m-1.2702\u001b[0m       -1.2714        94.4812\n",
      "     19       -1.2665       -1.2754        94.5872\n",
      "     20       -1.2656       -1.2748        94.4906\n",
      "     21       -1.2679       -1.2692        94.7250\n",
      "     22       -1.2671       -1.2648        95.4094\n",
      "     23       -1.2655       -1.2767        95.6751\n",
      "     24       -1.2631       -1.2624        95.1729\n",
      "     25       -1.2690       -1.2645        94.4779\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_0 | best epoch: 16 | train loss: -1.2687 | valid loss: -1.2798 | test log likelihood: 1.1431\n",
      "submitit INFO (2019-09-21 09:50:58,445) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,553) - Starting with JobEnvironment(job_id=17930894_9, hostname=learnfair0317, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,554) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_9/17930894_9_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1498\u001b[0m       \u001b[32m-1.2196\u001b[0m     +  105.4812\n",
      "      2       \u001b[36m-1.2405\u001b[0m       \u001b[32m-1.2514\u001b[0m     +  104.6712\n",
      "      3       \u001b[36m-1.2614\u001b[0m       \u001b[32m-1.2718\u001b[0m     +  104.5753\n",
      "      4       \u001b[36m-1.2719\u001b[0m       \u001b[32m-1.2834\u001b[0m     +  105.3869\n",
      "      5       \u001b[36m-1.2853\u001b[0m       \u001b[32m-1.2901\u001b[0m     +  105.9313\n",
      "      6       \u001b[36m-1.2889\u001b[0m       \u001b[32m-1.3002\u001b[0m     +  104.7816\n",
      "      7       \u001b[36m-1.2899\u001b[0m       -1.2855        105.8334\n",
      "      8       \u001b[36m-1.2913\u001b[0m       \u001b[32m-1.3103\u001b[0m     +  105.6443\n",
      "      9       \u001b[36m-1.2931\u001b[0m       -1.2962        105.4230\n",
      "     10       \u001b[36m-1.2946\u001b[0m       -1.2844        105.8723\n",
      "     11       -1.2925       -1.2902        106.1536\n",
      "     12       \u001b[36m-1.2991\u001b[0m       -1.3034        105.8647\n",
      "     13       -1.2974       -1.2964        105.7705\n",
      "     14       -1.2983       -1.2939        104.6652\n",
      "     15       -1.2980       -1.2888        104.9899\n",
      "     16       -1.2977       -1.3093        105.0297\n",
      "     17       \u001b[36m-1.3009\u001b[0m       -1.2979        104.8539\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_0 | best epoch: 8 | train loss: -1.2913 | valid loss: -1.3103 | test log likelihood: 1.1908\n",
      "submitit INFO (2019-09-21 09:41:21,609) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:09,802) - Starting with JobEnvironment(job_id=17930894_10, hostname=learnfair0321, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:09,802) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_10/17930894_10_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0024\u001b[0m       \u001b[32m-2.7017\u001b[0m     +  823.6938\n",
      "      2       \u001b[36m-2.8517\u001b[0m       \u001b[32m-2.9288\u001b[0m     +  412.9053\n",
      "      3       \u001b[36m-2.9206\u001b[0m       \u001b[32m-2.9487\u001b[0m     +  398.1293\n",
      "      4       \u001b[36m-2.9485\u001b[0m       \u001b[32m-3.0091\u001b[0m     +  388.9234\n",
      "      5       \u001b[36m-2.9780\u001b[0m       \u001b[32m-3.0690\u001b[0m     +  400.9388\n",
      "      6       \u001b[36m-3.0189\u001b[0m       -3.0106        400.8659\n",
      "      7       \u001b[36m-3.0198\u001b[0m       -3.0670        409.3459\n",
      "      8       \u001b[36m-3.0414\u001b[0m       \u001b[32m-3.1248\u001b[0m     +  405.8236\n",
      "      9       \u001b[36m-3.0603\u001b[0m       -3.0215        412.5370\n",
      "     10       -3.0493       -3.0249        412.4185\n",
      "     11       \u001b[36m-3.0607\u001b[0m       -3.0531        413.2703\n",
      "     12       \u001b[36m-3.0668\u001b[0m       -3.0423        412.6309\n",
      "     13       \u001b[36m-3.0747\u001b[0m       -3.0337        416.1211\n",
      "     14       \u001b[36m-3.0755\u001b[0m       -3.0457        403.9325\n",
      "     15       \u001b[36m-3.0840\u001b[0m       -3.0495        408.5180\n",
      "     16       -3.0696       \u001b[32m-3.1250\u001b[0m     +  394.2072\n",
      "     17       -3.0726       -3.0898        396.1386\n",
      "     18       -3.0751       -3.0756        432.5786\n",
      "     19       \u001b[36m-3.0858\u001b[0m       -3.1084        419.3879\n",
      "     20       \u001b[36m-3.0914\u001b[0m       -3.0744        399.4331\n",
      "     21       -3.0893       -3.1062        377.1075\n",
      "     22       \u001b[36m-3.0985\u001b[0m       -3.1155        380.0909\n",
      "     23       \u001b[36m-3.1012\u001b[0m       -3.1014        389.9215\n",
      "     24       \u001b[36m-3.1082\u001b[0m       -3.0371        412.4167\n",
      "     25       -3.0939       -3.1139        415.2559\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_1 | best epoch: 16 | train loss: -3.084 | valid loss: -3.125 | test log likelihood: 3.0655\n",
      "submitit INFO (2019-09-21 12:17:14,527) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Starting with JobEnvironment(job_id=17930894_11, hostname=learnfair0421, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_11/17930894_11_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0427\u001b[0m       \u001b[32m-2.7723\u001b[0m     +  696.1531\n",
      "      2       \u001b[36m-2.9024\u001b[0m       \u001b[32m-2.9939\u001b[0m     +  345.7982\n",
      "      3       \u001b[36m-2.9894\u001b[0m       \u001b[32m-3.0514\u001b[0m     +  352.2397\n",
      "      4       \u001b[36m-3.0421\u001b[0m       \u001b[32m-3.1293\u001b[0m     +  340.6364\n",
      "      5       \u001b[36m-3.0829\u001b[0m       \u001b[32m-3.1725\u001b[0m     +  333.6817\n",
      "      6       \u001b[36m-3.1220\u001b[0m       -3.1073        343.1316\n",
      "      7       \u001b[36m-3.1267\u001b[0m       -3.1622        345.9453\n",
      "      8       \u001b[36m-3.1429\u001b[0m       \u001b[32m-3.2113\u001b[0m     +  354.7401\n",
      "      9       \u001b[36m-3.1588\u001b[0m       -3.1373        353.8391\n",
      "     10       -3.1508       -3.1210        351.2506\n",
      "     11       \u001b[36m-3.1606\u001b[0m       -3.1451        353.2403\n",
      "     12       \u001b[36m-3.1651\u001b[0m       -3.1277        349.7682\n",
      "     13       \u001b[36m-3.1722\u001b[0m       -3.1296        353.7292\n",
      "     14       \u001b[36m-3.1727\u001b[0m       -3.1724        355.8697\n",
      "     15       \u001b[36m-3.1832\u001b[0m       -3.1632        353.1759\n",
      "     16       -3.1707       \u001b[32m-3.2193\u001b[0m     +  352.3970\n",
      "     17       -3.1761       -3.1816        350.8932\n",
      "     18       -3.1734       -3.1683        354.8510\n",
      "     19       \u001b[36m-3.1849\u001b[0m       -3.2002        337.3771\n",
      "     20       \u001b[36m-3.1904\u001b[0m       -3.1614        333.3324\n",
      "     21       -3.1858       -3.1976        409.4735\n",
      "     22       \u001b[36m-3.1950\u001b[0m       -3.2026        360.5465\n",
      "     23       \u001b[36m-3.1973\u001b[0m       -3.1987        360.4736\n",
      "     24       \u001b[36m-3.2035\u001b[0m       -3.2098        346.8195\n",
      "     25       -3.1901       -3.2175        343.8326\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_1 | best epoch: 16 | train loss: -3.1832 | valid loss: -3.2193 | test log likelihood: 3.1612\n",
      "submitit INFO (2019-09-21 11:51:28,031) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Starting with JobEnvironment(job_id=17930894_12, hostname=learnfair0450, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:12,607) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_12/17930894_12_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7394\u001b[0m       \u001b[32m-0.9240\u001b[0m     +  73.3696\n",
      "      2       \u001b[36m-0.9390\u001b[0m       \u001b[32m-0.9610\u001b[0m     +  72.3551\n",
      "      3       \u001b[36m-0.9988\u001b[0m       \u001b[32m-0.9798\u001b[0m     +  73.5150\n",
      "      4       \u001b[36m-1.0422\u001b[0m       \u001b[32m-1.0778\u001b[0m     +  74.7120\n",
      "      5       \u001b[36m-1.0625\u001b[0m       -1.0559        72.6085\n",
      "      6       \u001b[36m-1.0856\u001b[0m       \u001b[32m-1.0900\u001b[0m     +  71.9789\n",
      "      7       -1.0810       \u001b[32m-1.1007\u001b[0m     +  71.8562\n",
      "      8       \u001b[36m-1.0971\u001b[0m       -1.0765        72.0917\n",
      "      9       \u001b[36m-1.1024\u001b[0m       \u001b[32m-1.1162\u001b[0m     +  71.2221\n",
      "     10       \u001b[36m-1.1034\u001b[0m       -1.0875        73.4688\n",
      "     11       \u001b[36m-1.1105\u001b[0m       \u001b[32m-1.1182\u001b[0m     +  72.5450\n",
      "     12       \u001b[36m-1.1161\u001b[0m       \u001b[32m-1.1208\u001b[0m     +  71.1514\n",
      "     13       \u001b[36m-1.1321\u001b[0m       -1.1086        73.6823\n",
      "     14       -1.1319       \u001b[32m-1.1399\u001b[0m     +  74.9400\n",
      "     15       \u001b[36m-1.1330\u001b[0m       \u001b[32m-1.1670\u001b[0m     +  73.9833\n",
      "     16       \u001b[36m-1.1516\u001b[0m       -1.1042        74.1193\n",
      "     17       -1.1459       -1.1644        71.5015\n",
      "     18       \u001b[36m-1.1629\u001b[0m       -1.1623        71.2017\n",
      "     19       -1.1578       \u001b[32m-1.1754\u001b[0m     +  71.4596\n",
      "     20       \u001b[36m-1.1638\u001b[0m       \u001b[32m-1.1876\u001b[0m     +  72.2786\n",
      "     21       -1.1591       -1.1506        73.1078\n",
      "     22       \u001b[36m-1.1683\u001b[0m       -1.1793        71.8392\n",
      "     23       \u001b[36m-1.1703\u001b[0m       -1.1585        73.0378\n",
      "     24       \u001b[36m-1.1706\u001b[0m       -1.1800        72.4709\n",
      "     25       \u001b[36m-1.1826\u001b[0m       -1.1683        72.7684\n",
      "     26       -1.1680       \u001b[32m-1.1921\u001b[0m     +  72.8374\n",
      "     27       -1.1789       -1.1754        71.8178\n",
      "     28       -1.1769       -1.1440        71.1558\n",
      "     29       -1.1738       -1.1835        71.2291\n",
      "     30       -1.1756       -1.1718        71.4289\n",
      "     31       -1.1744       -1.1692        71.2180\n",
      "     32       \u001b[36m-1.1839\u001b[0m       -1.1808        72.1493\n",
      "     33       -1.1728       -1.1558        71.7905\n",
      "     34       -1.1800       -1.1875        73.2957\n",
      "     35       -1.1716       -1.1333        71.5568\n",
      "     36       -1.1830       \u001b[32m-1.1948\u001b[0m     +  71.6743\n",
      "     37       -1.1782       -1.1932        71.4426\n",
      "     38       -1.1805       -1.1834        71.9980\n",
      "     39       -1.1836       -1.1911        71.6036\n",
      "     40       -1.1802       -1.1837        72.0046\n",
      "     41       -1.1830       -1.1633        71.6500\n",
      "     42       -1.1834       \u001b[32m-1.2183\u001b[0m     +  71.4924\n",
      "     43       -1.1818       -1.1819        71.6456\n",
      "     44       \u001b[36m-1.1850\u001b[0m       -1.1923        71.3328\n",
      "     45       \u001b[36m-1.1912\u001b[0m       -1.1909        71.1225\n",
      "     46       -1.1830       -1.1675        71.3496\n",
      "     47       -1.1779       -1.1740        71.6704\n",
      "     48       -1.1789       -1.1861        71.5991\n",
      "     49       -1.1835       -1.1898        72.2061\n",
      "     50       -1.1858       -1.1785        72.7749\n",
      "     51       -1.1894       -1.1627        71.9308\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_1 | best epoch: 42 | train loss: -1.1839 | valid loss: -1.2183 | test log likelihood: 1.1702\n",
      "submitit INFO (2019-09-21 10:12:57,822) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Starting with JobEnvironment(job_id=17930894_13, hostname=learnfair0469, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_13/17930894_13_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.8253\u001b[0m       \u001b[32m-1.0868\u001b[0m     +  82.1728\n",
      "      2       \u001b[36m-1.1018\u001b[0m       \u001b[32m-1.1314\u001b[0m     +  77.2316\n",
      "      3       \u001b[36m-1.1408\u001b[0m       -1.1238        80.3646\n",
      "      4       \u001b[36m-1.1658\u001b[0m       \u001b[32m-1.1877\u001b[0m     +  79.1635\n",
      "      5       \u001b[36m-1.1690\u001b[0m       -1.1277        78.3105\n",
      "      6       \u001b[36m-1.1825\u001b[0m       -1.1810        81.7580\n",
      "      7       \u001b[36m-1.1833\u001b[0m       -1.1790        71.7418\n",
      "      8       \u001b[36m-1.1883\u001b[0m       -1.1662        82.7027\n",
      "      9       \u001b[36m-1.1905\u001b[0m       \u001b[32m-1.2051\u001b[0m     +  70.5574\n",
      "     10       -1.1894       -1.1733        80.5380\n",
      "     11       \u001b[36m-1.1921\u001b[0m       \u001b[32m-1.2095\u001b[0m     +  77.6382\n",
      "     12       \u001b[36m-1.1938\u001b[0m       -1.1965        81.0744\n",
      "     13       \u001b[36m-1.2034\u001b[0m       -1.1875        80.5607\n",
      "     14       -1.2002       -1.1959        73.5110\n",
      "     15       -1.1962       \u001b[32m-1.2215\u001b[0m     +  77.7678\n",
      "     16       \u001b[36m-1.2087\u001b[0m       -1.1989        67.6549\n",
      "     17       -1.2022       -1.2096        77.7259\n",
      "     18       \u001b[36m-1.2127\u001b[0m       -1.2082        76.7409\n",
      "     19       -1.2077       \u001b[32m-1.2247\u001b[0m     +  79.0596\n",
      "     20       -1.2089       \u001b[32m-1.2317\u001b[0m     +  67.3426\n",
      "     21       -1.2039       -1.1956        80.4328\n",
      "     22       -1.2097       -1.2125        92.0682\n",
      "     23       -1.2107       -1.1992        82.6805\n",
      "     24       -1.2118       -1.2163        80.2280\n",
      "     25       \u001b[36m-1.2216\u001b[0m       -1.2066        79.9666\n",
      "     26       -1.2066       -1.2269        78.7055\n",
      "     27       -1.2173       -1.2145        73.2697\n",
      "     28       -1.2159       -1.1844        67.0179\n",
      "     29       -1.2118       -1.2215        65.0805\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_1 | best epoch: 20 | train loss: -1.2127 | valid loss: -1.2317 | test log likelihood: 1.1942\n",
      "submitit INFO (2019-09-21 09:48:18,026) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:12,760) - Starting with JobEnvironment(job_id=17930894_14, hostname=learnfair0482, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:12,760) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_14/17930894_14_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.2573\u001b[0m       \u001b[32m-2.9792\u001b[0m     +  102.9921\n",
      "      2       \u001b[36m-3.1824\u001b[0m       \u001b[32m-3.3966\u001b[0m     +  103.7875\n",
      "      3       \u001b[36m-3.5245\u001b[0m       \u001b[32m-3.6186\u001b[0m     +  104.1617\n",
      "      4       \u001b[36m-3.6513\u001b[0m       \u001b[32m-3.6690\u001b[0m     +  104.5170\n",
      "      5       \u001b[36m-3.7203\u001b[0m       \u001b[32m-3.7472\u001b[0m     +  105.9646\n",
      "      6       \u001b[36m-3.7461\u001b[0m       -3.5338        103.6478\n",
      "      7       \u001b[36m-3.7522\u001b[0m       \u001b[32m-3.7747\u001b[0m     +  104.3657\n",
      "      8       \u001b[36m-3.7734\u001b[0m       -3.7728        105.6294\n",
      "      9       \u001b[36m-3.7769\u001b[0m       \u001b[32m-3.7936\u001b[0m     +  105.9419\n",
      "     10       \u001b[36m-3.7960\u001b[0m       -3.7651        106.8379\n",
      "     11       \u001b[36m-3.8031\u001b[0m       \u001b[32m-3.8230\u001b[0m     +  106.6036\n",
      "     12       -3.8019       -3.7873        107.6959\n",
      "     13       \u001b[36m-3.8245\u001b[0m       \u001b[32m-3.8779\u001b[0m     +  104.6130\n",
      "     14       -3.8113       -3.8336        103.1949\n",
      "     15       \u001b[36m-3.8388\u001b[0m       \u001b[32m-3.8817\u001b[0m     +  105.1342\n",
      "     16       -3.8304       -3.7759        104.7191\n",
      "     17       -3.8282       -3.8358        103.6596\n",
      "     18       -3.8264       -3.8438        103.6032\n",
      "     19       -3.8331       \u001b[32m-3.8972\u001b[0m     +  105.0721\n",
      "     20       \u001b[36m-3.8472\u001b[0m       -3.8557        107.2986\n",
      "     21       -3.8468       -3.8305        105.6943\n",
      "     22       -3.8399       -3.8363        105.4487\n",
      "     23       \u001b[36m-3.8527\u001b[0m       -3.8364        104.7467\n",
      "     24       -3.8425       -3.8924        104.4799\n",
      "     25       -3.8439       -3.8264        104.1078\n",
      "     26       -3.8514       -3.8772        105.0612\n",
      "     27       -3.8464       -3.8908        105.4033\n",
      "     28       \u001b[36m-3.8545\u001b[0m       -3.7560        105.3639\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_1 | best epoch: 19 | train loss: -3.8388 | valid loss: -3.8972 | test log likelihood: 3.8334\n",
      "submitit INFO (2019-09-21 10:00:59,565) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Starting with JobEnvironment(job_id=17930894_15, hostname=learnfair0485, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:12,606) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_15/17930894_15_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.3423\u001b[0m       \u001b[32m-2.9463\u001b[0m     +  87.0752\n",
      "      2       \u001b[36m-3.3071\u001b[0m       \u001b[32m-3.5288\u001b[0m     +  87.8910\n",
      "      3       \u001b[36m-3.5423\u001b[0m       \u001b[32m-3.6795\u001b[0m     +  89.7088\n",
      "      4       \u001b[36m-3.6566\u001b[0m       \u001b[32m-3.7204\u001b[0m     +  96.3338\n",
      "      5       \u001b[36m-3.7063\u001b[0m       \u001b[32m-3.7630\u001b[0m     +  89.8786\n",
      "      6       \u001b[36m-3.7530\u001b[0m       \u001b[32m-3.7730\u001b[0m     +  97.6308\n",
      "      7       -3.7303       \u001b[32m-3.7801\u001b[0m     +  105.7595\n",
      "      8       \u001b[36m-3.7924\u001b[0m       \u001b[32m-3.7898\u001b[0m     +  93.8088\n",
      "      9       \u001b[36m-3.7989\u001b[0m       \u001b[32m-3.8011\u001b[0m     +  95.3005\n",
      "     10       \u001b[36m-3.8226\u001b[0m       \u001b[32m-3.8715\u001b[0m     +  92.4875\n",
      "     11       \u001b[36m-3.8453\u001b[0m       -3.8529        90.8154\n",
      "     12       -3.8333       -3.8312        95.5594\n",
      "     13       \u001b[36m-3.8603\u001b[0m       \u001b[32m-3.8971\u001b[0m     +  92.0038\n",
      "     14       -3.8509       -3.8657        101.0762\n",
      "     15       \u001b[36m-3.8679\u001b[0m       \u001b[32m-3.9117\u001b[0m     +  95.1300\n",
      "     16       \u001b[36m-3.8742\u001b[0m       -3.8169        98.0771\n",
      "     17       -3.8709       -3.8653        121.1894\n",
      "     18       -3.8691       -3.8827        120.8255\n",
      "     19       \u001b[36m-3.8760\u001b[0m       \u001b[32m-3.9350\u001b[0m     +  113.1457\n",
      "     20       \u001b[36m-3.8888\u001b[0m       -3.8947        113.4659\n",
      "     21       -3.8882       -3.8635        100.6354\n",
      "     22       -3.8752       -3.8911        107.9844\n",
      "     23       \u001b[36m-3.8920\u001b[0m       -3.8791        97.5473\n",
      "     24       -3.8841       -3.9229        104.8795\n",
      "     25       -3.8855       -3.8844        111.5853\n",
      "     26       -3.8894       \u001b[32m-3.9454\u001b[0m     +  114.2622\n",
      "     27       -3.8894       -3.9159        121.0790\n",
      "     28       \u001b[36m-3.8975\u001b[0m       -3.8309        121.1018\n",
      "     29       -3.8807       -3.9119        122.6953\n",
      "     30       -3.8967       -3.8912        124.0371\n",
      "     31       -3.8904       -3.9204        125.3442\n",
      "     32       \u001b[36m-3.9017\u001b[0m       -3.9264        136.5063\n",
      "     33       -3.8845       -3.9166        120.6145\n",
      "     34       \u001b[36m-3.9030\u001b[0m       -3.9225        117.7429\n",
      "     35       -3.8944       -3.8635        133.6806\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_1 | best epoch: 26 | train loss: -3.892 | valid loss: -3.9454 | test log likelihood: 3.8726\n",
      "submitit INFO (2019-09-21 10:15:08,274) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,594) - Starting with JobEnvironment(job_id=17930894_16, hostname=learnfair0537, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,594) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_16/17930894_16_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.5255\u001b[0m       \u001b[32m-2.9382\u001b[0m     +  1084.9519\n",
      "      2       \u001b[36m-3.2389\u001b[0m       \u001b[32m-3.1718\u001b[0m     +  796.2249\n",
      "      3       \u001b[36m-3.3676\u001b[0m       \u001b[32m-3.4222\u001b[0m     +  812.6132\n",
      "      4       \u001b[36m-3.4097\u001b[0m       \u001b[32m-3.4306\u001b[0m     +  617.4932\n",
      "      5       \u001b[36m-3.4475\u001b[0m       \u001b[32m-3.5415\u001b[0m     +  614.0580\n",
      "      6       \u001b[36m-3.4795\u001b[0m       -3.4857        628.4961\n",
      "      7       \u001b[36m-3.4875\u001b[0m       -3.5182        597.8588\n",
      "      8       \u001b[36m-3.5077\u001b[0m       -3.5070        602.7281\n",
      "      9       \u001b[36m-3.5156\u001b[0m       -3.5322        602.6642\n",
      "     10       -3.5149       -3.5156        568.4056\n",
      "     11       \u001b[36m-3.5209\u001b[0m       \u001b[32m-3.5418\u001b[0m     +  616.0900\n",
      "     12       \u001b[36m-3.5247\u001b[0m       -3.4794        609.2546\n",
      "     13       \u001b[36m-3.5303\u001b[0m       -3.5174        604.0624\n",
      "     14       \u001b[36m-3.5312\u001b[0m       \u001b[32m-3.5628\u001b[0m     +  596.4545\n",
      "     15       \u001b[36m-3.5420\u001b[0m       \u001b[32m-3.5769\u001b[0m     +  621.0337\n",
      "     16       -3.5289       -3.5047        647.1249\n",
      "     17       -3.5392       -3.4992        630.8967\n",
      "     18       -3.5393       -3.5705        605.8595\n",
      "     19       \u001b[36m-3.5480\u001b[0m       -3.5541        614.8745\n",
      "     20       -3.5479       -3.5161        659.4338\n",
      "     21       -3.5473       -3.5661        636.6071\n",
      "     22       \u001b[36m-3.5495\u001b[0m       \u001b[32m-3.5791\u001b[0m     +  654.4719\n",
      "     23       \u001b[36m-3.5515\u001b[0m       -3.5742        655.8708\n",
      "     24       \u001b[36m-3.5589\u001b[0m       \u001b[32m-3.5844\u001b[0m     +  652.3640\n",
      "     25       -3.5537       \u001b[32m-3.5940\u001b[0m     +  663.9626\n",
      "     26       \u001b[36m-3.5633\u001b[0m       -3.5677        644.8289\n",
      "     27       -3.5568       -3.5681        647.1040\n",
      "     28       -3.5555       -3.5473        648.5744\n",
      "     29       -3.5533       -3.5628        669.2753\n",
      "     30       -3.5574       \u001b[32m-3.6407\u001b[0m     +  652.4537\n",
      "     31       \u001b[36m-3.5648\u001b[0m       -3.5825        661.4213\n",
      "     32       \u001b[36m-3.5666\u001b[0m       -3.5557        664.7282\n",
      "     33       -3.5598       -3.5573        667.3836\n",
      "     34       \u001b[36m-3.5694\u001b[0m       -3.5753        667.2007\n",
      "     35       -3.5615       -3.5497        657.9121\n",
      "     36       -3.5617       -3.5868        675.7920\n",
      "     37       -3.5676       -3.6242        688.7478\n",
      "     38       -3.5691       -3.5522        707.1978\n",
      "     39       \u001b[36m-3.5810\u001b[0m       -3.5947        702.2744\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_1 | best epoch: 30 | train loss: -3.5633 | valid loss: -3.6407 | test log likelihood: 3.571\n",
      "submitit INFO (2019-09-21 16:35:00,748) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Starting with JobEnvironment(job_id=17930894_17, hostname=learnfair0557, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_17/17930894_17_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.4912\u001b[0m       \u001b[32m-3.2896\u001b[0m     +  956.4437\n",
      "      2       \u001b[36m-3.3449\u001b[0m       \u001b[32m-3.3934\u001b[0m     +  560.5977\n",
      "      3       \u001b[36m-3.4415\u001b[0m       \u001b[32m-3.4549\u001b[0m     +  553.7097\n",
      "      4       \u001b[36m-3.4721\u001b[0m       \u001b[32m-3.5357\u001b[0m     +  557.6561\n",
      "      5       \u001b[36m-3.5193\u001b[0m       \u001b[32m-3.6048\u001b[0m     +  561.7581\n",
      "      6       \u001b[36m-3.5445\u001b[0m       -3.5342        552.6350\n",
      "      7       \u001b[36m-3.5541\u001b[0m       -3.5753        556.2947\n",
      "      8       \u001b[36m-3.5702\u001b[0m       -3.5972        557.3579\n",
      "      9       \u001b[36m-3.5842\u001b[0m       -3.5902        557.7960\n",
      "     10       -3.5836       -3.5799        561.9833\n",
      "     11       \u001b[36m-3.5896\u001b[0m       \u001b[32m-3.6129\u001b[0m     +  551.7901\n",
      "     12       \u001b[36m-3.5932\u001b[0m       -3.6080        539.4069\n",
      "     13       \u001b[36m-3.6006\u001b[0m       -3.5834        558.5204\n",
      "     14       \u001b[36m-3.6019\u001b[0m       -3.6108        568.6392\n",
      "     15       \u001b[36m-3.6061\u001b[0m       \u001b[32m-3.6302\u001b[0m     +  559.0326\n",
      "     16       -3.5975       -3.6190        559.2212\n",
      "     17       \u001b[36m-3.6068\u001b[0m       -3.5612        569.9960\n",
      "     18       -3.6054       -3.6190        583.6192\n",
      "     19       \u001b[36m-3.6140\u001b[0m       -3.6108        589.4065\n",
      "     20       \u001b[36m-3.6150\u001b[0m       -3.6019        565.2528\n",
      "     21       \u001b[36m-3.6157\u001b[0m       -3.6183        544.1064\n",
      "     22       \u001b[36m-3.6179\u001b[0m       \u001b[32m-3.6453\u001b[0m     +  554.1482\n",
      "     23       \u001b[36m-3.6205\u001b[0m       -3.6346        581.5350\n",
      "     24       \u001b[36m-3.6269\u001b[0m       -3.6412        562.0534\n",
      "     25       -3.6205       \u001b[32m-3.6506\u001b[0m     +  548.2699\n",
      "     26       \u001b[36m-3.6313\u001b[0m       -3.6239        550.1850\n",
      "     27       -3.6245       -3.6325        572.4141\n",
      "     28       -3.6233       -3.6014        591.5285\n",
      "     29       -3.6205       -3.6287        591.3002\n",
      "     30       -3.6249       \u001b[32m-3.6856\u001b[0m     +  571.7336\n",
      "     31       \u001b[36m-3.6334\u001b[0m       -3.6417        573.7748\n",
      "     32       \u001b[36m-3.6345\u001b[0m       -3.6111        580.9818\n",
      "     33       -3.6297       -3.6094        575.8299\n",
      "     34       \u001b[36m-3.6379\u001b[0m       -3.6319        579.6627\n",
      "     35       -3.6310       -3.6293        586.7510\n",
      "     36       -3.6273       -3.6280        591.8156\n",
      "     37       -3.6349       -3.6664        579.6367\n",
      "     38       -3.6338       -3.6092        573.4037\n",
      "     39       \u001b[36m-3.6428\u001b[0m       -3.6491        586.6625\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_1 | best epoch: 30 | train loss: -3.6313 | valid loss: -3.6856 | test log likelihood: 3.6206\n",
      "submitit INFO (2019-09-21 15:39:06,453) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Starting with JobEnvironment(job_id=17930894_18, hostname=learnfair0557, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_18/17930894_18_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-1.1364\u001b[0m       \u001b[32m-1.2216\u001b[0m     +  98.6209\n",
      "      2       \u001b[36m-1.2330\u001b[0m       \u001b[32m-1.2467\u001b[0m     +  99.0206\n",
      "      3       \u001b[36m-1.2477\u001b[0m       \u001b[32m-1.2594\u001b[0m     +  99.3162\n",
      "      4       \u001b[36m-1.2494\u001b[0m       -1.2585        99.1508\n",
      "      5       \u001b[36m-1.2581\u001b[0m       -1.2537        99.0075\n",
      "      6       \u001b[36m-1.2589\u001b[0m       \u001b[32m-1.2721\u001b[0m     +  98.9244\n",
      "      7       \u001b[36m-1.2626\u001b[0m       -1.2715        99.0142\n",
      "      8       -1.2621       -1.2660        99.1076\n",
      "      9       \u001b[36m-1.2656\u001b[0m       -1.2654        98.8003\n",
      "     10       \u001b[36m-1.2732\u001b[0m       \u001b[32m-1.2811\u001b[0m     +  99.1332\n",
      "     11       -1.2690       -1.2655        99.2186\n",
      "     12       -1.2710       -1.2680        99.2465\n",
      "     13       -1.2696       -1.2736        98.9595\n",
      "     14       \u001b[36m-1.2749\u001b[0m       \u001b[32m-1.2917\u001b[0m     +  99.5826\n",
      "     15       -1.2728       -1.2778        99.2974\n",
      "     16       -1.2698       -1.2750        98.8699\n",
      "     17       -1.2734       -1.2759        99.3915\n",
      "     18       -1.2734       -1.2832        98.8831\n",
      "     19       -1.2746       -1.2645        98.7017\n",
      "     20       -1.2720       -1.2805        98.9218\n",
      "     21       \u001b[36m-1.2753\u001b[0m       -1.2656        98.8235\n",
      "     22       -1.2747       -1.2641        99.1891\n",
      "     23       \u001b[36m-1.2766\u001b[0m       -1.2634        98.6351\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_1 | best epoch: 14 | train loss: -1.2749 | valid loss: -1.2917 | test log likelihood: 1.1436\n",
      "submitit INFO (2019-09-21 09:49:28,462) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Starting with JobEnvironment(job_id=17930894_19, hostname=learnfair0557, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,580) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_19/17930894_19_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-1.1573\u001b[0m       \u001b[32m-1.2277\u001b[0m     +  97.5364\n",
      "      2       \u001b[36m-1.2419\u001b[0m       \u001b[32m-1.2683\u001b[0m     +  97.0275\n",
      "      3       \u001b[36m-1.2719\u001b[0m       \u001b[32m-1.2917\u001b[0m     +  97.3098\n",
      "      4       \u001b[36m-1.2820\u001b[0m       \u001b[32m-1.2920\u001b[0m     +  97.0131\n",
      "      5       \u001b[36m-1.2888\u001b[0m       -1.2859        96.8374\n",
      "      6       \u001b[36m-1.2889\u001b[0m       \u001b[32m-1.3024\u001b[0m     +  97.0642\n",
      "      7       \u001b[36m-1.2916\u001b[0m       -1.3006        97.4206\n",
      "      8       -1.2911       -1.2972        97.1290\n",
      "      9       \u001b[36m-1.2940\u001b[0m       -1.2940        97.3701\n",
      "     10       \u001b[36m-1.2990\u001b[0m       \u001b[32m-1.3030\u001b[0m     +  97.1482\n",
      "     11       -1.2956       -1.2923        96.9570\n",
      "     12       -1.2982       -1.2955        97.0752\n",
      "     13       -1.2969       -1.3005        97.2029\n",
      "     14       \u001b[36m-1.3012\u001b[0m       \u001b[32m-1.3147\u001b[0m     +  96.7930\n",
      "     15       -1.2994       -1.3038        96.6457\n",
      "     16       -1.2976       -1.3008        96.8523\n",
      "     17       -1.3010       -1.3015        96.7260\n",
      "     18       \u001b[36m-1.3015\u001b[0m       -1.3105        96.5406\n",
      "     19       \u001b[36m-1.3036\u001b[0m       -1.2933        97.1646\n",
      "     20       -1.3008       -1.3090        96.6953\n",
      "     21       -1.3027       -1.2950        96.9757\n",
      "     22       -1.3016       -1.2943        97.1329\n",
      "     23       \u001b[36m-1.3044\u001b[0m       -1.2931        96.8738\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_1 | best epoch: 14 | train loss: -1.3012 | valid loss: -1.3147 | test log likelihood: 1.1757\n",
      "submitit INFO (2019-09-21 09:48:39,958) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,148) - Starting with JobEnvironment(job_id=17930894_20, hostname=learnfair0621, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,149) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_20/17930894_20_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.1116\u001b[0m       \u001b[32m-2.5105\u001b[0m     +  1096.6600\n",
      "      2       \u001b[36m-2.8432\u001b[0m       \u001b[32m-2.8942\u001b[0m     +  437.2588\n",
      "      3       \u001b[36m-2.9450\u001b[0m       \u001b[32m-3.0244\u001b[0m     +  386.4999\n",
      "      4       \u001b[36m-2.9820\u001b[0m       \u001b[32m-3.0837\u001b[0m     +  381.8430\n",
      "      5       \u001b[36m-3.0099\u001b[0m       -2.9638        382.2198\n",
      "      6       \u001b[36m-3.0305\u001b[0m       -3.0417        385.0026\n",
      "      7       \u001b[36m-3.0395\u001b[0m       -2.9784        397.3004\n",
      "      8       \u001b[36m-3.0561\u001b[0m       -3.0481        395.9422\n",
      "      9       \u001b[36m-3.0641\u001b[0m       -3.0770        396.5408\n",
      "     10       \u001b[36m-3.0714\u001b[0m       -3.0647        387.6083\n",
      "     11       -3.0618       -3.0623        388.3151\n",
      "     12       \u001b[36m-3.0720\u001b[0m       \u001b[32m-3.0987\u001b[0m     +  395.0064\n",
      "     13       \u001b[36m-3.0775\u001b[0m       \u001b[32m-3.1284\u001b[0m     +  397.9879\n",
      "     14       \u001b[36m-3.0839\u001b[0m       -3.1085        388.1868\n",
      "     15       \u001b[36m-3.0892\u001b[0m       -3.0204        381.4325\n",
      "     16       \u001b[36m-3.0907\u001b[0m       -3.0315        373.1768\n",
      "     17       \u001b[36m-3.0994\u001b[0m       -3.0549        408.1164\n",
      "     18       -3.0895       -3.0236        466.4354\n",
      "     19       -3.0990       -3.0724        451.5274\n",
      "     20       \u001b[36m-3.1024\u001b[0m       \u001b[32m-3.1342\u001b[0m     +  442.9861\n",
      "     21       -3.0995       -3.0654        405.5723\n",
      "     22       \u001b[36m-3.1098\u001b[0m       -3.1071        407.9622\n",
      "     23       \u001b[36m-3.1299\u001b[0m       -3.0963        418.9089\n",
      "     24       -3.1211       -3.1301        466.2303\n",
      "     25       -3.1086       -3.1126        457.5384\n",
      "     26       -3.1095       -3.0925        411.4854\n",
      "     27       -3.1053       \u001b[32m-3.1751\u001b[0m     +  384.4879\n",
      "     28       -3.0992       -3.0662        381.1984\n",
      "     29       -3.1290       -3.1062        392.5054\n",
      "     30       -3.1121       -3.1403        426.2287\n",
      "     31       -3.1057       -3.0753        416.2762\n",
      "     32       -3.1211       -3.1462        424.0267\n",
      "     33       -3.1103       -3.1313        407.8082\n",
      "     34       -3.1142       -3.0860        410.5663\n",
      "     35       -3.1032       \u001b[32m-3.1836\u001b[0m     +  412.6621\n",
      "     36       -3.1231       -3.0960        411.4050\n",
      "     37       \u001b[36m-3.1314\u001b[0m       -3.1145        401.7947\n",
      "     38       \u001b[36m-3.1363\u001b[0m       -3.1052        397.1615\n",
      "     39       -3.1082       \u001b[32m-3.2048\u001b[0m     +  397.0012\n",
      "     40       -3.1344       -3.1454        386.0252\n",
      "     41       -3.1143       -3.1562        389.5489\n",
      "     42       -3.1120       -3.1631        384.8141\n",
      "     43       \u001b[36m-3.1385\u001b[0m       -3.1037        385.7759\n",
      "     44       \u001b[36m-3.1442\u001b[0m       -3.1244        383.5655\n",
      "     45       -3.1290       -3.1064        395.6606\n",
      "     46       -3.1375       -3.1297        392.9265\n",
      "     47       -3.1184       -3.1133        397.1018\n",
      "     48       -3.1409       -3.1557        395.9745\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_2 | best epoch: 39 | train loss: -3.1363 | valid loss: -3.2048 | test log likelihood: 3.1132\n",
      "submitit INFO (2019-09-21 14:57:45,053) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,174) - Starting with JobEnvironment(job_id=17930894_21, hostname=learnfair0621, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,174) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_21/17930894_21_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-1.8848\u001b[0m       \u001b[32m-2.7550\u001b[0m     +  1096.7151\n",
      "      2       \u001b[36m-2.8617\u001b[0m       \u001b[32m-2.9296\u001b[0m     +  435.9464\n",
      "      3       \u001b[36m-2.9632\u001b[0m       \u001b[32m-3.0637\u001b[0m     +  383.8500\n",
      "      4       \u001b[36m-3.0327\u001b[0m       \u001b[32m-3.1434\u001b[0m     +  377.8008\n",
      "      5       \u001b[36m-3.0681\u001b[0m       -3.0638        381.2033\n",
      "      6       \u001b[36m-3.0930\u001b[0m       -3.1001        382.8021\n",
      "      7       \u001b[36m-3.1073\u001b[0m       -3.0570        393.9750\n",
      "      8       \u001b[36m-3.1288\u001b[0m       -3.1393        390.5343\n",
      "      9       \u001b[36m-3.1378\u001b[0m       \u001b[32m-3.1511\u001b[0m     +  391.6304\n",
      "     10       \u001b[36m-3.1424\u001b[0m       -3.1314        386.7013\n",
      "     11       -3.1407       -3.1361        383.0509\n",
      "     12       \u001b[36m-3.1501\u001b[0m       \u001b[32m-3.1812\u001b[0m     +  391.0006\n",
      "     13       \u001b[36m-3.1599\u001b[0m       \u001b[32m-3.1981\u001b[0m     +  392.9431\n",
      "     14       \u001b[36m-3.1641\u001b[0m       -3.1832        387.1390\n",
      "     15       \u001b[36m-3.1716\u001b[0m       -3.1492        380.0826\n",
      "     16       -3.1692       -3.1372        366.5608\n",
      "     17       \u001b[36m-3.1797\u001b[0m       -3.1306        402.0086\n",
      "     18       -3.1738       -3.0947        454.8476\n",
      "     19       \u001b[36m-3.1820\u001b[0m       -3.1697        450.0001\n",
      "     20       \u001b[36m-3.1863\u001b[0m       \u001b[32m-3.2001\u001b[0m     +  445.2668\n",
      "     21       -3.1824       -3.1461        401.5572\n",
      "     22       \u001b[36m-3.1943\u001b[0m       -3.1795        407.6808\n",
      "     23       \u001b[36m-3.2092\u001b[0m       -3.1679        400.8350\n",
      "     24       -3.2048       \u001b[32m-3.2026\u001b[0m     +  465.9485\n",
      "     25       -3.1953       -3.1865        456.6484\n",
      "     26       -3.1959       -3.1815        421.9743\n",
      "     27       -3.1902       \u001b[32m-3.2523\u001b[0m     +  382.5089\n",
      "     28       -3.1862       -3.1574        378.6989\n",
      "     29       \u001b[36m-3.2131\u001b[0m       -3.1846        389.7782\n",
      "     30       -3.1976       -3.2171        408.4619\n",
      "     31       -3.1896       -3.1640        420.4115\n",
      "     32       -3.2062       -3.2263        417.7174\n",
      "     33       -3.1951       -3.2214        406.5861\n",
      "     34       -3.1979       -3.1782        407.7111\n",
      "     35       -3.1864       \u001b[32m-3.2679\u001b[0m     +  408.9865\n",
      "     36       -3.2070       -3.1748        407.3867\n",
      "     37       \u001b[36m-3.2158\u001b[0m       -3.2147        403.7925\n",
      "     38       \u001b[36m-3.2193\u001b[0m       -3.1865        394.3246\n",
      "     39       -3.1891       \u001b[32m-3.2773\u001b[0m     +  395.4262\n",
      "     40       -3.2090       -3.2064        384.7611\n",
      "     41       -3.1942       -3.2259        382.6089\n",
      "     42       -3.1929       -3.1854        387.7622\n",
      "     43       -3.2147       -3.1774        380.0653\n",
      "     44       -3.2181       -3.2111        381.8952\n",
      "     45       -3.2032       -3.2254        387.2857\n",
      "     46       -3.2105       -3.2081        391.7579\n",
      "     47       -3.1957       -3.1876        389.9874\n",
      "     48       -3.2092       -3.2192        394.2760\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_2 | best epoch: 39 | train loss: -3.2193 | valid loss: -3.2773 | test log likelihood: 3.1876\n",
      "submitit INFO (2019-09-21 14:53:33,714) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,148) - Starting with JobEnvironment(job_id=17930894_22, hostname=learnfair0621, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,149) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_22/17930894_22_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7911\u001b[0m       \u001b[32m-0.9419\u001b[0m     +  73.0365\n",
      "      2       \u001b[36m-0.9541\u001b[0m       \u001b[32m-1.0156\u001b[0m     +  73.6773\n",
      "      3       \u001b[36m-1.0126\u001b[0m       \u001b[32m-1.0341\u001b[0m     +  74.7301\n",
      "      4       \u001b[36m-1.0637\u001b[0m       \u001b[32m-1.0525\u001b[0m     +  74.7033\n",
      "      5       \u001b[36m-1.0839\u001b[0m       \u001b[32m-1.0989\u001b[0m     +  74.5674\n",
      "      6       \u001b[36m-1.0881\u001b[0m       -1.0824        73.9607\n",
      "      7       \u001b[36m-1.0943\u001b[0m       \u001b[32m-1.1065\u001b[0m     +  76.6390\n",
      "      8       \u001b[36m-1.1121\u001b[0m       \u001b[32m-1.1266\u001b[0m     +  74.4156\n",
      "      9       \u001b[36m-1.1152\u001b[0m       \u001b[32m-1.1303\u001b[0m     +  74.4233\n",
      "     10       \u001b[36m-1.1359\u001b[0m       -1.1303        73.2608\n",
      "     11       -1.1325       \u001b[32m-1.1438\u001b[0m     +  75.4481\n",
      "     12       \u001b[36m-1.1460\u001b[0m       \u001b[32m-1.1629\u001b[0m     +  73.7605\n",
      "     13       \u001b[36m-1.1559\u001b[0m       -1.1538        73.7118\n",
      "     14       -1.1529       -1.1474        72.7907\n",
      "     15       -1.1549       -1.1471        73.3688\n",
      "     16       \u001b[36m-1.1600\u001b[0m       -1.1578        73.9302\n",
      "     17       \u001b[36m-1.1652\u001b[0m       \u001b[32m-1.1644\u001b[0m     +  73.4958\n",
      "     18       -1.1574       -1.1349        74.0978\n",
      "     19       -1.1596       \u001b[32m-1.1847\u001b[0m     +  74.4198\n",
      "     20       \u001b[36m-1.1671\u001b[0m       -1.1511        72.1849\n",
      "     21       -1.1630       \u001b[32m-1.1972\u001b[0m     +  72.5291\n",
      "     22       -1.1610       -1.1593        72.1072\n",
      "     23       \u001b[36m-1.1747\u001b[0m       -1.1818        71.9689\n",
      "     24       -1.1714       -1.1879        72.0720\n",
      "     25       -1.1713       -1.1685        71.4920\n",
      "     26       \u001b[36m-1.1751\u001b[0m       -1.1708        74.1015\n",
      "     27       -1.1732       -1.1518        73.8275\n",
      "     28       \u001b[36m-1.1762\u001b[0m       -1.1968        73.8318\n",
      "     29       -1.1712       -1.1881        74.1434\n",
      "     30       -1.1751       -1.1719        73.3657\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_2 | best epoch: 21 | train loss: -1.1671 | valid loss: -1.1972 | test log likelihood: 1.1547\n",
      "submitit INFO (2019-09-21 09:48:06,206) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,452) - Starting with JobEnvironment(job_id=17930894_23, hostname=learnfair0653, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,452) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_23/17930894_23_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.8063\u001b[0m       \u001b[32m-1.0702\u001b[0m     +  72.7039\n",
      "      2       \u001b[36m-1.0916\u001b[0m       \u001b[32m-1.1529\u001b[0m     +  71.7241\n",
      "      3       \u001b[36m-1.1357\u001b[0m       -1.1525        71.4315\n",
      "      4       \u001b[36m-1.1659\u001b[0m       \u001b[32m-1.1588\u001b[0m     +  71.7147\n",
      "      5       \u001b[36m-1.1804\u001b[0m       \u001b[32m-1.1916\u001b[0m     +  72.0761\n",
      "      6       \u001b[36m-1.1815\u001b[0m       -1.1778        72.3580\n",
      "      7       \u001b[36m-1.1862\u001b[0m       -1.1881        71.8688\n",
      "      8       \u001b[36m-1.1947\u001b[0m       \u001b[32m-1.2066\u001b[0m     +  72.5360\n",
      "      9       -1.1929       -1.1992        72.5005\n",
      "     10       \u001b[36m-1.2013\u001b[0m       -1.1923        72.1621\n",
      "     11       -1.1930       -1.1933        71.1631\n",
      "     12       \u001b[36m-1.2015\u001b[0m       \u001b[32m-1.2138\u001b[0m     +  72.5530\n",
      "     13       \u001b[36m-1.2065\u001b[0m       -1.2058        71.6372\n",
      "     14       -1.2039       -1.1952        72.7456\n",
      "     15       -1.2038       -1.1976        72.1374\n",
      "     16       \u001b[36m-1.2066\u001b[0m       -1.2040        71.5077\n",
      "     17       \u001b[36m-1.2109\u001b[0m       -1.2078        71.5693\n",
      "     18       -1.2035       -1.1887        72.0261\n",
      "     19       -1.2037       \u001b[32m-1.2311\u001b[0m     +  71.0737\n",
      "     20       \u001b[36m-1.2112\u001b[0m       -1.1967        72.4644\n",
      "     21       -1.2061       \u001b[32m-1.2324\u001b[0m     +  72.6734\n",
      "     22       -1.2036       -1.2021        72.0100\n",
      "     23       \u001b[36m-1.2157\u001b[0m       -1.2217        71.9159\n",
      "     24       -1.2119       -1.2313        71.1856\n",
      "     25       -1.2112       -1.2059        72.1307\n",
      "     26       -1.2153       -1.2120        71.5608\n",
      "     27       -1.2125       -1.1896        72.3913\n",
      "     28       -1.2150       \u001b[32m-1.2390\u001b[0m     +  72.5452\n",
      "     29       -1.2097       -1.2263        71.5573\n",
      "     30       -1.2127       -1.2107        72.1976\n",
      "     31       -1.2077       -1.2128        72.4042\n",
      "     32       \u001b[36m-1.2175\u001b[0m       -1.1941        72.2209\n",
      "     33       -1.2074       -1.2355        72.3581\n",
      "     34       -1.2150       -1.2086        71.9951\n",
      "     35       -1.2143       -1.2150        72.6212\n",
      "     36       \u001b[36m-1.2180\u001b[0m       -1.2054        72.6380\n",
      "     37       -1.2111       -1.2204        72.5225\n",
      "     38       -1.2106       \u001b[32m-1.2487\u001b[0m     +  71.8897\n",
      "     39       \u001b[36m-1.2213\u001b[0m       -1.1995        71.7874\n",
      "     40       -1.2149       -1.2147        69.9843\n",
      "     41       -1.2160       -1.1939        69.4586\n",
      "     42       -1.2179       -1.1867        68.9572\n",
      "     43       -1.2180       -1.1869        68.9592\n",
      "     44       \u001b[36m-1.2233\u001b[0m       -1.2023        69.5849\n",
      "     45       -1.2154       -1.2104        68.5583\n",
      "     46       -1.2152       -1.2155        69.5782\n",
      "     47       -1.2141       -1.2459        69.1166\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_2 | best epoch: 38 | train loss: -1.218 | valid loss: -1.2487 | test log likelihood: 1.201\n",
      "submitit INFO (2019-09-21 10:07:27,617) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,452) - Starting with JobEnvironment(job_id=17930894_24, hostname=learnfair0653, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,452) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_24/17930894_24_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.2265\u001b[0m       \u001b[32m-3.1303\u001b[0m     +  90.2450\n",
      "      2       \u001b[36m-3.3065\u001b[0m       \u001b[32m-3.5476\u001b[0m     +  90.0970\n",
      "      3       \u001b[36m-3.5689\u001b[0m       \u001b[32m-3.6741\u001b[0m     +  89.8253\n",
      "      4       \u001b[36m-3.6795\u001b[0m       \u001b[32m-3.6778\u001b[0m     +  89.1073\n",
      "      5       \u001b[36m-3.7358\u001b[0m       \u001b[32m-3.7722\u001b[0m     +  89.7018\n",
      "      6       \u001b[36m-3.7456\u001b[0m       \u001b[32m-3.8460\u001b[0m     +  90.4188\n",
      "      7       \u001b[36m-3.7740\u001b[0m       -3.7885        89.9950\n",
      "      8       \u001b[36m-3.7960\u001b[0m       -3.7380        89.6116\n",
      "      9       -3.7914       -3.8350        89.5744\n",
      "     10       \u001b[36m-3.8181\u001b[0m       -3.8267        90.1168\n",
      "     11       \u001b[36m-3.8191\u001b[0m       -3.8115        90.1218\n",
      "     12       -3.8051       \u001b[32m-3.8720\u001b[0m     +  89.7402\n",
      "     13       \u001b[36m-3.8210\u001b[0m       -3.8529        90.1702\n",
      "     14       \u001b[36m-3.8331\u001b[0m       -3.7983        90.3412\n",
      "     15       -3.8219       -3.8264        90.1831\n",
      "     16       -3.8300       -3.8355        90.9051\n",
      "     17       -3.8315       -3.8355        90.2566\n",
      "     18       -3.8283       -3.8462        90.6723\n",
      "     19       \u001b[36m-3.8511\u001b[0m       -3.8138        90.6685\n",
      "     20       -3.8403       -3.8517        90.3287\n",
      "     21       -3.8421       \u001b[32m-3.8896\u001b[0m     +  90.2748\n",
      "     22       \u001b[36m-3.8551\u001b[0m       -3.8101        89.6003\n",
      "     23       -3.8478       -3.8574        89.5984\n",
      "     24       -3.8460       -3.8582        89.2462\n",
      "     25       -3.8433       -3.8541        90.1895\n",
      "     26       -3.8496       -3.8422        89.8946\n",
      "     27       -3.8426       -3.8848        89.8526\n",
      "     28       -3.8494       -3.8055        89.8291\n",
      "     29       \u001b[36m-3.8619\u001b[0m       -3.8710        90.4225\n",
      "     30       -3.8512       -3.8758        89.6392\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_2 | best epoch: 21 | train loss: -3.8511 | valid loss: -3.8896 | test log likelihood: 3.849\n",
      "submitit INFO (2019-09-21 09:56:39,183) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,133) - Starting with JobEnvironment(job_id=17930894_25, hostname=learnfair0201, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,133) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_25/17930894_25_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0621\u001b[0m       \u001b[32m-2.9364\u001b[0m     +  125.5836\n",
      "      2       \u001b[36m-3.2525\u001b[0m       \u001b[32m-3.5453\u001b[0m     +  114.9338\n",
      "      3       \u001b[36m-3.5186\u001b[0m       \u001b[32m-3.6576\u001b[0m     +  146.1567\n",
      "      4       \u001b[36m-3.6327\u001b[0m       \u001b[32m-3.7172\u001b[0m     +  167.9966\n",
      "      5       \u001b[36m-3.6955\u001b[0m       -3.7036        134.8083\n",
      "      6       \u001b[36m-3.7216\u001b[0m       \u001b[32m-3.7462\u001b[0m     +  117.1300\n",
      "      7       \u001b[36m-3.7736\u001b[0m       \u001b[32m-3.7935\u001b[0m     +  164.0588\n",
      "      8       \u001b[36m-3.7961\u001b[0m       -3.7570        140.1613\n",
      "      9       \u001b[36m-3.7971\u001b[0m       \u001b[32m-3.8450\u001b[0m     +  155.9594\n",
      "     10       \u001b[36m-3.8319\u001b[0m       \u001b[32m-3.8455\u001b[0m     +  130.9401\n",
      "     11       \u001b[36m-3.8394\u001b[0m       -3.8364        118.2294\n",
      "     12       -3.8341       \u001b[32m-3.9087\u001b[0m     +  123.8071\n",
      "     13       \u001b[36m-3.8490\u001b[0m       -3.8685        162.7252\n",
      "     14       \u001b[36m-3.8595\u001b[0m       -3.8294        123.3451\n",
      "     15       -3.8466       -3.8313        137.9086\n",
      "     16       -3.8592       -3.9039        127.3673\n",
      "     17       -3.8589       -3.8304        119.7402\n",
      "     18       -3.8583       -3.8640        119.3416\n",
      "     19       \u001b[36m-3.8767\u001b[0m       -3.8960        129.8989\n",
      "     20       -3.8725       -3.8732        120.6219\n",
      "     21       -3.8735       -3.8961        120.6117\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_2 | best epoch: 12 | train loss: -3.8394 | valid loss: -3.9087 | test log likelihood: 3.8315\n",
      "submitit INFO (2019-09-21 09:59:37,707) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,297) - Starting with JobEnvironment(job_id=17930894_26, hostname=learnfair0205, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,297) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_26/17930894_26_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.6108\u001b[0m       \u001b[32m-3.1622\u001b[0m     +  1143.9941\n",
      "      2       \u001b[36m-3.3003\u001b[0m       \u001b[32m-3.3601\u001b[0m     +  561.3622\n",
      "      3       \u001b[36m-3.3819\u001b[0m       \u001b[32m-3.4076\u001b[0m     +  562.7097\n",
      "      4       \u001b[36m-3.4266\u001b[0m       \u001b[32m-3.5187\u001b[0m     +  566.1802\n",
      "      5       \u001b[36m-3.4517\u001b[0m       -3.4402        578.3288\n",
      "      6       \u001b[36m-3.4720\u001b[0m       -3.5035        583.7465\n",
      "      7       \u001b[36m-3.4870\u001b[0m       -3.4834        603.5329\n",
      "      8       \u001b[36m-3.5002\u001b[0m       \u001b[32m-3.5285\u001b[0m     +  597.1183\n",
      "      9       \u001b[36m-3.5122\u001b[0m       \u001b[32m-3.5488\u001b[0m     +  592.2302\n",
      "     10       \u001b[36m-3.5147\u001b[0m       -3.5345        595.3253\n",
      "     11       \u001b[36m-3.5170\u001b[0m       -3.5226        574.4701\n",
      "     12       \u001b[36m-3.5215\u001b[0m       \u001b[32m-3.5510\u001b[0m     +  592.5901\n",
      "     13       \u001b[36m-3.5338\u001b[0m       \u001b[32m-3.5566\u001b[0m     +  617.4487\n",
      "     14       -3.5326       \u001b[32m-3.5735\u001b[0m     +  599.7069\n",
      "     15       \u001b[36m-3.5362\u001b[0m       -3.5619        588.6397\n",
      "     16       -3.5354       -3.4460        609.4961\n",
      "     17       \u001b[36m-3.5409\u001b[0m       -3.5530        625.8343\n",
      "     18       -3.5408       -3.5374        630.2316\n",
      "     19       \u001b[36m-3.5489\u001b[0m       -3.5453        586.1522\n",
      "     20       \u001b[36m-3.5493\u001b[0m       -3.5136        574.4013\n",
      "     21       -3.5472       -3.5031        629.3729\n",
      "     22       \u001b[36m-3.5597\u001b[0m       -3.5575        617.6864\n",
      "     23       \u001b[36m-3.5670\u001b[0m       -3.5225        594.6458\n",
      "     24       \u001b[36m-3.5683\u001b[0m       \u001b[32m-3.5763\u001b[0m     +  595.5467\n",
      "     25       -3.5534       -3.5582        596.4310\n",
      "     26       -3.5638       -3.5577        599.3052\n",
      "     27       -3.5611       -3.5724        605.6370\n",
      "     28       -3.5548       -3.5614        572.0621\n",
      "     29       \u001b[36m-3.5747\u001b[0m       -3.5728        577.4389\n",
      "     30       -3.5627       \u001b[32m-3.6022\u001b[0m     +  585.6908\n",
      "     31       -3.5560       -3.5514        583.0817\n",
      "     32       -3.5743       \u001b[32m-3.6041\u001b[0m     +  583.6157\n",
      "     33       -3.5631       -3.5820        599.9005\n",
      "     34       -3.5642       -3.5810        595.6522\n",
      "     35       -3.5634       -3.5864        599.4156\n",
      "     36       -3.5712       -3.6015        591.1349\n",
      "     37       \u001b[36m-3.5803\u001b[0m       -3.5465        580.3126\n",
      "     38       -3.5794       -3.5714        582.0122\n",
      "     39       -3.5577       -3.5052        593.5420\n",
      "     40       -3.5767       -3.5977        580.0857\n",
      "     41       -3.5672       -3.5365        593.4175\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_2 | best epoch: 32 | train loss: -3.5747 | valid loss: -3.6041 | test log likelihood: 3.5747\n",
      "submitit INFO (2019-09-21 16:17:54,117) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,297) - Starting with JobEnvironment(job_id=17930894_27, hostname=learnfair0205, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,297) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_27/17930894_27_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.5113\u001b[0m       \u001b[32m-3.2844\u001b[0m     +  1144.2191\n",
      "      2       \u001b[36m-3.3585\u001b[0m       \u001b[32m-3.4377\u001b[0m     +  558.4065\n",
      "      3       \u001b[36m-3.4656\u001b[0m       \u001b[32m-3.4865\u001b[0m     +  559.3733\n",
      "      4       \u001b[36m-3.4887\u001b[0m       \u001b[32m-3.5758\u001b[0m     +  564.8592\n",
      "      5       \u001b[36m-3.5287\u001b[0m       -3.5202        578.2717\n",
      "      6       \u001b[36m-3.5454\u001b[0m       -3.5541        582.0503\n",
      "      7       \u001b[36m-3.5605\u001b[0m       -3.5309        602.3534\n",
      "      8       \u001b[36m-3.5779\u001b[0m       \u001b[32m-3.5791\u001b[0m     +  597.8848\n",
      "      9       \u001b[36m-3.5819\u001b[0m       \u001b[32m-3.6063\u001b[0m     +  596.0602\n",
      "     10       -3.5730       -3.5951        594.9320\n",
      "     11       \u001b[36m-3.5894\u001b[0m       -3.5842        570.9599\n",
      "     12       \u001b[36m-3.5986\u001b[0m       \u001b[32m-3.6071\u001b[0m     +  592.8798\n",
      "     13       \u001b[36m-3.6069\u001b[0m       \u001b[32m-3.6152\u001b[0m     +  615.2256\n",
      "     14       \u001b[36m-3.6081\u001b[0m       \u001b[32m-3.6342\u001b[0m     +  601.4499\n",
      "     15       \u001b[36m-3.6123\u001b[0m       -3.6194        585.5977\n",
      "     16       -3.6108       -3.6301        602.6403\n",
      "     17       -3.6078       -3.5975        618.2181\n",
      "     18       \u001b[36m-3.6125\u001b[0m       -3.5998        636.3216\n",
      "     19       \u001b[36m-3.6187\u001b[0m       -3.6062        586.8246\n",
      "     20       \u001b[36m-3.6232\u001b[0m       -3.6199        572.6230\n",
      "     21       -3.6185       -3.5921        625.4573\n",
      "     22       \u001b[36m-3.6306\u001b[0m       -3.6189        618.0296\n",
      "     23       \u001b[36m-3.6376\u001b[0m       -3.5832        595.4477\n",
      "     24       \u001b[36m-3.6392\u001b[0m       \u001b[32m-3.6374\u001b[0m     +  597.7736\n",
      "     25       -3.6271       -3.6066        595.4160\n",
      "     26       -3.6315       -3.6348        598.8782\n",
      "     27       -3.6291       \u001b[32m-3.6394\u001b[0m     +  602.6216\n",
      "     28       -3.6235       -3.6187        573.2258\n",
      "     29       \u001b[36m-3.6412\u001b[0m       -3.6264        575.4062\n",
      "     30       -3.6310       \u001b[32m-3.6570\u001b[0m     +  585.6159\n",
      "     31       -3.6249       -3.6129        581.0397\n",
      "     32       -3.6402       \u001b[32m-3.6588\u001b[0m     +  580.3352\n",
      "     33       -3.6274       -3.6343        597.0964\n",
      "     34       -3.6327       -3.6326        595.1641\n",
      "     35       -3.6288       -3.6451        598.6764\n",
      "     36       -3.6361       -3.6565        592.7327\n",
      "     37       \u001b[36m-3.6449\u001b[0m       -3.6412        579.4533\n",
      "     38       \u001b[36m-3.6460\u001b[0m       -3.6185        578.3842\n",
      "     39       -3.6306       -3.6350        592.3800\n",
      "     40       -3.6434       -3.6467        580.2554\n",
      "     41       -3.6323       -3.5964        591.9593\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_2 | best epoch: 32 | train loss: -3.6412 | valid loss: -3.6588 | test log likelihood: 3.6312\n",
      "submitit INFO (2019-09-21 16:17:49,600) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,607) - Starting with JobEnvironment(job_id=17930894_28, hostname=learnfair0215, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,607) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_28/17930894_28_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1730\u001b[0m       \u001b[32m-1.2147\u001b[0m     +  105.2211\n",
      "      2       \u001b[36m-1.2352\u001b[0m       \u001b[32m-1.2262\u001b[0m     +  104.4401\n",
      "      3       \u001b[36m-1.2480\u001b[0m       \u001b[32m-1.2512\u001b[0m     +  103.7028\n",
      "      4       \u001b[36m-1.2554\u001b[0m       \u001b[32m-1.2542\u001b[0m     +  105.6108\n",
      "      5       \u001b[36m-1.2579\u001b[0m       \u001b[32m-1.2588\u001b[0m     +  105.1138\n",
      "      6       \u001b[36m-1.2608\u001b[0m       \u001b[32m-1.2718\u001b[0m     +  104.4785\n",
      "      7       \u001b[36m-1.2636\u001b[0m       \u001b[32m-1.2734\u001b[0m     +  103.5033\n",
      "      8       \u001b[36m-1.2689\u001b[0m       -1.2646        104.2915\n",
      "      9       -1.2656       \u001b[32m-1.2838\u001b[0m     +  104.4564\n",
      "     10       \u001b[36m-1.2696\u001b[0m       -1.2661        104.3781\n",
      "     11       \u001b[36m-1.2725\u001b[0m       -1.2652        104.0418\n",
      "     12       \u001b[36m-1.2744\u001b[0m       -1.2803        104.2721\n",
      "     13       \u001b[36m-1.2777\u001b[0m       -1.2658        104.1190\n",
      "     14       -1.2725       -1.2727        103.8417\n",
      "     15       -1.2752       -1.2750        104.5233\n",
      "     16       -1.2758       -1.2730        105.1809\n",
      "     17       -1.2748       -1.2744        104.0264\n",
      "     18       -1.2776       -1.2467        104.2964\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_2 | best epoch: 9 | train loss: -1.2689 | valid loss: -1.2838 | test log likelihood: 1.1416\n",
      "submitit INFO (2019-09-21 09:42:54,801) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Starting with JobEnvironment(job_id=17930894_29, hostname=learnfair0218, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_29/17930894_29_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-1.1524\u001b[0m       \u001b[32m-1.2214\u001b[0m     +  94.5444\n",
      "      2       \u001b[36m-1.2429\u001b[0m       \u001b[32m-1.2472\u001b[0m     +  96.0031\n",
      "      3       \u001b[36m-1.2634\u001b[0m       \u001b[32m-1.2537\u001b[0m     +  95.8635\n",
      "      4       \u001b[36m-1.2785\u001b[0m       -1.2253        95.6114\n",
      "      5       \u001b[36m-1.2842\u001b[0m       \u001b[32m-1.2835\u001b[0m     +  95.6839\n",
      "      6       \u001b[36m-1.2893\u001b[0m       \u001b[32m-1.2982\u001b[0m     +  95.7357\n",
      "      7       \u001b[36m-1.2902\u001b[0m       \u001b[32m-1.2999\u001b[0m     +  95.7932\n",
      "      8       \u001b[36m-1.2937\u001b[0m       -1.2919        95.9607\n",
      "      9       -1.2913       \u001b[32m-1.3071\u001b[0m     +  95.9229\n",
      "     10       \u001b[36m-1.2949\u001b[0m       -1.2926        96.0547\n",
      "     11       \u001b[36m-1.2962\u001b[0m       -1.2895        96.0166\n",
      "     12       \u001b[36m-1.2974\u001b[0m       -1.3016        96.0341\n",
      "     13       \u001b[36m-1.3003\u001b[0m       -1.2889        96.0493\n",
      "     14       -1.2949       -1.2954        96.0596\n",
      "     15       -1.2980       -1.2962        95.9298\n",
      "     16       -1.2983       -1.2947        95.9252\n",
      "     17       -1.2988       -1.2986        96.1806\n",
      "     18       \u001b[36m-1.3020\u001b[0m       -1.2897        96.0022\n",
      "     19       -1.3004       \u001b[32m-1.3094\u001b[0m     +  96.0429\n",
      "     20       -1.3012       -1.3086        96.2651\n",
      "     21       -1.3001       -1.3021        96.0103\n",
      "     22       \u001b[36m-1.3022\u001b[0m       -1.3017        95.9555\n",
      "     23       -1.2997       -1.3027        96.0907\n",
      "     24       \u001b[36m-1.3032\u001b[0m       -1.3012        95.9817\n",
      "     25       -1.2997       -1.3031        96.0199\n",
      "     26       -1.3027       -1.3034        95.8714\n",
      "     27       \u001b[36m-1.3042\u001b[0m       -1.3085        96.0630\n",
      "     28       -1.3015       -1.3050        96.1124\n",
      "     29       -1.3020       \u001b[32m-1.3098\u001b[0m     +  96.4741\n",
      "     30       \u001b[36m-1.3055\u001b[0m       -1.2990        96.1155\n",
      "     31       -1.3033       -1.3005        96.0005\n",
      "     32       -1.3047       -1.3069        96.1515\n",
      "     33       -1.3040       -1.3029        96.2371\n",
      "     34       \u001b[36m-1.3058\u001b[0m       \u001b[32m-1.3099\u001b[0m     +  96.0133\n",
      "     35       -1.3048       -1.3065        96.0547\n",
      "     36       -1.3017       \u001b[32m-1.3183\u001b[0m     +  95.8402\n",
      "     37       -1.3046       -1.3098        96.0210\n",
      "     38       -1.3025       -1.3025        95.8948\n",
      "     39       -1.3050       -1.3010        96.0236\n",
      "     40       -1.3021       -1.2998        96.1241\n",
      "     41       -1.3037       -1.3011        96.0456\n",
      "     42       -1.3025       -1.2912        95.9834\n",
      "     43       -1.3056       -1.3157        96.1260\n",
      "     44       -1.3038       -1.3007        96.0271\n",
      "     45       -1.3056       -1.2977        95.8951\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_2 | best epoch: 36 | train loss: -1.3058 | valid loss: -1.3183 | test log likelihood: 1.2012\n",
      "submitit INFO (2019-09-21 10:23:52,665) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Starting with JobEnvironment(job_id=17930894_30, hostname=learnfair0218, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_30/17930894_30_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.1042\u001b[0m       \u001b[32m-2.8135\u001b[0m     +  731.7994\n",
      "      2       \u001b[36m-2.8499\u001b[0m       \u001b[32m-2.8660\u001b[0m     +  363.2995\n",
      "      3       \u001b[36m-2.9282\u001b[0m       \u001b[32m-3.0000\u001b[0m     +  351.0380\n",
      "      4       \u001b[36m-2.9849\u001b[0m       -2.9913        350.8679\n",
      "      5       \u001b[36m-2.9952\u001b[0m       \u001b[32m-3.0732\u001b[0m     +  360.5208\n",
      "      6       \u001b[36m-3.0200\u001b[0m       -3.0169        360.0304\n",
      "      7       \u001b[36m-3.0413\u001b[0m       \u001b[32m-3.0762\u001b[0m     +  366.8477\n",
      "      8       \u001b[36m-3.0432\u001b[0m       -3.0239        372.0525\n",
      "      9       \u001b[36m-3.0607\u001b[0m       -2.5263        369.1950\n",
      "     10       \u001b[36m-3.0713\u001b[0m       \u001b[32m-3.1231\u001b[0m     +  374.5155\n",
      "     11       -3.0665       -3.0902        370.2270\n",
      "     12       -3.0645       -3.0370        364.6367\n",
      "     13       \u001b[36m-3.0942\u001b[0m       -3.0331        361.1306\n",
      "     14       \u001b[36m-3.0963\u001b[0m       -3.1090        372.4944\n",
      "     15       -3.0960       -3.0706        375.4007\n",
      "     16       -3.0956       -3.0957        366.0771\n",
      "     17       \u001b[36m-3.0982\u001b[0m       -3.0850        351.4458\n",
      "     18       \u001b[36m-3.1030\u001b[0m       \u001b[32m-3.2144\u001b[0m     +  345.3145\n",
      "     19       -3.1020       -3.1799        363.2629\n",
      "     20       -3.0992       -3.1424        384.8949\n",
      "     21       -3.0994       -3.0554        380.3576\n",
      "     22       \u001b[36m-3.1088\u001b[0m       -3.0898        386.5174\n",
      "     23       -3.1056       -3.1175        368.0502\n",
      "     24       \u001b[36m-3.1108\u001b[0m       -2.9700        362.9661\n",
      "     25       \u001b[36m-3.1160\u001b[0m       -3.1341        370.0726\n",
      "     26       -3.1142       -3.1572        371.2519\n",
      "     27       -3.1094       -3.1746        388.6518\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_3 | best epoch: 18 | train loss: -3.103 | valid loss: -3.2144 | test log likelihood: 3.0949\n",
      "submitit INFO (2019-09-21 12:11:03,256) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Starting with JobEnvironment(job_id=17930894_31, hostname=learnfair0218, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_31/17930894_31_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0336\u001b[0m       \u001b[32m-2.8595\u001b[0m     +  731.7889\n",
      "      2       \u001b[36m-2.8750\u001b[0m       -2.8494        370.3219\n",
      "      3       \u001b[36m-2.9887\u001b[0m       \u001b[32m-3.0679\u001b[0m     +  357.8553\n",
      "      4       \u001b[36m-3.0535\u001b[0m       -3.0622        354.8923\n",
      "      5       \u001b[36m-3.0646\u001b[0m       \u001b[32m-3.1403\u001b[0m     +  362.7060\n",
      "      6       \u001b[36m-3.1002\u001b[0m       -3.1019        366.6432\n",
      "      7       \u001b[36m-3.1195\u001b[0m       \u001b[32m-3.1559\u001b[0m     +  371.0511\n",
      "      8       -3.1155       -3.1312        376.9891\n",
      "      9       \u001b[36m-3.1403\u001b[0m       -3.0673        376.9681\n",
      "     10       \u001b[36m-3.1526\u001b[0m       \u001b[32m-3.1878\u001b[0m     +  377.8736\n",
      "     11       -3.1472       -3.1632        375.2513\n",
      "     12       -3.1428       -3.1269        368.7280\n",
      "     13       \u001b[36m-3.1773\u001b[0m       -3.1258        367.8385\n",
      "     14       \u001b[36m-3.1800\u001b[0m       \u001b[32m-3.1882\u001b[0m     +  376.2604\n",
      "     15       \u001b[36m-3.1813\u001b[0m       -3.1451        382.6141\n",
      "     16       -3.1787       -3.1743        367.9697\n",
      "     17       \u001b[36m-3.1821\u001b[0m       -3.1731        354.1687\n",
      "     18       \u001b[36m-3.1877\u001b[0m       \u001b[32m-3.2798\u001b[0m     +  351.6416\n",
      "     19       -3.1870       -3.2578        375.0540\n",
      "     20       -3.1799       -3.2265        388.5086\n",
      "     21       -3.1821       -3.1436        382.7528\n",
      "     22       \u001b[36m-3.1901\u001b[0m       -3.1700        388.5163\n",
      "     23       -3.1878       -3.1798        370.8180\n",
      "     24       \u001b[36m-3.1940\u001b[0m       -3.1998        372.3330\n",
      "     25       \u001b[36m-3.1998\u001b[0m       -3.2108        373.9146\n",
      "     26       -3.1965       -3.2276        381.6667\n",
      "     27       -3.1935       -3.2478        384.5393\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_3 | best epoch: 18 | train loss: -3.1877 | valid loss: -3.2798 | test log likelihood: 3.1665\n",
      "submitit INFO (2019-09-21 12:14:14,168) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Starting with JobEnvironment(job_id=17930894_32, hostname=learnfair0218, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,671) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_32/17930894_32_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7303\u001b[0m       \u001b[32m-0.8960\u001b[0m     +  90.2456\n",
      "      2       \u001b[36m-0.9542\u001b[0m       \u001b[32m-0.9323\u001b[0m     +  72.5325\n",
      "      3       \u001b[36m-1.0176\u001b[0m       \u001b[32m-1.0323\u001b[0m     +  78.6028\n",
      "      4       \u001b[36m-1.0521\u001b[0m       \u001b[32m-1.0571\u001b[0m     +  73.4367\n",
      "      5       \u001b[36m-1.0837\u001b[0m       \u001b[32m-1.0751\u001b[0m     +  67.6660\n",
      "      6       \u001b[36m-1.0904\u001b[0m       \u001b[32m-1.0758\u001b[0m     +  69.2173\n",
      "      7       \u001b[36m-1.0954\u001b[0m       \u001b[32m-1.0913\u001b[0m     +  67.8913\n",
      "      8       \u001b[36m-1.1034\u001b[0m       \u001b[32m-1.1118\u001b[0m     +  66.6938\n",
      "      9       -1.1021       \u001b[32m-1.1170\u001b[0m     +  66.6680\n",
      "     10       \u001b[36m-1.1181\u001b[0m       -1.1039        66.4755\n",
      "     11       \u001b[36m-1.1245\u001b[0m       \u001b[32m-1.1328\u001b[0m     +  66.4797\n",
      "     12       \u001b[36m-1.1245\u001b[0m       \u001b[32m-1.1601\u001b[0m     +  66.5492\n",
      "     13       -1.1239       -1.1500        66.6885\n",
      "     14       \u001b[36m-1.1275\u001b[0m       -1.1494        66.6484\n",
      "     15       \u001b[36m-1.1342\u001b[0m       \u001b[32m-1.1845\u001b[0m     +  66.9432\n",
      "     16       \u001b[36m-1.1408\u001b[0m       -1.1362        79.0673\n",
      "     17       \u001b[36m-1.1441\u001b[0m       -1.1802        84.0377\n",
      "     18       \u001b[36m-1.1512\u001b[0m       -1.1692        69.5036\n",
      "     19       \u001b[36m-1.1609\u001b[0m       -1.1496        67.6157\n",
      "     20       -1.1459       -1.1516        91.8500\n",
      "     21       \u001b[36m-1.1648\u001b[0m       -1.1633        82.1908\n",
      "     22       \u001b[36m-1.1667\u001b[0m       -1.1657        76.5637\n",
      "     23       \u001b[36m-1.1675\u001b[0m       -1.1651        74.7185\n",
      "     24       -1.1648       -1.1604        82.8240\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_3 | best epoch: 15 | train loss: -1.1342 | valid loss: -1.1845 | test log likelihood: 1.1251\n",
      "submitit INFO (2019-09-21 09:40:36,172) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,496) - Starting with JobEnvironment(job_id=17930894_33, hostname=learnfair0223, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,496) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_33/17930894_33_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.8297\u001b[0m       \u001b[32m-1.0436\u001b[0m     +  79.2871\n",
      "      2       \u001b[36m-1.0987\u001b[0m       \u001b[32m-1.1106\u001b[0m     +  81.8117\n",
      "      3       \u001b[36m-1.1523\u001b[0m       \u001b[32m-1.1473\u001b[0m     +  82.1656\n",
      "      4       \u001b[36m-1.1547\u001b[0m       \u001b[32m-1.1636\u001b[0m     +  84.1649\n",
      "      5       \u001b[36m-1.1761\u001b[0m       \u001b[32m-1.1713\u001b[0m     +  79.4600\n",
      "      6       \u001b[36m-1.1777\u001b[0m       -1.1610        76.4852\n",
      "      7       \u001b[36m-1.1794\u001b[0m       -1.1708        84.8357\n",
      "      8       \u001b[36m-1.1855\u001b[0m       \u001b[32m-1.1984\u001b[0m     +  78.9021\n",
      "      9       -1.1786       -1.1862        97.2757\n",
      "     10       \u001b[36m-1.1934\u001b[0m       -1.1904        86.3149\n",
      "     11       \u001b[36m-1.1972\u001b[0m       \u001b[32m-1.2046\u001b[0m     +  75.3317\n",
      "     12       -1.1967       \u001b[32m-1.2172\u001b[0m     +  85.0060\n",
      "     13       -1.1932       -1.2104        84.6022\n",
      "     14       \u001b[36m-1.1980\u001b[0m       -1.2106        79.9333\n",
      "     15       \u001b[36m-1.1981\u001b[0m       -1.1899        78.6598\n",
      "     16       \u001b[36m-1.2005\u001b[0m       -1.2022        77.2367\n",
      "     17       \u001b[36m-1.2028\u001b[0m       \u001b[32m-1.2249\u001b[0m     +  88.7324\n",
      "     18       \u001b[36m-1.2051\u001b[0m       -1.2174        93.7075\n",
      "     19       \u001b[36m-1.2110\u001b[0m       -1.2001        86.5061\n",
      "     20       -1.2001       -1.2101        88.6172\n",
      "     21       \u001b[36m-1.2122\u001b[0m       -1.2106        81.5018\n",
      "     22       -1.2105       -1.2045        73.8475\n",
      "     23       -1.2093       -1.2039        74.1901\n",
      "     24       -1.2048       -1.1976        78.1190\n",
      "     25       -1.2083       -1.2110        85.4647\n",
      "     26       \u001b[36m-1.2128\u001b[0m       -1.2191        79.9291\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_3 | best epoch: 17 | train loss: -1.2028 | valid loss: -1.2249 | test log likelihood: 1.1894\n",
      "submitit INFO (2019-09-21 09:46:56,203) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,438) - Starting with JobEnvironment(job_id=17930894_34, hostname=learnfair0227, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,438) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_34/17930894_34_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.2454\u001b[0m       \u001b[32m-3.0644\u001b[0m     +  89.1504\n",
      "      2       \u001b[36m-3.3102\u001b[0m       \u001b[32m-3.5606\u001b[0m     +  90.2828\n",
      "      3       \u001b[36m-3.6046\u001b[0m       \u001b[32m-3.6923\u001b[0m     +  88.9935\n",
      "      4       \u001b[36m-3.6892\u001b[0m       \u001b[32m-3.7463\u001b[0m     +  88.6012\n",
      "      5       \u001b[36m-3.7252\u001b[0m       -3.6917        87.9734\n",
      "      6       \u001b[36m-3.7524\u001b[0m       \u001b[32m-3.7805\u001b[0m     +  89.7884\n",
      "      7       \u001b[36m-3.7624\u001b[0m       \u001b[32m-3.7998\u001b[0m     +  89.1320\n",
      "      8       \u001b[36m-3.7896\u001b[0m       \u001b[32m-3.8007\u001b[0m     +  88.4079\n",
      "      9       \u001b[36m-3.8068\u001b[0m       \u001b[32m-3.8243\u001b[0m     +  91.0668\n",
      "     10       -3.8041       \u001b[32m-3.8452\u001b[0m     +  90.7240\n",
      "     11       -3.7934       -3.7604        89.9665\n",
      "     12       \u001b[36m-3.8153\u001b[0m       -3.8213        89.8365\n",
      "     13       \u001b[36m-3.8163\u001b[0m       \u001b[32m-3.8775\u001b[0m     +  90.3557\n",
      "     14       \u001b[36m-3.8304\u001b[0m       -3.8321        91.6550\n",
      "     15       -3.8281       -3.8193        93.0486\n",
      "     16       \u001b[36m-3.8358\u001b[0m       -3.6723        93.0968\n",
      "     17       -3.8338       -3.8693        92.1084\n",
      "     18       \u001b[36m-3.8402\u001b[0m       -3.8730        90.5352\n",
      "     19       \u001b[36m-3.8428\u001b[0m       -3.8421        90.6073\n",
      "     20       -3.8321       -3.8352        89.8713\n",
      "     21       \u001b[36m-3.8520\u001b[0m       -3.8490        88.8288\n",
      "     22       -3.8428       -3.8126        90.1306\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_3 | best epoch: 13 | train loss: -3.8163 | valid loss: -3.8775 | test log likelihood: 3.8275\n",
      "submitit INFO (2019-09-21 09:44:35,437) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,438) - Starting with JobEnvironment(job_id=17930894_35, hostname=learnfair0227, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,438) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_35/17930894_35_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.3763\u001b[0m       \u001b[32m-3.1418\u001b[0m     +  82.0584\n",
      "      2       \u001b[36m-3.2898\u001b[0m       \u001b[32m-3.3561\u001b[0m     +  82.1964\n",
      "      3       \u001b[36m-3.5946\u001b[0m       \u001b[32m-3.7225\u001b[0m     +  81.8237\n",
      "      4       \u001b[36m-3.6802\u001b[0m       -3.6996        81.4778\n",
      "      5       \u001b[36m-3.7295\u001b[0m       \u001b[32m-3.7855\u001b[0m     +  81.3177\n",
      "      6       \u001b[36m-3.7618\u001b[0m       \u001b[32m-3.7900\u001b[0m     +  81.5952\n",
      "      7       \u001b[36m-3.7838\u001b[0m       -3.7554        81.7738\n",
      "      8       \u001b[36m-3.8114\u001b[0m       \u001b[32m-3.7966\u001b[0m     +  80.6281\n",
      "      9       \u001b[36m-3.8306\u001b[0m       \u001b[32m-3.8345\u001b[0m     +  81.4479\n",
      "     10       \u001b[36m-3.8357\u001b[0m       \u001b[32m-3.8813\u001b[0m     +  81.8537\n",
      "     11       -3.8340       -3.7817        83.8427\n",
      "     12       \u001b[36m-3.8495\u001b[0m       -3.8244        84.2170\n",
      "     13       \u001b[36m-3.8515\u001b[0m       \u001b[32m-3.8986\u001b[0m     +  85.0138\n",
      "     14       \u001b[36m-3.8631\u001b[0m       -3.8665        86.2398\n",
      "     15       -3.8626       -3.8658        84.8982\n",
      "     16       \u001b[36m-3.8703\u001b[0m       -3.8044        83.8101\n",
      "     17       -3.8698       -3.8911        83.0840\n",
      "     18       \u001b[36m-3.8762\u001b[0m       \u001b[32m-3.8999\u001b[0m     +  84.2744\n",
      "     19       -3.8755       -3.8628        85.8084\n",
      "     20       -3.8689       -3.7874        85.7032\n",
      "     21       \u001b[36m-3.8832\u001b[0m       -3.8745        85.7850\n",
      "     22       -3.8817       -3.8405        86.3036\n",
      "     23       \u001b[36m-3.8872\u001b[0m       -3.8566        85.6325\n",
      "     24       -3.8846       -3.8887        86.4708\n",
      "     25       -3.8853       \u001b[32m-3.9027\u001b[0m     +  86.9519\n",
      "     26       -3.8814       \u001b[32m-3.9061\u001b[0m     +  86.5785\n",
      "     27       \u001b[36m-3.8900\u001b[0m       -3.8857        85.0557\n",
      "     28       -3.8815       -3.8205        85.6141\n",
      "     29       \u001b[36m-3.8909\u001b[0m       -3.8655        83.4489\n",
      "     30       \u001b[36m-3.8931\u001b[0m       \u001b[32m-3.9107\u001b[0m     +  84.4682\n",
      "     31       \u001b[36m-3.8977\u001b[0m       \u001b[32m-3.9184\u001b[0m     +  83.8491\n",
      "     32       \u001b[36m-3.9003\u001b[0m       -3.9113        82.2710\n",
      "     33       -3.8952       -3.9035        82.4942\n",
      "     34       -3.8994       \u001b[32m-3.9365\u001b[0m     +  81.7816\n",
      "     35       \u001b[36m-3.9017\u001b[0m       -3.8997        85.0494\n",
      "     36       -3.8996       -3.9323        84.0427\n",
      "     37       \u001b[36m-3.9060\u001b[0m       -3.9172        83.5899\n",
      "     38       -3.9010       -3.9005        84.2323\n",
      "     39       -3.9019       -3.8808        83.7588\n",
      "     40       -3.9027       \u001b[32m-3.9618\u001b[0m     +  83.9115\n",
      "     41       -3.9008       -3.9045        83.8129\n",
      "     42       -3.8973       -3.9221        83.9122\n",
      "     43       \u001b[36m-3.9079\u001b[0m       -3.9122        84.3362\n",
      "     44       -3.8970       -3.9366        84.1321\n",
      "     45       \u001b[36m-3.9168\u001b[0m       -3.9028        84.1964\n",
      "     46       -3.9063       -3.8940        84.3378\n",
      "     47       -3.9048       -3.8961        84.7537\n",
      "     48       \u001b[36m-3.9229\u001b[0m       -3.9196        83.9366\n",
      "     49       -3.8986       -3.8101        84.2524\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_3 | best epoch: 40 | train loss: -3.906 | valid loss: -3.9618 | test log likelihood: 3.8905\n",
      "submitit INFO (2019-09-21 10:20:29,941) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Starting with JobEnvironment(job_id=17930894_36, hostname=learnfair0231, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_36/17930894_36_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.5750\u001b[0m       \u001b[32m-3.2381\u001b[0m     +  963.8059\n",
      "      2       \u001b[36m-3.2541\u001b[0m       \u001b[32m-3.3161\u001b[0m     +  564.6535\n",
      "      3       \u001b[36m-3.3665\u001b[0m       \u001b[32m-3.3636\u001b[0m     +  570.1628\n",
      "      4       \u001b[36m-3.4185\u001b[0m       \u001b[32m-3.4615\u001b[0m     +  572.7258\n",
      "      5       \u001b[36m-3.4367\u001b[0m       -3.4293        579.7161\n",
      "      6       \u001b[36m-3.4537\u001b[0m       -3.4168        582.4748\n",
      "      7       \u001b[36m-3.4757\u001b[0m       \u001b[32m-3.5014\u001b[0m     +  579.0163\n",
      "      8       \u001b[36m-3.4789\u001b[0m       -3.4024        576.5372\n",
      "      9       \u001b[36m-3.4938\u001b[0m       -3.5002        580.9237\n",
      "     10       \u001b[36m-3.5078\u001b[0m       -3.3429        579.9794\n",
      "     11       -3.5077       \u001b[32m-3.5311\u001b[0m     +  560.4991\n",
      "     12       \u001b[36m-3.5102\u001b[0m       -3.5055        574.9136\n",
      "     13       \u001b[36m-3.5317\u001b[0m       -3.5137        595.5058\n",
      "     14       \u001b[36m-3.5348\u001b[0m       -3.4929        603.6836\n",
      "     15       \u001b[36m-3.5370\u001b[0m       \u001b[32m-3.5488\u001b[0m     +  578.1155\n",
      "     16       -3.5361       -3.5430        580.1912\n",
      "     17       \u001b[36m-3.5391\u001b[0m       -3.4948        613.8717\n",
      "     18       \u001b[36m-3.5451\u001b[0m       \u001b[32m-3.5848\u001b[0m     +  632.2101\n",
      "     19       \u001b[36m-3.5465\u001b[0m       \u001b[32m-3.6093\u001b[0m     +  610.4179\n",
      "     20       -3.5429       -3.5863        572.4241\n",
      "     21       -3.5394       -3.5569        581.8829\n",
      "     22       \u001b[36m-3.5478\u001b[0m       -3.5493        606.2149\n",
      "     23       \u001b[36m-3.5488\u001b[0m       -3.5607        600.4486\n",
      "     24       \u001b[36m-3.5546\u001b[0m       -3.5109        593.6687\n",
      "     25       \u001b[36m-3.5563\u001b[0m       -3.6082        594.1445\n",
      "     26       \u001b[36m-3.5586\u001b[0m       -3.5552        595.2645\n",
      "     27       -3.5552       \u001b[32m-3.6148\u001b[0m     +  583.8210\n",
      "     28       -3.5524       -3.5479        571.9751\n",
      "     29       \u001b[36m-3.5644\u001b[0m       -3.5504        567.0073\n",
      "     30       \u001b[36m-3.5655\u001b[0m       -3.5724        585.2494\n",
      "     31       -3.5618       -3.5923        583.9237\n",
      "     32       -3.5589       -3.5789        589.5269\n",
      "     33       -3.5589       -3.5632        591.3519\n",
      "     34       -3.5645       -3.5116        592.8445\n",
      "     35       \u001b[36m-3.5698\u001b[0m       -3.5599        597.4308\n",
      "     36       \u001b[36m-3.5706\u001b[0m       -3.5871        577.1115\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_3 | best epoch: 27 | train loss: -3.5586 | valid loss: -3.6148 | test log likelihood: 3.5623\n",
      "submitit INFO (2019-09-21 15:21:35,450) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Starting with JobEnvironment(job_id=17930894_37, hostname=learnfair0231, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_37/17930894_37_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.5445\u001b[0m       \u001b[32m-3.3052\u001b[0m     +  963.8722\n",
      "      2       \u001b[36m-3.3259\u001b[0m       \u001b[32m-3.3592\u001b[0m     +  557.8794\n",
      "      3       \u001b[36m-3.4456\u001b[0m       \u001b[32m-3.4900\u001b[0m     +  569.2761\n",
      "      4       \u001b[36m-3.5055\u001b[0m       \u001b[32m-3.5183\u001b[0m     +  570.1133\n",
      "      5       \u001b[36m-3.5235\u001b[0m       \u001b[32m-3.5701\u001b[0m     +  578.5598\n",
      "      6       \u001b[36m-3.5502\u001b[0m       -3.5199        583.3453\n",
      "      7       \u001b[36m-3.5567\u001b[0m       -3.5598        574.3038\n",
      "      8       \u001b[36m-3.5639\u001b[0m       \u001b[32m-3.5731\u001b[0m     +  572.8546\n",
      "      9       \u001b[36m-3.5813\u001b[0m       \u001b[32m-3.5926\u001b[0m     +  576.1983\n",
      "     10       \u001b[36m-3.5890\u001b[0m       -3.5910        577.6875\n",
      "     11       -3.5888       \u001b[32m-3.6056\u001b[0m     +  560.3182\n",
      "     12       -3.5888       -3.5787        562.3032\n",
      "     13       \u001b[36m-3.6048\u001b[0m       -3.5750        595.2154\n",
      "     14       \u001b[36m-3.6100\u001b[0m       -3.6038        596.8575\n",
      "     15       -3.6050       -3.6039        579.6531\n",
      "     16       \u001b[36m-3.6104\u001b[0m       \u001b[32m-3.6290\u001b[0m     +  578.2846\n",
      "     17       \u001b[36m-3.6130\u001b[0m       -3.5956        608.7040\n",
      "     18       \u001b[36m-3.6178\u001b[0m       \u001b[32m-3.6456\u001b[0m     +  628.4944\n",
      "     19       \u001b[36m-3.6188\u001b[0m       \u001b[32m-3.6660\u001b[0m     +  610.6105\n",
      "     20       -3.6138       -3.6413        574.4654\n",
      "     21       -3.6113       -3.6164        573.9010\n",
      "     22       \u001b[36m-3.6202\u001b[0m       -3.6079        605.5936\n",
      "     23       -3.6191       -3.6162        598.2748\n",
      "     24       \u001b[36m-3.6244\u001b[0m       -3.6502        590.5720\n",
      "     25       \u001b[36m-3.6257\u001b[0m       -3.6586        585.7904\n",
      "     26       \u001b[36m-3.6270\u001b[0m       -3.6128        593.3055\n",
      "     27       -3.6239       \u001b[32m-3.6691\u001b[0m     +  578.6968\n",
      "     28       -3.6243       -3.6050        570.4307\n",
      "     29       -3.6260       -3.6130        560.6817\n",
      "     30       \u001b[36m-3.6330\u001b[0m       -3.6217        581.8848\n",
      "     31       -3.6293       -3.6480        581.0923\n",
      "     32       -3.6304       -3.6377        587.8240\n",
      "     33       -3.6274       -3.6155        585.7920\n",
      "     34       -3.6328       -3.6093        589.1159\n",
      "     35       \u001b[36m-3.6381\u001b[0m       -3.6328        586.9194\n",
      "     36       \u001b[36m-3.6424\u001b[0m       -3.6413        582.5198\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_3 | best epoch: 27 | train loss: -3.627 | valid loss: -3.6691 | test log likelihood: 3.6206\n",
      "submitit INFO (2019-09-21 15:19:25,847) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Starting with JobEnvironment(job_id=17930894_38, hostname=learnfair0231, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_38/17930894_38_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-1.1560\u001b[0m       \u001b[32m-1.2357\u001b[0m     +  95.0783\n",
      "      2       \u001b[36m-1.2377\u001b[0m       -1.2246        96.6010\n",
      "      3       \u001b[36m-1.2476\u001b[0m       \u001b[32m-1.2608\u001b[0m     +  95.5452\n",
      "      4       \u001b[36m-1.2574\u001b[0m       \u001b[32m-1.2663\u001b[0m     +  95.8335\n",
      "      5       -1.2559       \u001b[32m-1.2668\u001b[0m     +  95.9684\n",
      "      6       \u001b[36m-1.2616\u001b[0m       \u001b[32m-1.2724\u001b[0m     +  95.8337\n",
      "      7       \u001b[36m-1.2630\u001b[0m       -1.2633        95.4473\n",
      "      8       \u001b[36m-1.2676\u001b[0m       \u001b[32m-1.2737\u001b[0m     +  96.2587\n",
      "      9       \u001b[36m-1.2689\u001b[0m       -1.2652        96.1554\n",
      "     10       \u001b[36m-1.2695\u001b[0m       -1.2675        96.2543\n",
      "     11       \u001b[36m-1.2716\u001b[0m       -1.2698        96.3405\n",
      "     12       \u001b[36m-1.2731\u001b[0m       \u001b[32m-1.2787\u001b[0m     +  96.5188\n",
      "     13       \u001b[36m-1.2734\u001b[0m       -1.2770        96.4104\n",
      "     14       \u001b[36m-1.2741\u001b[0m       -1.2739        96.4583\n",
      "     15       \u001b[36m-1.2743\u001b[0m       \u001b[32m-1.2805\u001b[0m     +  96.4955\n",
      "     16       -1.2722       -1.2697        95.6106\n",
      "     17       -1.2735       -1.2688        96.0018\n",
      "     18       -1.2736       -1.2709        96.0418\n",
      "     19       -1.2723       \u001b[32m-1.2851\u001b[0m     +  95.7700\n",
      "     20       \u001b[36m-1.2756\u001b[0m       -1.2685        95.5199\n",
      "     21       -1.2732       -1.2815        95.8417\n",
      "     22       -1.2745       -1.2735        95.6639\n",
      "     23       -1.2723       -1.2796        95.7989\n",
      "     24       -1.2751       \u001b[32m-1.2867\u001b[0m     +  95.6191\n",
      "     25       -1.2749       -1.2763        96.5657\n",
      "     26       -1.2723       -1.2726        95.7311\n",
      "     27       -1.2721       -1.2756        95.7269\n",
      "     28       -1.2708       -1.2763        95.7918\n",
      "     29       -1.2755       -1.2867        95.7507\n",
      "     30       \u001b[36m-1.2772\u001b[0m       -1.2703        95.4758\n",
      "     31       -1.2756       -1.2740        95.8528\n",
      "     32       -1.2676       -1.2156        95.5815\n",
      "     33       -1.2444       -1.1972        96.2017\n",
      "     34       -1.2324       -1.2386        96.5547\n",
      "     35       -1.2239       -1.1672        96.6896\n",
      "     36       -1.2061       -1.1951        96.4333\n",
      "     37       -1.1120       -1.1826        95.5938\n",
      "     38       -1.1408       -1.1555        96.0002\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_3 | best epoch: 24 | train loss: -1.2756 | valid loss: -1.2867 | test log likelihood: 1.1525\n",
      "submitit INFO (2019-09-21 10:12:33,204) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Starting with JobEnvironment(job_id=17930894_39, hostname=learnfair0231, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,962) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_39/17930894_39_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1451\u001b[0m       \u001b[32m-1.2201\u001b[0m     +  108.3314\n",
      "      2       \u001b[36m-1.2351\u001b[0m       \u001b[32m-1.2299\u001b[0m     +  99.2437\n",
      "      3       \u001b[36m-1.2572\u001b[0m       \u001b[32m-1.2778\u001b[0m     +  97.2931\n",
      "      4       \u001b[36m-1.2759\u001b[0m       \u001b[32m-1.2856\u001b[0m     +  107.1786\n",
      "      5       \u001b[36m-1.2806\u001b[0m       \u001b[32m-1.2919\u001b[0m     +  97.9987\n",
      "      6       \u001b[36m-1.2866\u001b[0m       \u001b[32m-1.2986\u001b[0m     +  99.9852\n",
      "      7       \u001b[36m-1.2884\u001b[0m       -1.2930        107.4735\n",
      "      8       \u001b[36m-1.2924\u001b[0m       -1.2963        126.2834\n",
      "      9       -1.2920       -1.2899        138.9592\n",
      "     10       \u001b[36m-1.2931\u001b[0m       -1.2888        124.1475\n",
      "     11       \u001b[36m-1.2949\u001b[0m       -1.2939        129.4389\n",
      "     12       \u001b[36m-1.2956\u001b[0m       \u001b[32m-1.3011\u001b[0m     +  136.5607\n",
      "     13       \u001b[36m-1.2971\u001b[0m       -1.2989        130.3526\n",
      "     14       \u001b[36m-1.2974\u001b[0m       -1.2950        140.0409\n",
      "     15       \u001b[36m-1.2979\u001b[0m       -1.3008        124.9424\n",
      "     16       -1.2972       -1.2953        134.8664\n",
      "     17       \u001b[36m-1.2994\u001b[0m       -1.2935        124.4057\n",
      "     18       -1.2991       -1.2986        132.5990\n",
      "     19       -1.2983       \u001b[32m-1.3093\u001b[0m     +  135.5527\n",
      "     20       \u001b[36m-1.3010\u001b[0m       -1.2942        131.1335\n",
      "     21       -1.3006       -1.3083        133.5554\n",
      "     22       -1.3008       -1.3028        129.9632\n",
      "     23       -1.2994       -1.3039        126.6536\n",
      "     24       -1.3009       \u001b[32m-1.3115\u001b[0m     +  124.5808\n",
      "     25       \u001b[36m-1.3015\u001b[0m       -1.3008        142.6571\n",
      "     26       -1.3007       -1.2983        133.9765\n",
      "     27       \u001b[36m-1.3018\u001b[0m       -1.3019        133.5936\n",
      "     28       \u001b[36m-1.3025\u001b[0m       -1.3055        146.3709\n",
      "     29       \u001b[36m-1.3033\u001b[0m       \u001b[32m-1.3127\u001b[0m     +  122.2160\n",
      "     30       \u001b[36m-1.3042\u001b[0m       -1.2977        152.2263\n",
      "     31       -1.3033       -1.3001        120.5855\n",
      "     32       \u001b[36m-1.3045\u001b[0m       -1.3004        148.4268\n",
      "     33       -1.3027       -1.3082        136.4783\n",
      "     34       -1.3043       -1.3031        138.6526\n",
      "     35       -1.3040       -1.3047        121.3527\n",
      "     36       -1.3044       -1.3030        133.7667\n",
      "     37       -1.3024       -1.3092        132.3052\n",
      "     38       \u001b[36m-1.3046\u001b[0m       -1.2995        136.4170\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_3 | best epoch: 29 | train loss: -1.3033 | valid loss: -1.3127 | test log likelihood: 1.2059\n",
      "submitit INFO (2019-09-21 10:34:17,212) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Starting with JobEnvironment(job_id=17930894_40, hostname=learnfair0235, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_40/17930894_40_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0347\u001b[0m       \u001b[32m-2.6602\u001b[0m     +  835.6880\n",
      "      2       \u001b[36m-2.8348\u001b[0m       \u001b[32m-2.9296\u001b[0m     +  414.7730\n",
      "      3       \u001b[36m-2.9241\u001b[0m       \u001b[32m-2.9461\u001b[0m     +  400.1463\n",
      "      4       \u001b[36m-2.9644\u001b[0m       -2.9449        391.8978\n",
      "      5       \u001b[36m-2.9919\u001b[0m       \u001b[32m-3.0148\u001b[0m     +  388.0285\n",
      "      6       \u001b[36m-3.0125\u001b[0m       -3.0124        396.2808\n",
      "      7       \u001b[36m-3.0364\u001b[0m       -3.0051        397.2579\n",
      "      8       -3.0310       -3.0060        396.0707\n",
      "      9       \u001b[36m-3.0460\u001b[0m       -2.9364        401.9719\n",
      "     10       \u001b[36m-3.0523\u001b[0m       \u001b[32m-3.1288\u001b[0m     +  406.0959\n",
      "     11       \u001b[36m-3.0596\u001b[0m       -3.0308        407.5160\n",
      "     12       \u001b[36m-3.0686\u001b[0m       -3.0915        406.1322\n",
      "     13       \u001b[36m-3.0723\u001b[0m       -3.0508        405.8291\n",
      "     14       \u001b[36m-3.0771\u001b[0m       -3.0258        412.9308\n",
      "     15       -3.0761       -3.1219        408.0507\n",
      "     16       -3.0748       \u001b[32m-3.1312\u001b[0m     +  390.5698\n",
      "     17       \u001b[36m-3.0910\u001b[0m       -3.0451        389.8902\n",
      "     18       \u001b[36m-3.1028\u001b[0m       -3.0700        425.0058\n",
      "     19       -3.0862       -3.1167        431.4791\n",
      "     20       -3.0824       -3.0252        412.9475\n",
      "     21       -3.0736       -3.0512        394.0837\n",
      "     22       \u001b[36m-3.1035\u001b[0m       \u001b[32m-3.1553\u001b[0m     +  400.8106\n",
      "     23       -3.0852       -3.0946        425.6692\n",
      "     24       -3.1035       -2.9968        424.3618\n",
      "     25       -3.0990       -3.0767        449.6165\n",
      "     26       \u001b[36m-3.1063\u001b[0m       -3.1255        507.5379\n",
      "     27       \u001b[36m-3.1222\u001b[0m       -3.0997        446.2259\n",
      "     28       -3.1204       -3.0434        412.0878\n",
      "     29       -3.1093       -3.1005        405.1867\n",
      "     30       -3.1092       -3.1240        429.4670\n",
      "     31       -3.1084       -3.0974        480.8938\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_4 | best epoch: 22 | train loss: -3.1035 | valid loss: -3.1553 | test log likelihood: 3.0857\n",
      "submitit INFO (2019-09-21 13:03:38,548) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Starting with JobEnvironment(job_id=17930894_41, hostname=learnfair0235, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_41/17930894_41_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0351\u001b[0m       \u001b[32m-2.5134\u001b[0m     +  835.7457\n",
      "      2       \u001b[36m-2.8192\u001b[0m       \u001b[32m-2.9563\u001b[0m     +  409.5027\n",
      "      3       \u001b[36m-2.9768\u001b[0m       \u001b[32m-3.0028\u001b[0m     +  394.3731\n",
      "      4       \u001b[36m-3.0337\u001b[0m       \u001b[32m-3.0109\u001b[0m     +  383.4735\n",
      "      5       \u001b[36m-3.0712\u001b[0m       \u001b[32m-3.1079\u001b[0m     +  382.9687\n",
      "      6       \u001b[36m-3.0933\u001b[0m       -3.0948        393.2462\n",
      "      7       \u001b[36m-3.1220\u001b[0m       -3.0830        390.9869\n",
      "      8       -3.1160       \u001b[32m-3.1152\u001b[0m     +  392.1237\n",
      "      9       \u001b[36m-3.1333\u001b[0m       \u001b[32m-3.1197\u001b[0m     +  395.6382\n",
      "     10       \u001b[36m-3.1404\u001b[0m       \u001b[32m-3.2052\u001b[0m     +  402.1829\n",
      "     11       \u001b[36m-3.1465\u001b[0m       -3.1133        402.2509\n",
      "     12       \u001b[36m-3.1573\u001b[0m       -3.1649        398.5935\n",
      "     13       \u001b[36m-3.1613\u001b[0m       -3.1312        401.2081\n",
      "     14       \u001b[36m-3.1668\u001b[0m       -3.1839        408.3642\n",
      "     15       -3.1599       -3.1979        401.7550\n",
      "     16       -3.1652       \u001b[32m-3.2105\u001b[0m     +  386.9422\n",
      "     17       \u001b[36m-3.1809\u001b[0m       -3.1431        381.6228\n",
      "     18       \u001b[36m-3.1948\u001b[0m       -3.1719        410.7116\n",
      "     19       -3.1757       -3.2005        430.5712\n",
      "     20       -3.1793       -3.1319        408.9099\n",
      "     21       -3.1707       -3.1414        394.3152\n",
      "     22       \u001b[36m-3.1951\u001b[0m       \u001b[32m-3.2425\u001b[0m     +  394.8855\n",
      "     23       -3.1768       -3.1794        418.7169\n",
      "     24       \u001b[36m-3.1956\u001b[0m       -3.1493        412.5515\n",
      "     25       -3.1888       -3.1550        431.6759\n",
      "     26       \u001b[36m-3.1967\u001b[0m       -3.2143        492.8657\n",
      "     27       \u001b[36m-3.2127\u001b[0m       -3.1819        463.9836\n",
      "     28       -3.2105       -3.1635        416.1824\n",
      "     29       -3.2002       -3.1834        385.5592\n",
      "     30       -3.2004       -3.2307        407.5851\n",
      "     31       -3.1986       -3.1858        487.2199\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_4 | best epoch: 22 | train loss: -3.1951 | valid loss: -3.2425 | test log likelihood: 3.176\n",
      "submitit INFO (2019-09-21 12:59:33,354) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Starting with JobEnvironment(job_id=17930894_42, hostname=learnfair0235, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_42/17930894_42_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7294\u001b[0m       \u001b[32m-0.8654\u001b[0m     +  73.6336\n",
      "      2       \u001b[36m-0.9381\u001b[0m       \u001b[32m-0.9566\u001b[0m     +  73.2178\n",
      "      3       \u001b[36m-0.9991\u001b[0m       \u001b[32m-1.0215\u001b[0m     +  73.7171\n",
      "      4       \u001b[36m-1.0418\u001b[0m       \u001b[32m-1.0936\u001b[0m     +  73.7387\n",
      "      5       \u001b[36m-1.0672\u001b[0m       -1.0631        74.1546\n",
      "      6       \u001b[36m-1.0892\u001b[0m       -1.0891        73.5582\n",
      "      7       \u001b[36m-1.0991\u001b[0m       \u001b[32m-1.1298\u001b[0m     +  73.7625\n",
      "      8       \u001b[36m-1.1154\u001b[0m       -1.1044        74.2621\n",
      "      9       -1.1117       -1.1108        73.2441\n",
      "     10       \u001b[36m-1.1201\u001b[0m       -1.1216        74.6709\n",
      "     11       \u001b[36m-1.1217\u001b[0m       \u001b[32m-1.1435\u001b[0m     +  73.8971\n",
      "     12       \u001b[36m-1.1319\u001b[0m       \u001b[32m-1.1493\u001b[0m     +  74.6984\n",
      "     13       \u001b[36m-1.1346\u001b[0m       -1.1398        72.9370\n",
      "     14       \u001b[36m-1.1374\u001b[0m       -1.1290        74.4982\n",
      "     15       \u001b[36m-1.1588\u001b[0m       \u001b[32m-1.1509\u001b[0m     +  74.3191\n",
      "     16       -1.1479       \u001b[32m-1.1685\u001b[0m     +  74.3982\n",
      "     17       -1.1563       -1.1581        74.3184\n",
      "     18       -1.1563       \u001b[32m-1.1948\u001b[0m     +  74.0713\n",
      "     19       \u001b[36m-1.1639\u001b[0m       -1.1404        73.6201\n",
      "     20       \u001b[36m-1.1656\u001b[0m       -1.1897        73.8337\n",
      "     21       \u001b[36m-1.1692\u001b[0m       -1.1786        74.2063\n",
      "     22       -1.1580       -1.1738        74.4133\n",
      "     23       -1.1691       -1.1666        74.6050\n",
      "     24       -1.1657       -1.1769        74.4260\n",
      "     25       \u001b[36m-1.1710\u001b[0m       -1.1658        73.6528\n",
      "     26       -1.1704       -1.1587        74.1630\n",
      "     27       \u001b[36m-1.1736\u001b[0m       -1.1815        75.1271\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_4 | best epoch: 18 | train loss: -1.1588 | valid loss: -1.1948 | test log likelihood: 1.1517\n",
      "submitit INFO (2019-09-21 09:44:29,669) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Starting with JobEnvironment(job_id=17930894_43, hostname=learnfair0235, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_43/17930894_43_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7932\u001b[0m       \u001b[32m-0.9690\u001b[0m     +  78.0727\n",
      "      2       \u001b[36m-1.0849\u001b[0m       \u001b[32m-1.1298\u001b[0m     +  76.2437\n",
      "      3       \u001b[36m-1.1506\u001b[0m       \u001b[32m-1.1603\u001b[0m     +  68.9298\n",
      "      4       \u001b[36m-1.1622\u001b[0m       \u001b[32m-1.1962\u001b[0m     +  77.8284\n",
      "      5       \u001b[36m-1.1710\u001b[0m       -1.1747        87.2840\n",
      "      6       \u001b[36m-1.1775\u001b[0m       -1.1689        87.2900\n",
      "      7       \u001b[36m-1.1832\u001b[0m       \u001b[32m-1.2026\u001b[0m     +  88.3385\n",
      "      8       \u001b[36m-1.1915\u001b[0m       -1.1833        87.7254\n",
      "      9       -1.1897       -1.1914        87.4446\n",
      "     10       \u001b[36m-1.1940\u001b[0m       -1.1949        90.6338\n",
      "     11       -1.1923       -1.2019        91.7918\n",
      "     12       \u001b[36m-1.1975\u001b[0m       \u001b[32m-1.2055\u001b[0m     +  91.2929\n",
      "     13       -1.1960       -1.1990        89.6097\n",
      "     14       \u001b[36m-1.1976\u001b[0m       -1.1925        89.0877\n",
      "     15       \u001b[36m-1.2087\u001b[0m       -1.1975        88.7132\n",
      "     16       -1.2015       \u001b[32m-1.2264\u001b[0m     +  88.5372\n",
      "     17       -1.2045       -1.2036        87.6645\n",
      "     18       -1.2060       \u001b[32m-1.2313\u001b[0m     +  88.7513\n",
      "     19       -1.2077       -1.2101        88.8342\n",
      "     20       \u001b[36m-1.2088\u001b[0m       -1.2272        87.5029\n",
      "     21       \u001b[36m-1.2103\u001b[0m       -1.2164        88.3093\n",
      "     22       -1.2020       -1.2156        87.7479\n",
      "     23       -1.2094       -1.2078        86.9200\n",
      "     24       -1.2070       -1.2165        89.0836\n",
      "     25       -1.2093       -1.2045        92.7086\n",
      "     26       -1.2086       -1.2034        94.1702\n",
      "     27       \u001b[36m-1.2106\u001b[0m       -1.2198        92.9880\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_4 | best epoch: 18 | train loss: -1.2087 | valid loss: -1.2313 | test log likelihood: 1.1915\n",
      "submitit INFO (2019-09-21 09:50:39,601) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Starting with JobEnvironment(job_id=17930894_44, hostname=learnfair0235, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,079) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_44/17930894_44_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.2921\u001b[0m       \u001b[32m-2.8914\u001b[0m     +  87.9824\n",
      "      2       \u001b[36m-3.1526\u001b[0m       \u001b[32m-3.4126\u001b[0m     +  89.5595\n",
      "      3       \u001b[36m-3.5010\u001b[0m       \u001b[32m-3.6232\u001b[0m     +  89.2962\n",
      "      4       \u001b[36m-3.6444\u001b[0m       \u001b[32m-3.7408\u001b[0m     +  89.9152\n",
      "      5       \u001b[36m-3.6970\u001b[0m       \u001b[32m-3.7503\u001b[0m     +  89.4869\n",
      "      6       \u001b[36m-3.7483\u001b[0m       \u001b[32m-3.8333\u001b[0m     +  89.7852\n",
      "      7       \u001b[36m-3.7629\u001b[0m       -3.7364        90.2309\n",
      "      8       \u001b[36m-3.7850\u001b[0m       -3.7599        89.2608\n",
      "      9       -3.7802       -3.6895        90.6591\n",
      "     10       \u001b[36m-3.7953\u001b[0m       -3.7722        91.0190\n",
      "     11       \u001b[36m-3.7993\u001b[0m       \u001b[32m-3.8373\u001b[0m     +  91.4927\n",
      "     12       \u001b[36m-3.8095\u001b[0m       \u001b[32m-3.8708\u001b[0m     +  90.9192\n",
      "     13       \u001b[36m-3.8194\u001b[0m       -3.8318        90.4723\n",
      "     14       \u001b[36m-3.8223\u001b[0m       -3.8156        90.4161\n",
      "     15       \u001b[36m-3.8247\u001b[0m       -3.8459        89.3010\n",
      "     16       \u001b[36m-3.8366\u001b[0m       \u001b[32m-3.8718\u001b[0m     +  89.5845\n",
      "     17       \u001b[36m-3.8369\u001b[0m       -3.8438        89.7543\n",
      "     18       -3.8265       -3.8482        89.5217\n",
      "     19       -3.8346       -3.8660        89.0206\n",
      "     20       -3.8356       -3.7863        89.1599\n",
      "     21       \u001b[36m-3.8427\u001b[0m       -3.8112        89.5661\n",
      "     22       -3.8346       -3.7496        89.5794\n",
      "     23       -3.8422       -3.8378        89.5937\n",
      "     24       \u001b[36m-3.8485\u001b[0m       -3.8699        91.1317\n",
      "     25       -3.8471       -3.7670        90.8736\n",
      "     26       -3.8417       \u001b[32m-3.8745\u001b[0m     +  90.4731\n",
      "     27       \u001b[36m-3.8491\u001b[0m       \u001b[32m-3.8771\u001b[0m     +  89.4303\n",
      "     28       -3.8450       -3.8615        87.5348\n",
      "     29       \u001b[36m-3.8578\u001b[0m       \u001b[32m-3.8840\u001b[0m     +  87.6164\n",
      "     30       -3.8472       -3.7420        87.6142\n",
      "     31       -3.8562       \u001b[32m-3.9077\u001b[0m     +  87.4084\n",
      "     32       -3.8525       -3.8582        87.5354\n",
      "     33       -3.8461       -3.8622        87.0087\n",
      "     34       -3.8565       -3.8887        86.8673\n",
      "     35       \u001b[36m-3.8636\u001b[0m       -3.8869        87.8183\n",
      "     36       -3.8523       -3.8714        87.8593\n",
      "     37       -3.8552       -3.8321        87.8834\n",
      "     38       -3.8617       -3.8253        88.7725\n",
      "     39       -3.8532       -3.8743        88.4811\n",
      "     40       \u001b[36m-3.8717\u001b[0m       -3.8979        88.7755\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_4 | best epoch: 31 | train loss: -3.8578 | valid loss: -3.9077 | test log likelihood: 3.8512\n",
      "submitit INFO (2019-09-21 10:11:24,216) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,090) - Starting with JobEnvironment(job_id=17930894_45, hostname=learnfair0239, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,090) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_45/17930894_45_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.2416\u001b[0m       \u001b[32m-3.1377\u001b[0m     +  123.3764\n",
      "      2       \u001b[36m-3.3502\u001b[0m       \u001b[32m-3.6014\u001b[0m     +  122.8603\n",
      "      3       \u001b[36m-3.5812\u001b[0m       \u001b[32m-3.6623\u001b[0m     +  122.5994\n",
      "      4       \u001b[36m-3.6619\u001b[0m       \u001b[32m-3.7419\u001b[0m     +  119.8440\n",
      "      5       \u001b[36m-3.7056\u001b[0m       -3.6142        122.6137\n",
      "      6       \u001b[36m-3.7653\u001b[0m       \u001b[32m-3.8387\u001b[0m     +  122.4648\n",
      "      7       \u001b[36m-3.7918\u001b[0m       -3.7629        120.7234\n",
      "      8       \u001b[36m-3.7967\u001b[0m       -3.7789        121.1957\n",
      "      9       \u001b[36m-3.8092\u001b[0m       -3.7949        122.5268\n",
      "     10       \u001b[36m-3.8182\u001b[0m       \u001b[32m-3.8491\u001b[0m     +  122.2693\n",
      "     11       \u001b[36m-3.8355\u001b[0m       \u001b[32m-3.8843\u001b[0m     +  120.4391\n",
      "     12       -3.8324       \u001b[32m-3.8921\u001b[0m     +  123.1774\n",
      "     13       \u001b[36m-3.8518\u001b[0m       -3.8580        120.2091\n",
      "     14       \u001b[36m-3.8570\u001b[0m       -3.8513        122.7057\n",
      "     15       -3.8562       -3.8770        122.6901\n",
      "     16       \u001b[36m-3.8647\u001b[0m       \u001b[32m-3.9005\u001b[0m     +  122.6116\n",
      "     17       \u001b[36m-3.8744\u001b[0m       -3.8712        123.0006\n",
      "     18       -3.8618       -3.8663        122.8186\n",
      "     19       -3.8732       -3.8762        122.4098\n",
      "     20       -3.8734       -3.8155        122.8148\n",
      "     21       \u001b[36m-3.8787\u001b[0m       -3.8670        122.3054\n",
      "     22       -3.8745       -3.8731        122.1209\n",
      "     23       -3.8694       \u001b[32m-3.9122\u001b[0m     +  122.9659\n",
      "     24       \u001b[36m-3.8885\u001b[0m       -3.8992        122.9922\n",
      "     25       -3.8833       -3.8240        122.5494\n",
      "     26       -3.8834       -3.8980        122.6831\n",
      "     27       \u001b[36m-3.8894\u001b[0m       -3.8417        122.8834\n",
      "     28       -3.8828       -3.8883        122.6908\n",
      "     29       \u001b[36m-3.8987\u001b[0m       \u001b[32m-3.9176\u001b[0m     +  122.3554\n",
      "     30       -3.8861       -3.8657        122.2730\n",
      "     31       -3.8957       \u001b[32m-3.9300\u001b[0m     +  122.8147\n",
      "     32       -3.8921       -3.9023        122.8120\n",
      "     33       -3.8864       -3.8906        120.9215\n",
      "     34       -3.8956       -3.9259        119.9426\n",
      "     35       \u001b[36m-3.9050\u001b[0m       -3.9197        121.9512\n",
      "     36       -3.8934       -3.9063        119.9817\n",
      "     37       -3.8959       -3.9166        122.6111\n",
      "     38       -3.8981       -3.9009        122.0042\n",
      "     39       -3.8914       -3.8956        122.5789\n",
      "     40       \u001b[36m-3.9106\u001b[0m       -3.9236        121.9015\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_4 | best epoch: 31 | train loss: -3.8987 | valid loss: -3.93 | test log likelihood: 3.8751\n",
      "submitit INFO (2019-09-21 10:34:16,477) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,856) - Starting with JobEnvironment(job_id=17930894_46, hostname=learnfair0242, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,856) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_46/17930894_46_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.5489\u001b[0m       \u001b[32m-3.2265\u001b[0m     +  980.4899\n",
      "      2       \u001b[36m-3.2786\u001b[0m       \u001b[32m-3.3377\u001b[0m     +  564.8972\n",
      "      3       \u001b[36m-3.3778\u001b[0m       \u001b[32m-3.3714\u001b[0m     +  567.5915\n",
      "      4       \u001b[36m-3.4144\u001b[0m       \u001b[32m-3.4436\u001b[0m     +  571.1641\n",
      "      5       \u001b[36m-3.4448\u001b[0m       \u001b[32m-3.4860\u001b[0m     +  573.4632\n",
      "      6       \u001b[36m-3.4612\u001b[0m       -3.3914        570.0439\n",
      "      7       \u001b[36m-3.4820\u001b[0m       -3.4431        571.0660\n",
      "      8       -3.4792       \u001b[32m-3.5222\u001b[0m     +  570.1987\n",
      "      9       \u001b[36m-3.4922\u001b[0m       -3.5034        573.6847\n",
      "     10       \u001b[36m-3.5085\u001b[0m       \u001b[32m-3.5399\u001b[0m     +  576.2990\n",
      "     11       -3.5084       -3.5316        557.1520\n",
      "     12       \u001b[36m-3.5203\u001b[0m       -3.5344        546.7806\n",
      "     13       \u001b[36m-3.5258\u001b[0m       \u001b[32m-3.5542\u001b[0m     +  584.9534\n",
      "     14       \u001b[36m-3.5322\u001b[0m       -3.5347        580.9805\n",
      "     15       -3.5315       -3.5369        554.9104\n",
      "     16       \u001b[36m-3.5370\u001b[0m       \u001b[32m-3.5587\u001b[0m     +  565.6659\n",
      "     17       \u001b[36m-3.5432\u001b[0m       -3.5350        560.9146\n",
      "     18       \u001b[36m-3.5516\u001b[0m       \u001b[32m-3.5615\u001b[0m     +  580.2510\n",
      "     19       -3.5453       -3.5583        579.0971\n",
      "     20       -3.5447       -3.5007        549.4059\n",
      "     21       -3.5404       -3.5507        545.1907\n",
      "     22       \u001b[36m-3.5575\u001b[0m       \u001b[32m-3.5880\u001b[0m     +  601.1731\n",
      "     23       -3.5442       -3.5539        594.4502\n",
      "     24       \u001b[36m-3.5591\u001b[0m       -3.5529        576.0402\n",
      "     25       -3.5530       -3.5621        568.1077\n",
      "     26       \u001b[36m-3.5629\u001b[0m       -3.5758        571.8347\n",
      "     27       \u001b[36m-3.5720\u001b[0m       -3.5161        564.8424\n",
      "     28       -3.5679       \u001b[32m-3.5991\u001b[0m     +  566.3102\n",
      "     29       -3.5621       -3.5477        560.1456\n",
      "     30       -3.5657       -3.5715        549.3037\n",
      "     31       -3.5615       -3.5749        556.8610\n",
      "     32       \u001b[36m-3.5751\u001b[0m       -3.5954        570.1441\n",
      "     33       -3.5680       -3.5722        584.3712\n",
      "     34       -3.5750       -3.5762        580.2306\n",
      "     35       -3.5673       -3.5913        593.9160\n",
      "     36       -3.5627       \u001b[32m-3.6078\u001b[0m     +  590.0061\n",
      "     37       -3.5571       -3.5864        598.1171\n",
      "     38       -3.5641       \u001b[32m-3.6101\u001b[0m     +  581.5485\n",
      "     39       -3.5743       -3.6066        564.9266\n",
      "     40       -3.5661       -3.5842        572.2037\n",
      "     41       \u001b[36m-3.5852\u001b[0m       -3.5740        585.7616\n",
      "     42       -3.5662       -3.5516        584.0559\n",
      "     43       -3.5765       \u001b[32m-3.6112\u001b[0m     +  586.6853\n",
      "     44       -3.5728       -3.5910        588.7294\n",
      "     45       -3.5751       -3.5969        586.4775\n",
      "     46       -3.5707       -3.5627        582.5759\n",
      "     47       -3.5657       -3.5819        587.6374\n",
      "     48       -3.5670       -3.5793        584.7465\n",
      "     49       -3.5744       -3.5562        585.0240\n",
      "     50       -3.5728       -3.5500        590.7723\n",
      "     51       \u001b[36m-3.5856\u001b[0m       -3.6042        586.3086\n",
      "     52       -3.5740       -3.6046        611.1275\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_4 | best epoch: 43 | train loss: -3.5852 | valid loss: -3.6112 | test log likelihood: 3.5636\n",
      "submitit INFO (2019-09-21 17:51:06,880) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Starting with JobEnvironment(job_id=17930894_47, hostname=learnfair0246, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,835) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_47/17930894_47_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.5681\u001b[0m       \u001b[32m-3.3486\u001b[0m     +  1148.1751\n",
      "      2       \u001b[36m-3.3636\u001b[0m       \u001b[32m-3.4574\u001b[0m     +  615.3378\n",
      "      3       \u001b[36m-3.4581\u001b[0m       \u001b[32m-3.4623\u001b[0m     +  608.9339\n",
      "      4       \u001b[36m-3.4988\u001b[0m       \u001b[32m-3.5071\u001b[0m     +  626.0333\n",
      "      5       \u001b[36m-3.5285\u001b[0m       \u001b[32m-3.5532\u001b[0m     +  631.1496\n",
      "      6       \u001b[36m-3.5524\u001b[0m       -3.5354        624.9131\n",
      "      7       \u001b[36m-3.5699\u001b[0m       -3.5332        630.0393\n",
      "      8       \u001b[36m-3.5714\u001b[0m       \u001b[32m-3.5794\u001b[0m     +  615.4248\n",
      "      9       \u001b[36m-3.5792\u001b[0m       -3.5577        624.3310\n",
      "     10       \u001b[36m-3.5936\u001b[0m       \u001b[32m-3.6073\u001b[0m     +  624.1527\n",
      "     11       \u001b[36m-3.5953\u001b[0m       -3.6009        603.6079\n",
      "     12       \u001b[36m-3.6006\u001b[0m       -3.6026        641.9900\n",
      "     13       \u001b[36m-3.6066\u001b[0m       \u001b[32m-3.6179\u001b[0m     +  631.4933\n",
      "     14       \u001b[36m-3.6099\u001b[0m       -3.6002        620.0631\n",
      "     15       \u001b[36m-3.6112\u001b[0m       -3.6007        638.1790\n",
      "     16       -3.6106       \u001b[32m-3.6237\u001b[0m     +  641.3013\n",
      "     17       \u001b[36m-3.6198\u001b[0m       \u001b[32m-3.6253\u001b[0m     +  662.0227\n",
      "     18       \u001b[36m-3.6265\u001b[0m       -3.6215        621.6906\n",
      "     19       -3.6173       -3.6244        607.2456\n",
      "     20       -3.6186       -3.5713        655.0905\n",
      "     21       -3.6129       -3.6148        637.2956\n",
      "     22       \u001b[36m-3.6306\u001b[0m       \u001b[32m-3.6473\u001b[0m     +  634.5091\n",
      "     23       -3.6161       -3.6142        628.9087\n",
      "     24       -3.6303       -3.6080        627.2223\n",
      "     25       -3.6263       -3.6178        635.8101\n",
      "     26       \u001b[36m-3.6325\u001b[0m       -3.6360        624.3622\n",
      "     27       \u001b[36m-3.6413\u001b[0m       -3.6081        611.6219\n",
      "     28       -3.6368       \u001b[32m-3.6574\u001b[0m     +  630.4592\n",
      "     29       -3.6317       -3.6094        629.0101\n",
      "     30       -3.6350       -3.6333        634.9495\n",
      "     31       -3.6307       -3.6343        636.5397\n",
      "     32       \u001b[36m-3.6443\u001b[0m       \u001b[32m-3.6732\u001b[0m     +  638.5917\n",
      "     33       -3.6396       -3.6326        643.0883\n",
      "     34       \u001b[36m-3.6446\u001b[0m       -3.6546        636.4294\n",
      "     35       -3.6392       -3.6496        650.1164\n",
      "     36       -3.6356       -3.6645        645.1567\n",
      "     37       -3.6299       -3.6588        644.6753\n",
      "     38       -3.6349       -3.6724        663.8628\n",
      "     39       -3.6405       -3.6715        653.5068\n",
      "     40       -3.6356       -3.6459        663.1846\n",
      "     41       \u001b[36m-3.6511\u001b[0m       -3.6338        650.1549\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_4 | best epoch: 32 | train loss: -3.6443 | valid loss: -3.6732 | test log likelihood: 3.6282\n",
      "submitit INFO (2019-09-21 16:47:09,476) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Starting with JobEnvironment(job_id=17930894_48, hostname=learnfair0246, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,835) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_48/17930894_48_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1732\u001b[0m       \u001b[32m-1.2123\u001b[0m     +  108.2274\n",
      "      2       \u001b[36m-1.2431\u001b[0m       \u001b[32m-1.2519\u001b[0m     +  106.8394\n",
      "      3       \u001b[36m-1.2500\u001b[0m       \u001b[32m-1.2573\u001b[0m     +  107.4365\n",
      "      4       \u001b[36m-1.2529\u001b[0m       \u001b[32m-1.2603\u001b[0m     +  106.5721\n",
      "      5       \u001b[36m-1.2562\u001b[0m       -1.2511        106.4328\n",
      "      6       \u001b[36m-1.2641\u001b[0m       \u001b[32m-1.2685\u001b[0m     +  107.1632\n",
      "      7       -1.2602       -1.2601        107.0812\n",
      "      8       -1.2623       -1.2497        107.4197\n",
      "      9       \u001b[36m-1.2666\u001b[0m       \u001b[32m-1.2715\u001b[0m     +  107.0520\n",
      "     10       -1.2647       -1.2571        106.5066\n",
      "     11       -1.2665       -1.2694        107.0101\n",
      "     12       \u001b[36m-1.2715\u001b[0m       -1.2689        106.8022\n",
      "     13       -1.2701       \u001b[32m-1.2755\u001b[0m     +  107.1404\n",
      "     14       \u001b[36m-1.2717\u001b[0m       -1.2668        106.6198\n",
      "     15       \u001b[36m-1.2732\u001b[0m       \u001b[32m-1.2795\u001b[0m     +  107.2454\n",
      "     16       \u001b[36m-1.2751\u001b[0m       \u001b[32m-1.2837\u001b[0m     +  106.3220\n",
      "     17       -1.2728       -1.2723        106.4240\n",
      "     18       \u001b[36m-1.2755\u001b[0m       -1.2702        107.4577\n",
      "     19       \u001b[36m-1.2776\u001b[0m       -1.2809        106.7723\n",
      "     20       -1.2750       -1.2827        107.3202\n",
      "     21       -1.2741       -1.2768        106.9023\n",
      "     22       \u001b[36m-1.2785\u001b[0m       \u001b[32m-1.2929\u001b[0m     +  106.8196\n",
      "     23       -1.2758       \u001b[32m-1.2937\u001b[0m     +  107.1025\n",
      "     24       -1.2769       -1.2756        106.7715\n",
      "     25       \u001b[36m-1.2789\u001b[0m       -1.2816        107.2548\n",
      "     26       \u001b[36m-1.2799\u001b[0m       -1.2829        107.1394\n",
      "     27       -1.2793       -1.2832        107.2449\n",
      "     28       \u001b[36m-1.2806\u001b[0m       -1.2831        107.5126\n",
      "     29       -1.2795       -1.2853        106.7595\n",
      "     30       -1.2797       -1.2456        107.3565\n",
      "     31       -1.2752       -1.2796        107.5425\n",
      "     32       -1.2803       -1.2813        108.1542\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_4 | best epoch: 23 | train loss: -1.2785 | valid loss: -1.2937 | test log likelihood: 1.1545\n",
      "submitit INFO (2019-09-21 10:09:02,780) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,960) - Starting with JobEnvironment(job_id=17930894_49, hostname=learnfair0255, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,960) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_49/17930894_49_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1523\u001b[0m       \u001b[32m-1.1824\u001b[0m     +  108.8230\n",
      "      2       \u001b[36m-1.2411\u001b[0m       \u001b[32m-1.2597\u001b[0m     +  107.8176\n",
      "      3       \u001b[36m-1.2643\u001b[0m       \u001b[32m-1.2786\u001b[0m     +  107.8441\n",
      "      4       \u001b[36m-1.2756\u001b[0m       \u001b[32m-1.2833\u001b[0m     +  105.8628\n",
      "      5       \u001b[36m-1.2838\u001b[0m       -1.2793        104.3308\n",
      "      6       \u001b[36m-1.2900\u001b[0m       \u001b[32m-1.2932\u001b[0m     +  104.3779\n",
      "      7       -1.2895       -1.2917        105.3781\n",
      "      8       \u001b[36m-1.2918\u001b[0m       -1.2820        106.3454\n",
      "      9       \u001b[36m-1.2945\u001b[0m       \u001b[32m-1.2992\u001b[0m     +  112.6746\n",
      "     10       -1.2911       -1.2886        113.9443\n",
      "     11       \u001b[36m-1.2945\u001b[0m       -1.2968        113.4302\n",
      "     12       \u001b[36m-1.2988\u001b[0m       -1.2967        112.0770\n",
      "     13       -1.2967       \u001b[32m-1.2994\u001b[0m     +  112.5042\n",
      "     14       -1.2978       -1.2932        113.2764\n",
      "     15       \u001b[36m-1.2994\u001b[0m       \u001b[32m-1.3049\u001b[0m     +  113.8391\n",
      "     16       \u001b[36m-1.2999\u001b[0m       \u001b[32m-1.3089\u001b[0m     +  114.8133\n",
      "     17       -1.2969       -1.2956        113.0809\n",
      "     18       -1.2998       -1.2954        112.7144\n",
      "     19       \u001b[36m-1.3009\u001b[0m       -1.3036        112.7067\n",
      "     20       -1.2993       -1.3055        112.6192\n",
      "     21       -1.2996       -1.3031        113.9450\n",
      "     22       \u001b[36m-1.3031\u001b[0m       \u001b[32m-1.3168\u001b[0m     +  114.5592\n",
      "     23       -1.3005       -1.3165        112.6563\n",
      "     24       -1.3007       -1.2992        113.0095\n",
      "     25       -1.3016       -1.3030        113.4883\n",
      "     26       -1.3023       -1.3036        113.1200\n",
      "     27       -1.3024       -1.3112        113.8774\n",
      "     28       \u001b[36m-1.3038\u001b[0m       -1.3071        114.8685\n",
      "     29       -1.3025       -1.3062        112.9461\n",
      "     30       -1.3028       -1.3051        112.5129\n",
      "     31       -1.3013       -1.3042        112.6575\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_4 | best epoch: 22 | train loss: -1.3031 | valid loss: -1.3168 | test log likelihood: 1.2097\n",
      "submitit INFO (2019-09-21 10:09:37,935) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,297) - Starting with JobEnvironment(job_id=17930894_50, hostname=learnfair0258, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,298) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_50/17930894_50_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.1038\u001b[0m       \u001b[32m-2.7359\u001b[0m     +  964.0105\n",
      "      2       \u001b[36m-2.8070\u001b[0m       \u001b[32m-2.9203\u001b[0m     +  485.1696\n",
      "      3       \u001b[36m-2.9233\u001b[0m       \u001b[32m-3.0053\u001b[0m     +  502.6753\n",
      "      4       \u001b[36m-2.9561\u001b[0m       -2.9923        503.5053\n",
      "      5       \u001b[36m-2.9954\u001b[0m       \u001b[32m-3.0633\u001b[0m     +  502.9012\n",
      "      6       \u001b[36m-3.0140\u001b[0m       -3.0108        497.5907\n",
      "      7       \u001b[36m-3.0267\u001b[0m       -2.9646        495.7301\n",
      "      8       -3.0246       \u001b[32m-3.1395\u001b[0m     +  509.4324\n",
      "      9       \u001b[36m-3.0483\u001b[0m       -3.0291        486.9750\n",
      "     10       \u001b[36m-3.0566\u001b[0m       -3.0353        528.0560\n",
      "     11       \u001b[36m-3.0626\u001b[0m       -3.1209        511.8381\n",
      "     12       -3.0606       -3.0925        483.8542\n",
      "     13       \u001b[36m-3.0770\u001b[0m       -3.0225        427.7063\n",
      "     14       \u001b[36m-3.0842\u001b[0m       -3.0458        523.4254\n",
      "     15       -3.0793       -3.0813        563.7084\n",
      "     16       \u001b[36m-3.0966\u001b[0m       -3.0205        551.4424\n",
      "     17       -3.0916       -3.0289        468.7526\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs/run_5 | best epoch: 8 | train loss: -3.0267 | valid loss: -3.1395 | test log likelihood: 3.0219\n",
      "submitit INFO (2019-09-21 11:50:47,785) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,888) - Starting with JobEnvironment(job_id=17930894_51, hostname=learnfair0266, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,888) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_51/17930894_51_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba32/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.0061\u001b[0m       \u001b[32m-2.3847\u001b[0m     +  752.2854\n",
      "      2       \u001b[36m-2.8533\u001b[0m       \u001b[32m-2.9620\u001b[0m     +  366.7653\n",
      "      3       \u001b[36m-2.9693\u001b[0m       \u001b[32m-3.0437\u001b[0m     +  360.8406\n",
      "      4       \u001b[36m-3.0301\u001b[0m       \u001b[32m-3.0760\u001b[0m     +  353.0457\n",
      "      5       \u001b[36m-3.0648\u001b[0m       \u001b[32m-3.1371\u001b[0m     +  359.1492\n",
      "      6       \u001b[36m-3.0931\u001b[0m       -3.0886        357.1358\n",
      "      7       \u001b[36m-3.1103\u001b[0m       -3.0658        362.6786\n",
      "      8       -3.1095       \u001b[32m-3.2124\u001b[0m     +  369.7656\n",
      "      9       \u001b[36m-3.1316\u001b[0m       -3.1418        372.8663\n",
      "     10       \u001b[36m-3.1425\u001b[0m       -3.1172        363.2200\n",
      "     11       \u001b[36m-3.1499\u001b[0m       -3.2021        352.0549\n",
      "     12       -3.1476       -3.1687        372.5332\n",
      "     13       \u001b[36m-3.1617\u001b[0m       -3.1933        370.1120\n",
      "     14       \u001b[36m-3.1706\u001b[0m       -3.1882        370.2240\n",
      "     15       -3.1654       -3.1718        373.6812\n",
      "     16       \u001b[36m-3.1820\u001b[0m       -3.1208        369.1081\n",
      "     17       -3.1769       -3.1053        364.4273\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba32/GridedCCP_noabs_nonorm/run_5 | best epoch: 8 | train loss: -3.1103 | valid loss: -3.2124 | test log likelihood: 3.0972\n",
      "submitit INFO (2019-09-21 11:08:11,698) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,888) - Starting with JobEnvironment(job_id=17930894_52, hostname=learnfair0266, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,888) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_52/17930894_52_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.6715\u001b[0m       \u001b[32m-0.8439\u001b[0m     +  80.8803\n",
      "      2       \u001b[36m-0.9108\u001b[0m       \u001b[32m-0.9478\u001b[0m     +  73.1337\n",
      "      3       \u001b[36m-0.9745\u001b[0m       \u001b[32m-1.0027\u001b[0m     +  70.9583\n",
      "      4       \u001b[36m-1.0213\u001b[0m       \u001b[32m-1.0426\u001b[0m     +  77.8081\n",
      "      5       \u001b[36m-1.0511\u001b[0m       \u001b[32m-1.0761\u001b[0m     +  76.6501\n",
      "      6       \u001b[36m-1.0585\u001b[0m       \u001b[32m-1.0859\u001b[0m     +  78.0240\n",
      "      7       \u001b[36m-1.0705\u001b[0m       -1.0819        77.7594\n",
      "      8       \u001b[36m-1.0957\u001b[0m       \u001b[32m-1.1042\u001b[0m     +  83.2108\n",
      "      9       -1.0947       \u001b[32m-1.1416\u001b[0m     +  85.8484\n",
      "     10       \u001b[36m-1.1015\u001b[0m       -1.1015        72.0169\n",
      "     11       \u001b[36m-1.1103\u001b[0m       -1.1391        81.9925\n",
      "     12       \u001b[36m-1.1142\u001b[0m       -1.1181        68.8287\n",
      "     13       \u001b[36m-1.1274\u001b[0m       -1.1101        68.7866\n",
      "     14       \u001b[36m-1.1348\u001b[0m       \u001b[32m-1.1529\u001b[0m     +  69.0318\n",
      "     15       \u001b[36m-1.1355\u001b[0m       -1.1201        79.8119\n",
      "     16       \u001b[36m-1.1464\u001b[0m       -1.1391        85.0636\n",
      "     17       \u001b[36m-1.1466\u001b[0m       \u001b[32m-1.1587\u001b[0m     +  68.7357\n",
      "     18       \u001b[36m-1.1532\u001b[0m       \u001b[32m-1.1677\u001b[0m     +  76.8537\n",
      "     19       \u001b[36m-1.1546\u001b[0m       \u001b[32m-1.1743\u001b[0m     +  83.6802\n",
      "     20       \u001b[36m-1.1594\u001b[0m       -1.1519        75.0990\n",
      "     21       \u001b[36m-1.1633\u001b[0m       -1.1672        65.4937\n",
      "     22       -1.1541       -1.1214        76.7971\n",
      "     23       -1.1559       -1.1678        75.2986\n",
      "     24       \u001b[36m-1.1682\u001b[0m       -1.1497        80.2612\n",
      "     25       \u001b[36m-1.1742\u001b[0m       \u001b[32m-1.1811\u001b[0m     +  77.6498\n",
      "     26       -1.1736       -1.1713        78.2808\n",
      "     27       -1.1704       \u001b[32m-1.1979\u001b[0m     +  77.3627\n",
      "     28       -1.1738       -1.1794        78.6836\n",
      "     29       -1.1721       -1.1693        78.3804\n",
      "     30       \u001b[36m-1.1791\u001b[0m       -1.1463        81.5152\n",
      "     31       \u001b[36m-1.1802\u001b[0m       -1.1865        79.2683\n",
      "     32       -1.1766       -1.1816        83.3628\n",
      "     33       -1.1736       -1.1827        78.9359\n",
      "     34       -1.1765       -1.1824        81.7117\n",
      "     35       -1.1798       -1.1944        82.7769\n",
      "     36       -1.1799       -1.1752        79.0710\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs/run_5 | best epoch: 27 | train loss: -1.1742 | valid loss: -1.1979 | test log likelihood: 1.1619\n",
      "submitit INFO (2019-09-21 09:57:45,988) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Starting with JobEnvironment(job_id=17930894_53, hostname=learnfair0281, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_53/17930894_53_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training mnist/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-0.7969\u001b[0m       \u001b[32m-1.0593\u001b[0m     +  73.7987\n",
      "      2       \u001b[36m-1.0974\u001b[0m       \u001b[32m-1.1279\u001b[0m     +  73.0349\n",
      "      3       \u001b[36m-1.1343\u001b[0m       \u001b[32m-1.1557\u001b[0m     +  73.1098\n",
      "      4       \u001b[36m-1.1643\u001b[0m       \u001b[32m-1.1787\u001b[0m     +  71.9970\n",
      "      5       \u001b[36m-1.1732\u001b[0m       \u001b[32m-1.1829\u001b[0m     +  72.5456\n",
      "      6       \u001b[36m-1.1758\u001b[0m       \u001b[32m-1.1987\u001b[0m     +  72.2973\n",
      "      7       \u001b[36m-1.1790\u001b[0m       -1.1895        72.2793\n",
      "      8       \u001b[36m-1.1945\u001b[0m       \u001b[32m-1.2000\u001b[0m     +  72.4466\n",
      "      9       -1.1906       \u001b[32m-1.2233\u001b[0m     +  73.0275\n",
      "     10       -1.1920       -1.1955        72.1355\n",
      "     11       -1.1935       -1.2160        72.7457\n",
      "     12       -1.1912       -1.1987        72.8082\n",
      "     13       \u001b[36m-1.2036\u001b[0m       -1.1959        72.6357\n",
      "     14       -1.2012       -1.2143        72.0096\n",
      "     15       -1.2012       -1.1858        71.9977\n",
      "     16       \u001b[36m-1.2055\u001b[0m       -1.1897        72.1574\n",
      "     17       -1.2037       -1.2122        72.7490\n",
      "     18       \u001b[36m-1.2059\u001b[0m       -1.2187        72.7591\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "mnist/GridedCCP_noabs_nonorm/run_5 | best epoch: 9 | train loss: -1.1945 | valid loss: -1.2233 | test log likelihood: 1.1789\n",
      "submitit INFO (2019-09-21 09:32:41,730) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Starting with JobEnvironment(job_id=17930894_54, hostname=learnfair0281, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_54/17930894_54_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1       \u001b[36m-2.3187\u001b[0m       \u001b[32m-3.1243\u001b[0m     +  94.2481\n",
      "      2       \u001b[36m-3.3129\u001b[0m       \u001b[32m-3.5907\u001b[0m     +  93.0081\n",
      "      3       \u001b[36m-3.5880\u001b[0m       \u001b[32m-3.6717\u001b[0m     +  89.8070\n",
      "      4       \u001b[36m-3.6887\u001b[0m       \u001b[32m-3.7145\u001b[0m     +  88.4852\n",
      "      5       \u001b[36m-3.7184\u001b[0m       -3.7126        91.9740\n",
      "      6       \u001b[36m-3.7391\u001b[0m       \u001b[32m-3.7707\u001b[0m     +  89.0416\n",
      "      7       \u001b[36m-3.7840\u001b[0m       \u001b[32m-3.7758\u001b[0m     +  93.5045\n",
      "      8       -3.7724       \u001b[32m-3.8028\u001b[0m     +  89.5315\n",
      "      9       -3.7805       \u001b[32m-3.8973\u001b[0m     +  93.6611\n",
      "     10       \u001b[36m-3.7892\u001b[0m       -3.8390        88.8579\n",
      "     11       \u001b[36m-3.8032\u001b[0m       -3.5259        88.9715\n",
      "     12       \u001b[36m-3.8114\u001b[0m       -3.6903        88.6889\n",
      "     13       \u001b[36m-3.8150\u001b[0m       -3.8559        88.5009\n",
      "     14       \u001b[36m-3.8163\u001b[0m       -3.8325        88.5303\n",
      "     15       \u001b[36m-3.8198\u001b[0m       -3.8333        89.3420\n",
      "     16       \u001b[36m-3.8409\u001b[0m       -3.8100        89.0378\n",
      "     17       -3.8314       -3.8125        88.4324\n",
      "     18       -3.8168       -3.8257        89.7367\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs/run_5 | best epoch: 9 | train loss: -3.784 | valid loss: -3.8973 | test log likelihood: 3.8058\n",
      "submitit INFO (2019-09-21 09:38:32,510) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Starting with JobEnvironment(job_id=17930894_55, hostname=learnfair0281, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,834) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_55/17930894_55_submitted.pkl\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n",
      "no_abs\n",
      "\n",
      "--- Training svhn/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.2142\u001b[0m       \u001b[32m-3.0017\u001b[0m     +  157.4076\n",
      "      2       \u001b[36m-3.3829\u001b[0m       \u001b[32m-3.6486\u001b[0m     +  164.6275\n",
      "      3       \u001b[36m-3.6119\u001b[0m       \u001b[32m-3.7195\u001b[0m     +  161.2611\n",
      "      4       \u001b[36m-3.7196\u001b[0m       \u001b[32m-3.7613\u001b[0m     +  160.3293\n",
      "      5       \u001b[36m-3.7655\u001b[0m       \u001b[32m-3.7787\u001b[0m     +  160.2696\n",
      "      6       \u001b[36m-3.7712\u001b[0m       \u001b[32m-3.8057\u001b[0m     +  178.4116\n",
      "      7       \u001b[36m-3.8207\u001b[0m       \u001b[32m-3.8317\u001b[0m     +  143.8663\n",
      "      8       -3.8160       -3.8145        170.2526\n",
      "      9       \u001b[36m-3.8301\u001b[0m       \u001b[32m-3.9059\u001b[0m     +  159.0095\n",
      "     10       \u001b[36m-3.8363\u001b[0m       -3.8689        143.3809\n",
      "     11       \u001b[36m-3.8492\u001b[0m       -3.8690        153.9937\n",
      "     12       \u001b[36m-3.8581\u001b[0m       -3.8481        115.5995\n",
      "     13       -3.8556       -3.8907        134.6649\n",
      "     14       \u001b[36m-3.8618\u001b[0m       -3.8936        142.1000\n",
      "     15       \u001b[36m-3.8670\u001b[0m       -3.8666        138.8528\n",
      "     16       \u001b[36m-3.8848\u001b[0m       -3.8477        134.6678\n",
      "     17       -3.8743       -3.8564        142.3567\n",
      "     18       -3.8638       -3.7637        139.8596\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "svhn/GridedCCP_noabs_nonorm/run_5 | best epoch: 9 | train loss: -3.8301 | valid loss: -3.9059 | test log likelihood: 3.8098\n",
      "submitit INFO (2019-09-21 09:57:47,085) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,546) - Starting with JobEnvironment(job_id=17930894_56, hostname=learnfair0285, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,546) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_56/17930894_56_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp        dur\n",
      "-------  ------------  ------------  ----  ---------\n",
      "      1       \u001b[36m-2.4950\u001b[0m       \u001b[32m-3.1635\u001b[0m     +  1240.3495\n",
      "      2       \u001b[36m-3.3013\u001b[0m       \u001b[32m-3.4078\u001b[0m     +  746.9740\n",
      "      3       \u001b[36m-3.3868\u001b[0m       \u001b[32m-3.4320\u001b[0m     +  745.5311\n",
      "      4       \u001b[36m-3.4245\u001b[0m       \u001b[32m-3.4819\u001b[0m     +  747.0830\n",
      "      5       \u001b[36m-3.4576\u001b[0m       \u001b[32m-3.5057\u001b[0m     +  828.5603\n",
      "      6       \u001b[36m-3.4737\u001b[0m       -3.4837        792.9265\n",
      "      7       \u001b[36m-3.4851\u001b[0m       -3.3940        812.0487\n",
      "      8       \u001b[36m-3.4875\u001b[0m       \u001b[32m-3.5425\u001b[0m     +  729.2410\n",
      "      9       \u001b[36m-3.5053\u001b[0m       -3.5094        668.3470\n",
      "     10       \u001b[36m-3.5093\u001b[0m       \u001b[32m-3.5465\u001b[0m     +  737.7823\n",
      "     11       \u001b[36m-3.5172\u001b[0m       -3.5312        709.6382\n",
      "     12       \u001b[36m-3.5224\u001b[0m       -3.5462        679.7631\n",
      "     13       \u001b[36m-3.5247\u001b[0m       -3.5003        708.9383\n",
      "     14       \u001b[36m-3.5386\u001b[0m       -3.5126        759.0638\n",
      "     15       -3.5340       -3.4825        677.2671\n",
      "     16       \u001b[36m-3.5418\u001b[0m       -3.4885        643.4515\n",
      "     17       -3.5388       \u001b[32m-3.5712\u001b[0m     +  679.3218\n",
      "     18       -3.5288       -3.5548        735.2511\n",
      "     19       -3.5313       -3.5346        679.4512\n",
      "     20       \u001b[36m-3.5508\u001b[0m       -3.5363        678.3668\n",
      "     21       -3.5474       -3.5298        678.9318\n",
      "     22       \u001b[36m-3.5521\u001b[0m       -3.5472        672.6224\n",
      "     23       -3.5402       -3.5346        647.9013\n",
      "     24       -3.5481       -3.5493        661.9199\n",
      "     25       -3.5474       -3.5119        657.0222\n",
      "     26       \u001b[36m-3.5536\u001b[0m       -3.5346        666.5112\n",
      "     27       \u001b[36m-3.5575\u001b[0m       \u001b[32m-3.5777\u001b[0m     +  688.1047\n",
      "     28       \u001b[36m-3.5582\u001b[0m       -3.5295        693.0562\n",
      "     29       \u001b[36m-3.5673\u001b[0m       -3.5375        673.8924\n",
      "     30       -3.5531       -3.5220        664.1747\n",
      "     31       -3.5524       -3.5628        641.3085\n",
      "     32       -3.5617       -3.5160        679.3335\n",
      "     33       -3.5613       -3.5495        677.1382\n",
      "     34       -3.5598       -3.5733        691.5622\n",
      "     35       -3.5639       -3.5443        700.5960\n",
      "     36       -3.5665       -3.5552        687.8034\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs/run_5 | best epoch: 27 | train loss: -3.5575 | valid loss: -3.5777 | test log likelihood: 3.5459\n",
      "submitit INFO (2019-09-21 16:35:12,270) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:14,831) - Starting with JobEnvironment(job_id=17930894_57, hostname=learnfair0290, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:14,831) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_57/17930894_57_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training celeba64/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-2.5664\u001b[0m       \u001b[32m-3.2698\u001b[0m     +  975.1806\n",
      "      2       \u001b[36m-3.3723\u001b[0m       \u001b[32m-3.4769\u001b[0m     +  567.3988\n",
      "      3       \u001b[36m-3.4598\u001b[0m       \u001b[32m-3.4937\u001b[0m     +  564.4164\n",
      "      4       \u001b[36m-3.5036\u001b[0m       \u001b[32m-3.5634\u001b[0m     +  573.3644\n",
      "      5       \u001b[36m-3.5277\u001b[0m       \u001b[32m-3.5731\u001b[0m     +  581.0107\n",
      "      6       \u001b[36m-3.5501\u001b[0m       -3.5445        571.1029\n",
      "      7       \u001b[36m-3.5631\u001b[0m       -3.5335        566.3966\n",
      "      8       -3.5626       \u001b[32m-3.6155\u001b[0m     +  568.4266\n",
      "      9       \u001b[36m-3.5808\u001b[0m       -3.5626        561.5194\n",
      "     10       \u001b[36m-3.5886\u001b[0m       -3.6066        566.8578\n",
      "     11       \u001b[36m-3.5931\u001b[0m       -3.6037        555.7284\n",
      "     12       \u001b[36m-3.5956\u001b[0m       -3.6137        548.2217\n",
      "     13       \u001b[36m-3.6017\u001b[0m       -3.5942        580.4468\n",
      "     14       \u001b[36m-3.6126\u001b[0m       -3.5482        572.1437\n",
      "     15       -3.6090       -3.6053        572.5692\n",
      "     16       \u001b[36m-3.6158\u001b[0m       -3.5864        601.5488\n",
      "     17       -3.6143       \u001b[32m-3.6389\u001b[0m     +  591.6402\n",
      "     18       -3.6064       -3.6147        632.4204\n",
      "     19       -3.6035       -3.5976        611.6365\n",
      "     20       \u001b[36m-3.6227\u001b[0m       -3.6018        614.9030\n",
      "     21       -3.6188       -3.5875        592.2892\n",
      "     22       \u001b[36m-3.6234\u001b[0m       -3.6162        631.8540\n",
      "     23       -3.6144       -3.6141        659.8180\n",
      "     24       \u001b[36m-3.6238\u001b[0m       -3.6172        623.8448\n",
      "     25       -3.6211       -3.6337        605.0200\n",
      "     26       \u001b[36m-3.6260\u001b[0m       -3.6136        619.4133\n",
      "     27       \u001b[36m-3.6314\u001b[0m       \u001b[32m-3.6487\u001b[0m     +  617.5027\n",
      "     28       -3.6311       -3.6083        628.7976\n",
      "     29       \u001b[36m-3.6406\u001b[0m       -3.6030        597.0971\n",
      "     30       -3.6272       -3.6197        608.6971\n",
      "     31       -3.6291       -3.6293        595.2512\n",
      "     32       -3.6383       -3.5874        598.6199\n",
      "     33       -3.6367       -3.6215        621.2072\n",
      "     34       -3.6351       -3.6425        630.7715\n",
      "     35       -3.6397       -3.6189        596.8365\n",
      "     36       \u001b[36m-3.6412\u001b[0m       -3.6212        647.4737\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "celeba64/GridedCCP_noabs_nonorm/run_5 | best epoch: 27 | train loss: -3.6314 | valid loss: -3.6487 | test log likelihood: 3.6191\n",
      "submitit INFO (2019-09-21 15:26:59,585) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,248) - Starting with JobEnvironment(job_id=17930894_58, hostname=learnfair0294, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,248) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_58/17930894_58_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1372\u001b[0m       \u001b[32m-1.2146\u001b[0m     +  104.5328\n",
      "      2       \u001b[36m-1.2260\u001b[0m       \u001b[32m-1.2417\u001b[0m     +  111.4122\n",
      "      3       \u001b[36m-1.2364\u001b[0m       \u001b[32m-1.2469\u001b[0m     +  110.0652\n",
      "      4       \u001b[36m-1.2446\u001b[0m       -1.2455        101.9052\n",
      "      5       \u001b[36m-1.2465\u001b[0m       -1.2401        102.0678\n",
      "      6       \u001b[36m-1.2515\u001b[0m       \u001b[32m-1.2644\u001b[0m     +  101.6218\n",
      "      7       \u001b[36m-1.2557\u001b[0m       -1.2487        102.1170\n",
      "      8       \u001b[36m-1.2564\u001b[0m       -1.2643        101.8157\n",
      "      9       -1.2561       -1.2510        102.3218\n",
      "     10       \u001b[36m-1.2622\u001b[0m       -1.2594        101.6295\n",
      "     11       -1.2621       -1.2627        109.1776\n",
      "     12       -1.2616       \u001b[32m-1.2681\u001b[0m     +  109.3965\n",
      "     13       \u001b[36m-1.2634\u001b[0m       \u001b[32m-1.2768\u001b[0m     +  100.8627\n",
      "     14       \u001b[36m-1.2646\u001b[0m       -1.2606        101.1556\n",
      "     15       \u001b[36m-1.2687\u001b[0m       -1.2707        101.4036\n",
      "     16       -1.2655       -1.2734        101.2005\n",
      "     17       -1.2632       -1.2504        101.0900\n",
      "     18       -1.2639       \u001b[32m-1.2823\u001b[0m     +  101.0549\n",
      "     19       \u001b[36m-1.2710\u001b[0m       -1.2775        102.3569\n",
      "     20       -1.2687       -1.2682        110.7694\n",
      "     21       -1.2667       -1.2721        102.1050\n",
      "     22       -1.2692       -1.2742        101.4620\n",
      "     23       -1.2682       -1.2633        101.2271\n",
      "     24       -1.2688       -1.2731        101.5893\n",
      "     25       \u001b[36m-1.2718\u001b[0m       -1.2717        101.3908\n",
      "     26       -1.2697       -1.2753        110.3654\n",
      "     27       -1.2669       -1.2649        100.8982\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs/run_5 | best epoch: 18 | train loss: -1.2687 | valid loss: -1.2823 | test log likelihood: 1.139\n",
      "submitit INFO (2019-09-21 09:58:25,841) - Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2019-09-21 09:09:15,067) - Starting with JobEnvironment(job_id=17930894_59, hostname=learnfair0305, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2019-09-21 09:09:15,067) - Loading pickle: /private/home/yannd/projects/Neural-Process-Family/logs/17930894_59/17930894_59_submitted.pkl\n",
      "no_abs\n",
      "\n",
      "--- Training zs-multi-mnist/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1       \u001b[36m-1.1655\u001b[0m       \u001b[32m-1.2311\u001b[0m     +  135.7672\n",
      "      2       \u001b[36m-1.2525\u001b[0m       \u001b[32m-1.2799\u001b[0m     +  131.7878\n",
      "      3       \u001b[36m-1.2749\u001b[0m       \u001b[32m-1.2845\u001b[0m     +  113.8077\n",
      "      4       \u001b[36m-1.2862\u001b[0m       \u001b[32m-1.2863\u001b[0m     +  112.7076\n",
      "      5       \u001b[36m-1.2874\u001b[0m       -1.2787        122.0701\n",
      "      6       \u001b[36m-1.2915\u001b[0m       \u001b[32m-1.3013\u001b[0m     +  127.0073\n",
      "      7       \u001b[36m-1.2935\u001b[0m       -1.2887        112.0576\n",
      "      8       -1.2931       -1.2993        132.4010\n",
      "      9       -1.2928       -1.2900        136.2980\n",
      "     10       \u001b[36m-1.2981\u001b[0m       -1.2963        126.4368\n",
      "     11       -1.2975       -1.2974        119.0547\n",
      "     12       -1.2960       \u001b[32m-1.3013\u001b[0m     +  125.6985\n",
      "     13       -1.2968       \u001b[32m-1.3084\u001b[0m     +  122.4769\n",
      "     14       \u001b[36m-1.2984\u001b[0m       -1.2944        118.7580\n",
      "     15       \u001b[36m-1.3022\u001b[0m       -1.2993        112.8279\n",
      "     16       -1.2991       -1.3056        120.9631\n",
      "     17       -1.2972       -1.2837        121.0229\n",
      "     18       -1.2971       \u001b[32m-1.3145\u001b[0m     +  112.5931\n",
      "     19       \u001b[36m-1.3035\u001b[0m       -1.3084        112.8410\n",
      "     20       -1.3012       -1.3022        112.2079\n",
      "     21       -1.2997       -1.3066        116.4302\n",
      "     22       -1.3021       -1.3075        113.4395\n",
      "     23       -1.3009       -1.2953        114.5969\n",
      "     24       -1.3011       -1.3041        127.9888\n",
      "     25       \u001b[36m-1.3040\u001b[0m       -1.3048        123.4196\n",
      "     26       -1.3031       -1.3066        126.3172\n",
      "     27       -1.3031       -1.2990        121.2515\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "zs-multi-mnist/GridedCCP_noabs_nonorm/run_5 | best epoch: 18 | train loss: -1.3022 | valid loss: -1.3145 | test log likelihood: 1.21\n",
      "submitit INFO (2019-09-21 10:06:29,602) - Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in job:\n",
    "    print(\"--------------------------------\")\n",
    "    print(j.stdout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in job:\n",
    "    print(\"--------------------------------\")\n",
    "    print(j.stderr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import load_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=load_all_results(\"results/imgs\").groupby([\"Data\", \"Model\"]).agg([\"count\",\"mean\",\"std\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=results.pivot_table(values=\"LogLike\", index=\"Model\", columns=\"Data\")[\"mean\"].loc[[\"GridedCCP_noabs_nonorm\",\"GridedCCP_noabs\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=load_all_results(\"results/iclr\").groupby([\"Data\", \"Model\"]).agg([\"mean\",\"std\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th>celeba32</th>\n",
       "      <th>celeba64</th>\n",
       "      <th>mnist</th>\n",
       "      <th>svhn</th>\n",
       "      <th>zs-multi-mnist</th>\n",
       "      <th>celeba32</th>\n",
       "      <th>celeba64</th>\n",
       "      <th>mnist</th>\n",
       "      <th>svhn</th>\n",
       "      <th>zs-multi-mnist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>GridedCCP</td>\n",
       "      <td>3.189612</td>\n",
       "      <td>3.641896</td>\n",
       "      <td>1.192756</td>\n",
       "      <td>3.892689</td>\n",
       "      <td>1.206837</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.004385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_large</td>\n",
       "      <td>3.348835</td>\n",
       "      <td>3.697071</td>\n",
       "      <td>1.259766</td>\n",
       "      <td>3.969055</td>\n",
       "      <td>0.302583</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>0.748818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_no_density</td>\n",
       "      <td>3.147637</td>\n",
       "      <td>3.616212</td>\n",
       "      <td>1.152608</td>\n",
       "      <td>3.877042</td>\n",
       "      <td>1.131187</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.077255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_no_norm</td>\n",
       "      <td>3.159699</td>\n",
       "      <td>3.621540</td>\n",
       "      <td>1.193550</td>\n",
       "      <td>3.864701</td>\n",
       "      <td>1.202753</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.006133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_noabs</td>\n",
       "      <td>3.076240</td>\n",
       "      <td>3.562211</td>\n",
       "      <td>1.153952</td>\n",
       "      <td>3.834699</td>\n",
       "      <td>1.145723</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.006254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_noabs_nonorm</td>\n",
       "      <td>3.159254</td>\n",
       "      <td>3.622247</td>\n",
       "      <td>1.191520</td>\n",
       "      <td>3.856335</td>\n",
       "      <td>1.198882</td>\n",
       "      <td>0.031779</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.030229</td>\n",
       "      <td>0.013396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_rbf</td>\n",
       "      <td>3.177886</td>\n",
       "      <td>3.626489</td>\n",
       "      <td>1.191303</td>\n",
       "      <td>3.886865</td>\n",
       "      <td>1.210399</td>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.013488</td>\n",
       "      <td>0.003908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SelfAttnCNP</td>\n",
       "      <td>3.182620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076328</td>\n",
       "      <td>3.943764</td>\n",
       "      <td>-0.828911</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043303</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.075716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean                                               \\\n",
       "Data                    celeba32  celeba64     mnist      svhn zs-multi-mnist   \n",
       "Model                                                                           \n",
       "GridedCCP               3.189612  3.641896  1.192756  3.892689       1.206837   \n",
       "GridedCCP_large         3.348835  3.697071  1.259766  3.969055       0.302583   \n",
       "GridedCCP_no_density    3.147637  3.616212  1.152608  3.877042       1.131187   \n",
       "GridedCCP_no_norm       3.159699  3.621540  1.193550  3.864701       1.202753   \n",
       "GridedCCP_noabs         3.076240  3.562211  1.153952  3.834699       1.145723   \n",
       "GridedCCP_noabs_nonorm  3.159254  3.622247  1.191520  3.856335       1.198882   \n",
       "GridedCCP_rbf           3.177886  3.626489  1.191303  3.886865       1.210399   \n",
       "SelfAttnCNP             3.182620       NaN  1.076328  3.943764      -0.828911   \n",
       "\n",
       "                             std                                               \n",
       "Data                    celeba32  celeba64     mnist      svhn zs-multi-mnist  \n",
       "Model                                                                          \n",
       "GridedCCP               0.022758  0.005689  0.006284  0.011921       0.004385  \n",
       "GridedCCP_large         0.020439  0.009171  0.005840  0.026102       0.748818  \n",
       "GridedCCP_no_density    0.021082  0.005163  0.007343  0.014566       0.077255  \n",
       "GridedCCP_no_norm       0.033209  0.005991  0.005707  0.026639       0.006133  \n",
       "GridedCCP_noabs         0.031238  0.010440  0.015529  0.016775       0.006254  \n",
       "GridedCCP_noabs_nonorm  0.031779  0.006362  0.007315  0.030229       0.013396  \n",
       "GridedCCP_rbf           0.022731  0.009268  0.004030  0.013488       0.003908  \n",
       "SelfAttnCNP             0.020023       NaN  0.043303  0.017116       0.075716  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pivot_table(values=\"LogLike\", index=\"Model\", columns=\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=results.pivot_table(values=\"LogLike\", index=\"Model\", columns=\"Data\")[\"mean\"].loc[[\"GridedCCP\",\"GridedCCP_no_norm\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Data</th>\n",
       "      <th>celeba32</th>\n",
       "      <th>celeba64</th>\n",
       "      <th>mnist</th>\n",
       "      <th>svhn</th>\n",
       "      <th>zs-multi-mnist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>GridedCCP_noabs_nonorm</td>\n",
       "      <td>3.178740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.196449</td>\n",
       "      <td>3.859168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_noabs</td>\n",
       "      <td>3.075197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166871</td>\n",
       "      <td>3.825127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP</td>\n",
       "      <td>3.189612</td>\n",
       "      <td>3.641896</td>\n",
       "      <td>1.192756</td>\n",
       "      <td>3.892689</td>\n",
       "      <td>1.206837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GridedCCP_no_norm</td>\n",
       "      <td>3.159699</td>\n",
       "      <td>3.621540</td>\n",
       "      <td>1.193550</td>\n",
       "      <td>3.864701</td>\n",
       "      <td>1.202753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Data                    celeba32  celeba64     mnist      svhn  zs-multi-mnist\n",
       "Model                                                                         \n",
       "GridedCCP_noabs_nonorm  3.178740       NaN  1.196449  3.859168             NaN\n",
       "GridedCCP_noabs         3.075197       NaN  1.166871  3.825127             NaN\n",
       "GridedCCP               3.189612  3.641896  1.192756  3.892689        1.206837\n",
       "GridedCCP_no_norm       3.159699  3.621540  1.193550  3.864701        1.202753"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((t1,t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/train_32x32.mat\n",
      "Using downloaded and verified file: /private/home/yannd/projects/Neural-Process-Family/utils/data/../../data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "from utils.data import get_dataset\n",
    "from utils.data.helpers import train_dev_split\n",
    "from utils.visualize import plot_dataset_samples_imgs, plot_losses #, plot_posterior_samples_imgs\n",
    "\n",
    "celeba32_train, celeba32_test = train_dev_split(get_dataset(\"celeba32\")(), dev_size=0.1, is_stratify=False)\n",
    "svhn_train, svhn_test = get_dataset(\"svhn\")(split=\"train\"), get_dataset(\"svhn\")(split=\"test\")\n",
    "mnist_train, mnist_test = get_dataset(\"mnist\")(split=\"train\"), get_dataset(\"mnist\")(split=\"test\")\n",
    "\n",
    "# celeba64 not fully trained yet\n",
    "train_datasets_32 = {\"mnist\":mnist_train, \"celeba32\":celeba32_train, \"svhn\":svhn_train}\n",
    "test_datasets_32 = {\"mnist\":mnist_test, \"celeba32\":celeba32_test, \"svhn\":svhn_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_abs\n",
      "no_abs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from neuralproc import NeuralProcessLoss\n",
    "from utils.train import train_models\n",
    "from utils.data import cntxt_trgt_collate\n",
    "import skorch\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "\n",
    "def add_y_dim(models, datasets):\n",
    "    \"\"\"Add y _dim to all ofthe models depending on the dataset.\"\"\"\n",
    "    return {data_name: {model_name: partial(model, y_dim=data_train.shape[0]) \n",
    "                        for model_name, model in models.items()} \n",
    "            for data_name, data_train in datasets.items()}\n",
    "\n",
    "from train_imgs import get_model\n",
    "\n",
    "\n",
    "models_grided_32 = {}\n",
    "models_grided_32[\"GridedCCP_noabs_nonorm\"] = get_model(\"GridedCCP\",  img_shape=(32,32), is_no_abs=True, is_no_normalization=True)\n",
    "models_grided_32[\"GridedCCP_noabs\"] = get_model(\"GridedCCP\",  img_shape=(32,32), is_no_abs=True)\n",
    "models_grided_32[\"GridedCCP\"] = get_model(\"GridedCCP\",  img_shape=(32,32))\n",
    "models_grided_32[\"GridedCCP\"] = get_model(\"GridedCCP\",  img_shape=(32,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_0 | best epoch: 27 | train loss: -1.2124 | valid loss: -1.2357 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_1 | best epoch: 20 | train loss: -1.2127 | valid loss: -1.2317 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_2 | best epoch: 38 | train loss: -1.218 | valid loss: -1.2487 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_3 | best epoch: 17 | train loss: -1.2028 | valid loss: -1.2249 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_4 | best epoch: 18 | train loss: -1.2087 | valid loss: -1.2313 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "mnist/GridedCCP_noabs_nonorm/run_5 | best epoch: 9 | train loss: -1.1945 | valid loss: -1.2233 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_0 | best epoch: 27 | train loss: -1.1725 | valid loss: -1.2041 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_1 | best epoch: 42 | train loss: -1.1839 | valid loss: -1.2183 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_2 | best epoch: 21 | train loss: -1.1671 | valid loss: -1.1972 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_3 | best epoch: 15 | train loss: -1.1342 | valid loss: -1.1845 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_4 | best epoch: 18 | train loss: -1.1588 | valid loss: -1.1948 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "mnist/GridedCCP_noabs/run_5 | best epoch: 27 | train loss: -1.1742 | valid loss: -1.1979 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_0 ---\n",
      "\n",
      "mnist/GridedCCP/run_0 | best epoch: 27 | train loss: -1.2121 | valid loss: -1.2366 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_1 ---\n",
      "\n",
      "mnist/GridedCCP/run_1 | best epoch: 20 | train loss: -1.2142 | valid loss: -1.2326 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_2 ---\n",
      "\n",
      "mnist/GridedCCP/run_2 | best epoch: 38 | train loss: -1.2183 | valid loss: -1.2488 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_3 ---\n",
      "\n",
      "mnist/GridedCCP/run_3 | best epoch: 15 | train loss: -1.2017 | valid loss: -1.2384 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_4 ---\n",
      "\n",
      "mnist/GridedCCP/run_4 | best epoch: 18 | train loss: -1.2094 | valid loss: -1.2321 | test log likelihood: None\n",
      "\n",
      "--- Loading mnist/GridedCCP/run_5 ---\n",
      "\n",
      "mnist/GridedCCP/run_5 | best epoch: 9 | train loss: -1.1996 | valid loss: -1.2259 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_0 | best epoch: 20 | train loss: -3.197 | valid loss: -3.2607 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_1 | best epoch: 16 | train loss: -3.1832 | valid loss: -3.2193 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_2 | best epoch: 39 | train loss: -3.2193 | valid loss: -3.2773 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_3 | best epoch: 18 | train loss: -3.1877 | valid loss: -3.2798 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_4 | best epoch: 22 | train loss: -3.1951 | valid loss: -3.2425 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs_nonorm/run_5 | best epoch: 8 | train loss: -3.1103 | valid loss: -3.2124 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_0 | best epoch: 20 | train loss: -3.1067 | valid loss: -3.1749 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_1 | best epoch: 16 | train loss: -3.084 | valid loss: -3.125 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_2 | best epoch: 39 | train loss: -3.1363 | valid loss: -3.2048 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_3 | best epoch: 18 | train loss: -3.103 | valid loss: -3.2144 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_4 | best epoch: 22 | train loss: -3.1035 | valid loss: -3.1553 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "celeba32/GridedCCP_noabs/run_5 | best epoch: 8 | train loss: -3.0267 | valid loss: -3.1395 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_0 ---\n",
      "\n",
      "celeba32/GridedCCP/run_0 | best epoch: 20 | train loss: -3.2248 | valid loss: -3.2857 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_1 ---\n",
      "\n",
      "celeba32/GridedCCP/run_1 | best epoch: 16 | train loss: -3.2099 | valid loss: -3.2458 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_2 ---\n",
      "\n",
      "celeba32/GridedCCP/run_2 | best epoch: 39 | train loss: -3.2464 | valid loss: -3.3048 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_3 ---\n",
      "\n",
      "celeba32/GridedCCP/run_3 | best epoch: 18 | train loss: -3.2153 | valid loss: -3.307 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_4 ---\n",
      "\n",
      "celeba32/GridedCCP/run_4 | best epoch: 22 | train loss: -3.2253 | valid loss: -3.268 | test log likelihood: None\n",
      "\n",
      "--- Loading celeba32/GridedCCP/run_5 ---\n",
      "\n",
      "celeba32/GridedCCP/run_5 | best epoch: 8 | train loss: -3.1623 | valid loss: -3.2622 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_0 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_0 | best epoch: 20 | train loss: -3.8724 | valid loss: -3.9242 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_1 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_1 | best epoch: 26 | train loss: -3.892 | valid loss: -3.9454 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_2 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_2 | best epoch: 12 | train loss: -3.8394 | valid loss: -3.9087 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_3 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_3 | best epoch: 40 | train loss: -3.906 | valid loss: -3.9618 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_4 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_4 | best epoch: 31 | train loss: -3.8987 | valid loss: -3.93 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs_nonorm/run_5 ---\n",
      "\n",
      "svhn/GridedCCP_noabs_nonorm/run_5 | best epoch: 9 | train loss: -3.8301 | valid loss: -3.9059 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_0 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_0 | best epoch: 20 | train loss: -3.8437 | valid loss: -3.9092 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_1 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_1 | best epoch: 19 | train loss: -3.8388 | valid loss: -3.8972 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_2 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_2 | best epoch: 21 | train loss: -3.8511 | valid loss: -3.8896 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_3 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_3 | best epoch: 13 | train loss: -3.8163 | valid loss: -3.8775 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_4 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_4 | best epoch: 31 | train loss: -3.8578 | valid loss: -3.9077 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP_noabs/run_5 ---\n",
      "\n",
      "svhn/GridedCCP_noabs/run_5 | best epoch: 9 | train loss: -3.784 | valid loss: -3.8973 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP/run_0 ---\n",
      "\n",
      "svhn/GridedCCP/run_0 | best epoch: 20 | train loss: -3.9124 | valid loss: -3.9581 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP/run_1 ---\n",
      "\n",
      "svhn/GridedCCP/run_1 | best epoch: 26 | train loss: -3.9195 | valid loss: -3.9624 | test log likelihood: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading svhn/GridedCCP/run_2 ---\n",
      "\n",
      "svhn/GridedCCP/run_2 | best epoch: 24 | train loss: -3.9238 | valid loss: -3.9554 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP/run_3 ---\n",
      "\n",
      "svhn/GridedCCP/run_3 | best epoch: 13 | train loss: -3.8931 | valid loss: -3.9304 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP/run_4 ---\n",
      "\n",
      "svhn/GridedCCP/run_4 | best epoch: 16 | train loss: -3.9077 | valid loss: -3.9329 | test log likelihood: None\n",
      "\n",
      "--- Loading svhn/GridedCCP/run_5 ---\n",
      "\n",
      "svhn/GridedCCP/run_5 | best epoch: 9 | train loss: -3.8791 | valid loss: -3.9521 | test log likelihood: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kwargs = dict(chckpnt_dirname=\"results/iclr/\", \n",
    "             is_retrain=False, \n",
    "             train_split=skorch.dataset.CVSplit(0.1), # use 10% of data for validation \n",
    "             patience=10,\n",
    "             batch_size=16,\n",
    "             seed=123,\n",
    "             runs=6)\n",
    "\n",
    "\n",
    "trainers_grided_32 = train_models(train_datasets_32, \n",
    "                                 add_y_dim(models_grided_32, train_datasets_32),\n",
    "                                  NeuralProcessLoss,\n",
    "                                 **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train import _best_loss\n",
    "import pandas as pd\n",
    "from utils.helpers import count_parameters\n",
    "\n",
    "def get_efficiency(trainers):\n",
    "    out = []\n",
    "    for name, trainer in trainers.items():\n",
    "        _, best_epoch = _best_loss(trainer)\n",
    "        l = [epoch_hist['dur'] for epoch_hist in trainer.history]\n",
    "        out.append(name.split(\"/\")+[best_epoch, sum(l)/len(l), count_parameters(trainer.module_)])\n",
    "    return pd.DataFrame(out, columns=[\"Data\", \"Model\", \"Runs\", \"Convergence Epoch\", \"Time Per Epoch\", \"N. Param\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Model</th>\n",
       "      <th>Convergence Epoch</th>\n",
       "      <th>Time Per Epoch</th>\n",
       "      <th>N. Param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>celeba32</td>\n",
       "      <td>GridedCCP</td>\n",
       "      <td>19.0</td>\n",
       "      <td>421.549205</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>celeba32</td>\n",
       "      <td>GridedCCP_noabs</td>\n",
       "      <td>19.0</td>\n",
       "      <td>424.116470</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>celeba32</td>\n",
       "      <td>GridedCCP_noabs_nonorm</td>\n",
       "      <td>19.0</td>\n",
       "      <td>414.203496</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mnist</td>\n",
       "      <td>GridedCCP</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.103737</td>\n",
       "      <td>163637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mnist</td>\n",
       "      <td>GridedCCP_noabs</td>\n",
       "      <td>24.0</td>\n",
       "      <td>73.572033</td>\n",
       "      <td>163637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>mnist</td>\n",
       "      <td>GridedCCP_noabs_nonorm</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.772923</td>\n",
       "      <td>163637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>svhn</td>\n",
       "      <td>GridedCCP</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.668675</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>svhn</td>\n",
       "      <td>GridedCCP_noabs</td>\n",
       "      <td>19.5</td>\n",
       "      <td>90.792809</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>svhn</td>\n",
       "      <td>GridedCCP_noabs_nonorm</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.303710</td>\n",
       "      <td>164511.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data                   Model  Convergence Epoch  Time Per Epoch  \\\n",
       "0  celeba32               GridedCCP               19.0      421.549205   \n",
       "1  celeba32         GridedCCP_noabs               19.0      424.116470   \n",
       "2  celeba32  GridedCCP_noabs_nonorm               19.0      414.203496   \n",
       "3     mnist               GridedCCP               19.0      100.103737   \n",
       "4     mnist         GridedCCP_noabs               24.0       73.572033   \n",
       "5     mnist  GridedCCP_noabs_nonorm               19.0       79.772923   \n",
       "6      svhn               GridedCCP               18.0      122.668675   \n",
       "7      svhn         GridedCCP_noabs               19.5       90.792809   \n",
       "8      svhn  GridedCCP_noabs_nonorm               23.0      112.303710   \n",
       "\n",
       "   N. Param  \n",
       "0  164511.0  \n",
       "1  164511.0  \n",
       "2  164511.0  \n",
       "3  163637.0  \n",
       "4  163637.0  \n",
       "5  163637.0  \n",
       "6  164511.0  \n",
       "7  164511.0  \n",
       "8  164511.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_efficiency(trainers_grided_32).groupby([\"Data\", \"Model\"]).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridedCCP_noabs_nonorm tensor(5.6931)\n",
      "GridedCCP_noabs tensor(2.4378)\n",
      "GridedCCP tensor(12.4873)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 388,
       "width": 809
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 388,
       "width": 809
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 388,
       "width": 809
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = [\"mnist\",  \"celeba32\", \"svhn\"]\n",
    "\n",
    "for m in [\"GridedCCP_noabs_nonorm\", \"GridedCCP_noabs\", \"GridedCCP\"]:\n",
    "    fig, axes = plt.subplots(1,len(dataset), figsize=(14,9))\n",
    "\n",
    "    for i, d in enumerate(dataset):\n",
    "        # use abs because I force positive weights in my implementation\n",
    "        weights_layer_1 = trainers_grided_32['{}/{}/run_1'.format(d, m)].module_.conv.weight.squeeze(1).mean(0).abs()\n",
    "        im = axes[i].imshow(weights_layer_1.detach().numpy())\n",
    "        axes[i].set_title(d+ \" \"+ m)\n",
    "\n",
    "    fig.colorbar(im,  orientation=\"horizontal\", ax=axes.ravel().tolist())\n",
    "    \n",
    "    print(m,weights_layer_1.sum().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_layer_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
