{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeurIPS - Run ZSMMT\n",
    "\n",
    "Goal : train models on ZSMMT\n",
    "\n",
    "Data : ZSMMT\n",
    "\n",
    "Models : SelfAttnLNP and ConvLNP and ConvCNP \n",
    "\n",
    "Loss : NLLLloss\n",
    "\n",
    "Runs : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "\n",
    "from train_imgs import main, parse_arguments\n",
    "from results import get_exp_args\n",
    "\n",
    "class Run:\n",
    "    def checkpoint(self, args):\n",
    "        \"\"\"Resubmits the same callable with the same arguments but makes sure continnue from last chckpnt.\"\"\"\n",
    "        args.is_continue_train = True\n",
    "        return submitit.utils.DelayedSubmission(self, args)\n",
    "\n",
    "    def __call__(self, args):\n",
    "        job_env = submitit.utils.JobEnvironment()\n",
    "        args.starting_run = args.starting_run * job_env.num_tasks + job_env.local_rank\n",
    "        return main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_exp_args(\"exp_final3_allmm\", is_load=False, is_reeval=True)\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [a for a in args if  a.model == \"SelfAttnNPF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = [a for a in args if a.model == \"ConvNPF\"]\n",
    "#for a in args:\n",
    "#    a.batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor=submitit.SlurmExecutor(folder=\"logs/%j\", max_num_timeout=3)\n",
    "executor.update_parameters(num_gpus=1, \n",
    "                           time=60*24*2,  \n",
    "                           cpus_per_task=10, \n",
    "                           mem='32GB',\n",
    "                           constraint=\"volta32gb\",\n",
    "                           partition=\"dev\"\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = executor.map_array(Run(), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SlurmJob<job_id=27822369_0, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_1, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_2, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_3, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_4, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_5, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_6, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_7, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_8, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=27822369_9, task_id=0, state=\"COMPLETED\">]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "None\n",
      "--------------------------------\n",
      "submitit INFO (2020-07-01 10:36:01,989) - Starting with JobEnvironment(job_id=27822369_1, hostname=learnfair0337, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2020-07-01 10:36:01,989) - Loading pickle: /private/home/yannd/projects/NPF/logs/27822369_1/27822369_1_submitted.pkl\n",
      "1.75\n",
      "\n",
      "--- Loading zsmms/SelfAttnNPF_NllLNPF/run_1 ---\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2020-07-01 10:36:27,968) - Starting with JobEnvironment(job_id=27822369_2, hostname=learnfair0337, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2020-07-01 10:36:27,968) - Loading pickle: /private/home/yannd/projects/NPF/logs/27822369_2/27822369_2_submitted.pkl\n",
      "1.75\n",
      "\n",
      "--- Loading zsmms/SelfAttnNPF_NllLNPF/run_2 ---\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2020-07-01 10:36:53,688) - Starting with JobEnvironment(job_id=27822369_3, hostname=learnfair0337, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2020-07-01 10:36:53,689) - Loading pickle: /private/home/yannd/projects/NPF/logs/27822369_3/27822369_3_submitted.pkl\n",
      "1.75\n",
      "\n",
      "--- Loading zsmms/SelfAttnNPF_NllLNPF/run_3 ---\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "None\n",
      "--------------------------------\n",
      "None\n",
      "--------------------------------\n",
      "None\n",
      "--------------------------------\n",
      "None\n",
      "--------------------------------\n",
      "submitit INFO (2020-07-01 10:36:01,815) - Starting with JobEnvironment(job_id=27822369_8, hostname=learnfair0725, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2020-07-01 10:36:01,815) - Loading pickle: /private/home/yannd/projects/NPF/logs/27822369_8/27822369_8_submitted.pkl\n",
      "1.75\n",
      "\n",
      "--- Loading zsmms/SelfAttnNPF_ElboLNPF/run_3 ---\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "submitit INFO (2020-07-01 10:36:01,815) - Starting with JobEnvironment(job_id=27822369_9, hostname=learnfair0749, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2020-07-01 10:36:01,815) - Loading pickle: /private/home/yannd/projects/NPF/logs/27822369_9/27822369_9_submitted.pkl\n",
      "1.75\n",
      "\n",
      "--- Loading zsmms/SelfAttnNPF_ElboLNPF/run_4 ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job in jobs:\n",
    "    print(\"--------------------------------\")\n",
    "    print(job.stdout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 18:44:40,889) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0677: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710143.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 13:20:47,677) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0677: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710144.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 05:00:08,872) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0734: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710147.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 04:41:14,259) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0745: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710150.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 09:50:45,294) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0745: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710151.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 06:14:47,969) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0785: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710157.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 19:35:36,730) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0785: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710158.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 20:38:11,312) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0785: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710159.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 07:25:53,271) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0785: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710160.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 09:33:08,624) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0785: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710161.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 02:56:29,552) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0846: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710177.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 14:42:14,670) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0846: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710178.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 07:42:17,508) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0846: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710179.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 08:34:59,592) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0850: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710181.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 07:19:33,385) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0893: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710188.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 14:06:17,564) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1, 1, 11, 11]).\n",
      "srun: error: learnfair0893: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710191.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 05:07:09,411) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0893: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710192.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 07:57:49,803) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0902: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710194.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "submitit ERROR (2020-06-27 06:01:38,039) - Submitted job triggered an exception\n",
      "ERROR:submitit:Submitted job triggered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/_submit.py\", line 6, in <module>\n",
      "    submitit_main()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 186, in submitit_main\n",
      "    process_job(args.folder)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 179, in process_job\n",
      "    raise error\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/submission.py\", line 168, in process_job\n",
      "    result = delayed.result()\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/submitit/utils.py\", line 122, in result\n",
      "    self._result = self.function(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-2-14b290c95f63>\", line 15, in __call__\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 313, in main\n",
      "    is_reeval=args.is_reeval,\n",
      "  File \"/private/home/yannd/projects/NPF/train_imgs.py\", line 251, in train\n",
      "    **kwargs,\n",
      "  File \"/private/home/yannd/projects/NPF/utils/train.py\", line 253, in train_models\n",
      "    trainer.load_params(checkpoint=chckpt)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/skorch/net.py\", line 1656, in load_params\n",
      "    self.module_.load_state_dict(state_dict)\n",
      "  File \"/private/home/yannd/.conda/envs/neuralproc/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for GridConvLNP:\n",
      "\tMissing key(s) in state_dict: \"induced_to_induced.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced.conv_blocks.9.conv2_pointwise.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.4.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.5.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.6.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.7.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.8.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.9.conv2_pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv1.pointwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_depthwise.bias\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.weight\", \"induced_to_induced_post_sampling.conv_blocks.10.conv2_pointwise.bias\". \n",
      "\tsize mismatch for conv.weight: copying a param with shape torch.Size([1, 1, 11, 11]) from checkpoint, the shape in current model is torch.Size([1, 1, 7, 7]).\n",
      "srun: error: learnfair0902: task 0: Exited with exit code 1\n",
      "srun: Terminating job step 27710195.0\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n",
      "--------------------------------\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "INFO:utils.data.imgs:Resizing ZeroShotMultiMNIST ...\n",
      "/private/home/yannd/projects/NPF/npf/architectures/mlp.py:78: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  txt.format(hidden_size, output_size, input_size, self.hidden_size)\n",
      "INFO:submitit:Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in jobs:\n",
    "    print(\"--------------------------------\")\n",
    "    print(j.stderr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c27a140d21e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jobs' is not defined"
     ]
    }
   ],
   "source": [
    "for j in jobs:\n",
    "    j.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
