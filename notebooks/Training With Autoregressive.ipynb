{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training With Autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = False # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/yannd/projects/Neural-Process-Family\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralproc\n",
    "from train_imgs import main, parse_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import get_dataset\n",
    "from utils.data.helpers import train_dev_split\n",
    "\n",
    "celeba32_train, celeba32_test = train_dev_split(get_dataset(\"celeba32\")(), dev_size=0.1, is_stratify=False)\n",
    "train_datasets = {\"celeba32\":celeba32_train}\n",
    "test_datasets = {\"celeba32\":celeba32_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralproc.utils.datasplit import GridCntxtTrgtGetter, RandomMasker, no_masker, half_masker\n",
    "\n",
    "# same as in previous tutorials but uses masks rather than indices\n",
    "get_cntxt_trgt = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.01, max_nnz=0.5, is_batch_share=True),\n",
    "                                      target_masker=no_masker,\n",
    "                                      is_add_cntxts_to_trgts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 2  # 2D spatial input \n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from neuralproc import RegularGridsConvolutionalProcess, AttentiveNeuralProcess, NeuralProcessLoss, ConvolutionalProcess\n",
    "from neuralproc.predefined import UnetCNN, CNN, SelfAttention, MLP, ResConvBlock\n",
    "from neuralproc import merge_flat_input\n",
    "from neuralproc.utils.predict import GenAllAutoregressivePixel\n",
    "\n",
    "from neuralproc.utils.helpers import (MultivariateNormalDiag, ProbabilityConverter,\n",
    "                                      make_abs_conv)\n",
    "\n",
    "kwargs = dict(r_dim=128,\n",
    "              # make sure output is in 0,1 as images preprocessed so\n",
    "              pred_loc_transformer=lambda mu: torch.sigmoid(mu))\n",
    "\n",
    "# models that take into account the grid\n",
    "models_grided = {}\n",
    "models_grided[\"test\"] = partial(RegularGridsConvolutionalProcess, \n",
    "                                     x_dim=X_DIM,\n",
    "                                     Conv=lambda y_dim: make_abs_conv(nn.Conv2d)(\n",
    "                                                y_dim,\n",
    "                                                y_dim,\n",
    "                                                groups=y_dim,\n",
    "                                                kernel_size=7,\n",
    "                                                padding=7 // 2,\n",
    "                                                bias=False,\n",
    "                                            ),\n",
    "                                     PseudoTransformer=partial(CNN, \n",
    "                                                             ConvBlock=ResConvBlock,\n",
    "                                                             Conv=torch.nn.Conv2d,\n",
    "                                                             n_blocks=5,  \n",
    "                                                             Normalization=torch.nn.BatchNorm2d, \n",
    "                                                             is_chan_last=True,\n",
    "                                                             kernel_size=3),\n",
    "                                        n_autoregressive_steps=3,\n",
    "                                        is_autoregress_confidence=True,\n",
    "                                         get_gen_autoregressive_trgts=GenAllAutoregressivePixel(),\n",
    "                                     **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridedCCP_ARC - N Param: 166561\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import count_parameters\n",
    "    \n",
    "for k,v in models_grided.items():\n",
    "    print(k, \"- N Param:\", count_parameters(v(y_dim=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_y_dim(models, datasets):\n",
    "    \"\"\"Add y _dim to all ofthe models depending on the dataset.\"\"\"\n",
    "    return {data_name: {model_name: partial(model, y_dim=data_train.shape[0]) \n",
    "                        for model_name, model in models.items()} \n",
    "            for data_name, data_train in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralproc import NeuralProcessLoss\n",
    "from utils.train import train_models\n",
    "from utils.data import cntxt_trgt_collate\n",
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training celeba32/GridedCCP_ARC/run_0 ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2b3fff2ec54fafab5d40372bb524df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# still training celeba64\n",
    "trainers_grided = train_models(train_datasets, \n",
    "                                 add_y_dim(models_grided, train_datasets),\n",
    "                                 NeuralProcessLoss,\n",
    "                                 test_datasets=test_datasets,\n",
    "                                 chckpnt_dirname=\"results/imgs/\", \n",
    "                                 is_retrain=True, \n",
    "                                 train_split=skorch.dataset.CVSplit(0.1), # use 10% of data for validation \n",
    "                                 iterator_train__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, \n",
    "                                                                               is_return_masks=True), \n",
    "                                 iterator_valid__collate_fn=cntxt_trgt_collate(get_cntxt_trgt, \n",
    "                                                                               is_return_masks=True),\n",
    "                                 patience=10,\n",
    "                                 seed=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.BoolTensor([True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
